{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "venv_prj_C247",
      "language": "python",
      "name": "venv_prj_c247"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "oldHeight": 654.545454,
      "position": {
        "height": "40px",
        "left": "266.375px",
        "right": "20px",
        "top": "2px",
        "width": "800px"
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "varInspector_section_display": "none",
      "window_display": false
    },
    "colab": {
      "name": "Single Person proper - Deep CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMepjcctlDHt",
        "colab_type": "text"
      },
      "source": [
        "# Notes\n",
        "\n",
        "This architecture was described in \"Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG\", by R. T. Schmirrmester et al, 2018. In this notebook we conduct experimetns showing the importance of using batchnorm/dropout layers, and dependacy between accuracy and the number of timestamps in a sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GNM-hxClDHw",
        "colab_type": "text"
      },
      "source": [
        "# Set up the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSCgTLd7lDHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "987dee76-fbb2-48cb-ff3c-ea5d5711a1fc"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wy-pf2-lDH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# import tf\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# import os functions\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0uNcNIQlig6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e92bfea7-21e2-4f00-a89a-e2e339118125"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHo20o7BmCNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55829f60-ce63-4211-c900-4936eedf183c"
      },
      "source": [
        "cd 'drive/My Drive/147 Project'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/147 Project'\n",
            "/content/drive/My Drive/147 Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOIQOtDIlDIC",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4vDBM9OlDIE",
        "colab_type": "text"
      },
      "source": [
        "### Read the files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL92xsdHlDIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.load(\"./EEG_data/X_test.npy\")\n",
        "y_test = np.load(\"./EEG_data/y_test.npy\") - 769\n",
        "person_train_valid = np.load(\"./EEG_data/person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"./EEG_data/X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"./EEG_data/y_train_valid.npy\") - 769\n",
        "person_test = np.load(\"./EEG_data/person_test.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhBtq0HTlDIK",
        "colab_type": "text"
      },
      "source": [
        "### Shape of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqX1K41GlDIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "42f20d1b-a474-4949-e4f3-f7488413ddeb"
      },
      "source": [
        "print(\"training/Valid data shape: {}\".format(X_train_valid.shape))       # training data of many persons\n",
        "print(\"Test data shape: {}\".format(X_test.shape))                        # test data of many persons\n",
        "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))     # training labels of many persons\n",
        "print(\"Test target shape: {}\".format(y_test.shape))                      # test labels of many persons\n",
        "print(\"Person train/valid  shape: {}\".format(person_train_valid.shape))  # which person correspond to the trail in test set\n",
        "print(\"Person test shape: {}\".format(person_test.shape))                 # which person correspond to the trail in test set"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid  shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kh6sgZ6lDIT",
        "colab_type": "text"
      },
      "source": [
        "### divide dataset into training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6V75TeclDIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ad5328c6-6da8-42b9-dd1e-146b0744cc1e"
      },
      "source": [
        "perm = np.random.permutation(X_train_valid.shape[0])\n",
        "num_train = int(0.8 * X_train_valid.shape[0])\n",
        "num_valid = X_train_valid.shape[0] - num_train\n",
        "X_train =  X_train_valid[perm[0:num_train]]\n",
        "y_train =  y_train_valid[perm[0:num_train]]\n",
        "X_valid = X_train_valid[perm[num_train: ]]\n",
        "y_valid = y_train_valid[perm[num_train: ]]\n",
        "\n",
        "\n",
        "print(\"Training data shape: {}\".format(X_train.shape))\n",
        "print(\"Training label shape: {}\".format(y_train.shape))\n",
        "print(\"Validation data shape: {}\".format(X_valid.shape))\n",
        "print(\"Validation label shape: {}\".format(y_valid.shape))\n",
        "print(\"Test data shape: {}\".format(X_test.shape))\n",
        "print(\"Test label shape: {}\".format(y_test.shape))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape: (1692, 22, 1000)\n",
            "Training label shape: (1692,)\n",
            "Validation data shape: (423, 22, 1000)\n",
            "Validation label shape: (423,)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Test label shape: (443,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkvqI_aclDIa",
        "colab_type": "text"
      },
      "source": [
        "### Augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EUuD5NalDIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sliding_window(X_arr, y_arr, time_window=100, time_step=1, time_stride=1):\n",
        "    temp_x = np.moveaxis(X_arr, 2, 0)\n",
        "    temp_x = temp_x.astype(np.float32)\n",
        "    buff = []\n",
        "    \n",
        "    num_slices = (len(temp_x)-time_window*time_step) // time_stride + 1\n",
        "    \n",
        "    # get time slices for data\n",
        "    for i in range(num_slices):\n",
        "        buff.append(temp_x[i*time_stride:i*time_stride + time_window*time_step:time_step])\n",
        "        buff[i] = np.moveaxis(buff[i], 0, 2)\n",
        "        # uncomment this if additional dimension is needed\n",
        "        # buff[i] = buff[i].reshape(1, buff[i].shape[0], buff[i].shape[1], buff[i].shape[2])\n",
        "        \n",
        "    temp_x = np.concatenate(buff)\n",
        "        \n",
        "    # get time slice for labels\n",
        "    temp_y = np.ones((X_arr.shape[0],num_slices))\n",
        "    \n",
        "    for i in range(len(y_arr)):\n",
        "        temp_y[i] = temp_y[i] * y_arr[i]\n",
        "        \n",
        "    temp_y = temp_y.reshape((-1))\n",
        "    \n",
        "    return temp_x, temp_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltwtwpV8p0-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_augmented_deep_model(TIME_WINDOW):\n",
        "    # input\n",
        "    deep_aug_input = layers.Input(shape=(22, TIME_WINDOW))\n",
        "\n",
        "\n",
        "    # ================================== CONV1 ================================== #\n",
        "\n",
        "    # conv accross time domain\n",
        "    r1 = layers.Reshape((22, TIME_WINDOW, 1))(deep_aug_input)\n",
        "    c1 = layers.Conv2D(25, (1, 10), strides=(1, 1))(r1)\n",
        "    new_size = TIME_WINDOW - 10 + 1\n",
        "    t1 = tf.keras.layers.Permute((2, 3, 1))(c1)\n",
        "\n",
        "    # # conv accross channels\n",
        "    r2 = layers.Reshape((new_size, 25*22, 1))(t1)\n",
        "    c2 = layers.Conv2D(25, (1, 25*22), strides=(1, 1))(r2)\n",
        "    bn2 = layers.BatchNormalization(axis=1)(c2)                 # do I use the right filter?\n",
        "    a2 = layers.Activation(\"elu\")(bn2)\n",
        "\n",
        "\n",
        "    # max pool across time domain\n",
        "    r3 = layers.Reshape((new_size, 25, 1))(a2)\n",
        "    maxpool3 = layers.MaxPooling2D(pool_size=(3, 1), strides=(3, 1))(r3)\n",
        "    new_size = (new_size - 3)//3 + 1\n",
        "    \n",
        "    # # =========================================================================== #\n",
        "\n",
        "\n",
        "\n",
        "    # # ================================= CONV2-4 ================================= #\n",
        "\n",
        "    c4 = layers.Conv2D(50, (10, 25), strides=(1, 1))(maxpool3)\n",
        "    new_size = new_size - 10 + 1\n",
        "    bn4 = layers.BatchNormalization(axis=1)(c4)\n",
        "    a4 = layers.Activation(\"elu\")(bn4)\n",
        "    do4 = layers.Dropout(0.5)(a4)\n",
        "    r4 = layers.Reshape((new_size, 50, 1))(do4)\n",
        "    maxpool4 = layers.MaxPooling2D(pool_size=(3, 1), strides=(3, 1))(r4)\n",
        "    new_size = (new_size - 3)//3 + 1\n",
        "    \n",
        "\n",
        "    c5 = layers.Conv2D(100, (10, 50), strides=(1, 1))(maxpool4)\n",
        "    new_size = new_size - 10 + 1\n",
        "    bn5 = layers.BatchNormalization(axis=1)(c5)\n",
        "    a5 = layers.Activation(\"elu\")(bn5)\n",
        "    do5 = layers.Dropout(0.5)(a5)\n",
        "    r5 = layers.Reshape((new_size, 100, 1))(do5)\n",
        "    maxpool5 = layers.MaxPooling2D(pool_size=(3, 1), strides=(3, 1))(r5)\n",
        "    new_size = (new_size - 3)//3 + 1\n",
        "    \n",
        "\n",
        "    c6 = layers.Conv2D(200, (10, 100), strides=(1, 1))(maxpool5)\n",
        "    new_size = new_size - 10 + 1\n",
        "    bn6 = layers.BatchNormalization(axis=1)(c6)\n",
        "    a6 = layers.Activation(\"elu\")(bn6)\n",
        "    do6 = layers.Dropout(0.5)(a6)\n",
        "    r6 = layers.Reshape((new_size, 200, 1))(do6)\n",
        "    maxpool6 = layers.MaxPooling2D(pool_size=(3, 1), strides=(3, 1))(r6)\n",
        "\n",
        "    # # =========================================================================== #\n",
        "\n",
        "    f7 = layers.Flatten()(do6)\n",
        "\n",
        "    # output\n",
        "    deep_aug_output = layers.Dense(4, activation=\"softmax\")(f7)\n",
        "    \n",
        "    return keras.Model(inputs = deep_aug_input, outputs = deep_aug_output, name=\"deep_aug_model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOEdxm_aolMm",
        "colab_type": "text"
      },
      "source": [
        "### Train on Single Person dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyxJ0pVjokE3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec8a4d27-f708-4698-eb00-8cb277d01c54"
      },
      "source": [
        "person_num = 0\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (189, 22, 1000)\n",
            "Training label shape for 1 person: (189,)\n",
            "Validation data shape for 1 person: (48, 22, 1000)\n",
            "Validation label shape for 1 person: (48,)\n",
            "Test data shape for 1 person: (50, 22, 1000)\n",
            "Test label shape for 1 person: (50,)\n",
            "Training data shape with slices: (189, 22, 600)\n",
            "Training label shape with slice: (189,)\n",
            "Validation data shape with slices: (48, 22, 600)\n",
            "Validation label shape with slice: (48,)\n",
            "Train on 189 samples, validate on 48 samples\n",
            "Epoch 1/60\n",
            "189/189 [==============================] - 1s 4ms/sample - loss: 3.1019 - acc: 0.3175 - val_loss: 1.6097 - val_acc: 0.1875\n",
            "Epoch 2/60\n",
            "189/189 [==============================] - 0s 374us/sample - loss: 2.1036 - acc: 0.2540 - val_loss: 1.5882 - val_acc: 0.2917\n",
            "Epoch 3/60\n",
            "189/189 [==============================] - 0s 383us/sample - loss: 1.9759 - acc: 0.2381 - val_loss: 1.5692 - val_acc: 0.2708\n",
            "Epoch 4/60\n",
            "189/189 [==============================] - 0s 377us/sample - loss: 1.8695 - acc: 0.3122 - val_loss: 1.5329 - val_acc: 0.3750\n",
            "Epoch 5/60\n",
            "189/189 [==============================] - 0s 364us/sample - loss: 1.6633 - acc: 0.3122 - val_loss: 1.9802 - val_acc: 0.3333\n",
            "Epoch 6/60\n",
            "189/189 [==============================] - 0s 361us/sample - loss: 1.6182 - acc: 0.3122 - val_loss: 1.5080 - val_acc: 0.4167\n",
            "Epoch 7/60\n",
            "189/189 [==============================] - 0s 357us/sample - loss: 1.6541 - acc: 0.3545 - val_loss: 1.5701 - val_acc: 0.3750\n",
            "Epoch 8/60\n",
            "189/189 [==============================] - 0s 366us/sample - loss: 1.5059 - acc: 0.3757 - val_loss: 1.5787 - val_acc: 0.3542\n",
            "Epoch 9/60\n",
            "189/189 [==============================] - 0s 348us/sample - loss: 1.5638 - acc: 0.3651 - val_loss: 1.4171 - val_acc: 0.3750\n",
            "Epoch 10/60\n",
            "189/189 [==============================] - 0s 365us/sample - loss: 1.4096 - acc: 0.3968 - val_loss: 1.4300 - val_acc: 0.3750\n",
            "Epoch 11/60\n",
            "189/189 [==============================] - 0s 371us/sample - loss: 1.4828 - acc: 0.3386 - val_loss: 1.3531 - val_acc: 0.3333\n",
            "Epoch 12/60\n",
            "189/189 [==============================] - 0s 377us/sample - loss: 1.5027 - acc: 0.3545 - val_loss: 1.3267 - val_acc: 0.3750\n",
            "Epoch 13/60\n",
            "189/189 [==============================] - 0s 378us/sample - loss: 1.3928 - acc: 0.4074 - val_loss: 1.3150 - val_acc: 0.3750\n",
            "Epoch 14/60\n",
            "189/189 [==============================] - 0s 380us/sample - loss: 1.4038 - acc: 0.3862 - val_loss: 1.3044 - val_acc: 0.4167\n",
            "Epoch 15/60\n",
            "189/189 [==============================] - 0s 371us/sample - loss: 1.2954 - acc: 0.4815 - val_loss: 1.3326 - val_acc: 0.3958\n",
            "Epoch 16/60\n",
            "189/189 [==============================] - 0s 350us/sample - loss: 1.3307 - acc: 0.4233 - val_loss: 1.2995 - val_acc: 0.3958\n",
            "Epoch 17/60\n",
            "189/189 [==============================] - 0s 379us/sample - loss: 1.2916 - acc: 0.4497 - val_loss: 1.3021 - val_acc: 0.3750\n",
            "Epoch 18/60\n",
            "189/189 [==============================] - 0s 389us/sample - loss: 1.1986 - acc: 0.4550 - val_loss: 1.3059 - val_acc: 0.3333\n",
            "Epoch 19/60\n",
            "189/189 [==============================] - 0s 438us/sample - loss: 1.2063 - acc: 0.4868 - val_loss: 1.2795 - val_acc: 0.4167\n",
            "Epoch 20/60\n",
            "189/189 [==============================] - 0s 364us/sample - loss: 1.2045 - acc: 0.5397 - val_loss: 1.2783 - val_acc: 0.4583\n",
            "Epoch 21/60\n",
            "189/189 [==============================] - 0s 356us/sample - loss: 1.0567 - acc: 0.5344 - val_loss: 1.3037 - val_acc: 0.3333\n",
            "Epoch 22/60\n",
            "189/189 [==============================] - 0s 369us/sample - loss: 1.1091 - acc: 0.5608 - val_loss: 1.2527 - val_acc: 0.3958\n",
            "Epoch 23/60\n",
            "189/189 [==============================] - 0s 358us/sample - loss: 1.0464 - acc: 0.5714 - val_loss: 1.2472 - val_acc: 0.3750\n",
            "Epoch 24/60\n",
            "189/189 [==============================] - 0s 367us/sample - loss: 0.9526 - acc: 0.6190 - val_loss: 1.2398 - val_acc: 0.4583\n",
            "Epoch 25/60\n",
            "189/189 [==============================] - 0s 360us/sample - loss: 1.0363 - acc: 0.5714 - val_loss: 1.2279 - val_acc: 0.4583\n",
            "Epoch 26/60\n",
            "189/189 [==============================] - 0s 359us/sample - loss: 0.9023 - acc: 0.6138 - val_loss: 1.2243 - val_acc: 0.4583\n",
            "Epoch 27/60\n",
            "189/189 [==============================] - 0s 390us/sample - loss: 0.8664 - acc: 0.6561 - val_loss: 1.1976 - val_acc: 0.4583\n",
            "Epoch 28/60\n",
            "189/189 [==============================] - 0s 363us/sample - loss: 0.8438 - acc: 0.6190 - val_loss: 1.1613 - val_acc: 0.5208\n",
            "Epoch 29/60\n",
            "189/189 [==============================] - 0s 357us/sample - loss: 0.7220 - acc: 0.7037 - val_loss: 1.1514 - val_acc: 0.5000\n",
            "Epoch 30/60\n",
            "189/189 [==============================] - 0s 365us/sample - loss: 0.6877 - acc: 0.7460 - val_loss: 1.1233 - val_acc: 0.4583\n",
            "Epoch 31/60\n",
            "189/189 [==============================] - 0s 370us/sample - loss: 0.6954 - acc: 0.7249 - val_loss: 1.1173 - val_acc: 0.4792\n",
            "Epoch 32/60\n",
            "189/189 [==============================] - 0s 354us/sample - loss: 0.5918 - acc: 0.7725 - val_loss: 1.1146 - val_acc: 0.5000\n",
            "Epoch 33/60\n",
            "189/189 [==============================] - 0s 372us/sample - loss: 0.5620 - acc: 0.7884 - val_loss: 1.1055 - val_acc: 0.5833\n",
            "Epoch 34/60\n",
            "189/189 [==============================] - 0s 361us/sample - loss: 0.5011 - acc: 0.8201 - val_loss: 1.1431 - val_acc: 0.5000\n",
            "Epoch 35/60\n",
            "189/189 [==============================] - 0s 378us/sample - loss: 0.6017 - acc: 0.7778 - val_loss: 1.1164 - val_acc: 0.5417\n",
            "Epoch 36/60\n",
            "189/189 [==============================] - 0s 382us/sample - loss: 0.5811 - acc: 0.7937 - val_loss: 1.1648 - val_acc: 0.5833\n",
            "Epoch 37/60\n",
            "189/189 [==============================] - 0s 343us/sample - loss: 0.5533 - acc: 0.7566 - val_loss: 1.0715 - val_acc: 0.5417\n",
            "Epoch 38/60\n",
            "189/189 [==============================] - 0s 353us/sample - loss: 0.3631 - acc: 0.8624 - val_loss: 1.1905 - val_acc: 0.4792\n",
            "Epoch 39/60\n",
            "189/189 [==============================] - 0s 368us/sample - loss: 0.3986 - acc: 0.8571 - val_loss: 1.0713 - val_acc: 0.5417\n",
            "Epoch 40/60\n",
            "189/189 [==============================] - 0s 332us/sample - loss: 0.2612 - acc: 0.8942 - val_loss: 1.0601 - val_acc: 0.5417\n",
            "Epoch 41/60\n",
            "189/189 [==============================] - 0s 395us/sample - loss: 0.3146 - acc: 0.8942 - val_loss: 1.1104 - val_acc: 0.5208\n",
            "Epoch 42/60\n",
            "189/189 [==============================] - 0s 345us/sample - loss: 0.2465 - acc: 0.8995 - val_loss: 1.0868 - val_acc: 0.5208\n",
            "Epoch 43/60\n",
            "189/189 [==============================] - 0s 424us/sample - loss: 0.2367 - acc: 0.9101 - val_loss: 1.0850 - val_acc: 0.5625\n",
            "Epoch 44/60\n",
            "189/189 [==============================] - 0s 381us/sample - loss: 0.1642 - acc: 0.9365 - val_loss: 1.2601 - val_acc: 0.4583\n",
            "Epoch 45/60\n",
            "189/189 [==============================] - 0s 406us/sample - loss: 0.1803 - acc: 0.9206 - val_loss: 1.2393 - val_acc: 0.5208\n",
            "Epoch 46/60\n",
            "189/189 [==============================] - 0s 395us/sample - loss: 0.1952 - acc: 0.9206 - val_loss: 1.2841 - val_acc: 0.4167\n",
            "Epoch 47/60\n",
            "189/189 [==============================] - 0s 408us/sample - loss: 0.3402 - acc: 0.8677 - val_loss: 1.5979 - val_acc: 0.4375\n",
            "Epoch 48/60\n",
            "189/189 [==============================] - 0s 386us/sample - loss: 0.2066 - acc: 0.9365 - val_loss: 1.2122 - val_acc: 0.5000\n",
            "Epoch 49/60\n",
            "189/189 [==============================] - 0s 382us/sample - loss: 0.2286 - acc: 0.9048 - val_loss: 1.1863 - val_acc: 0.6042\n",
            "Epoch 50/60\n",
            "189/189 [==============================] - 0s 362us/sample - loss: 0.1373 - acc: 0.9471 - val_loss: 1.2537 - val_acc: 0.5417\n",
            "Epoch 51/60\n",
            "189/189 [==============================] - 0s 368us/sample - loss: 0.1324 - acc: 0.9577 - val_loss: 1.1451 - val_acc: 0.5833\n",
            "Epoch 52/60\n",
            "189/189 [==============================] - 0s 381us/sample - loss: 0.1856 - acc: 0.9365 - val_loss: 1.2667 - val_acc: 0.5833\n",
            "Epoch 53/60\n",
            "189/189 [==============================] - 0s 398us/sample - loss: 0.0781 - acc: 0.9788 - val_loss: 1.2391 - val_acc: 0.4792\n",
            "Epoch 54/60\n",
            "189/189 [==============================] - 0s 416us/sample - loss: 0.1134 - acc: 0.9524 - val_loss: 1.3427 - val_acc: 0.5417\n",
            "Epoch 55/60\n",
            "189/189 [==============================] - 0s 370us/sample - loss: 0.1247 - acc: 0.9524 - val_loss: 1.2559 - val_acc: 0.5417\n",
            "Epoch 56/60\n",
            "189/189 [==============================] - 0s 371us/sample - loss: 0.0974 - acc: 0.9630 - val_loss: 1.3226 - val_acc: 0.5417\n",
            "Epoch 57/60\n",
            "189/189 [==============================] - 0s 382us/sample - loss: 0.1234 - acc: 0.9524 - val_loss: 1.3459 - val_acc: 0.5417\n",
            "Epoch 58/60\n",
            "189/189 [==============================] - 0s 361us/sample - loss: 0.2009 - acc: 0.9312 - val_loss: 1.8415 - val_acc: 0.5000\n",
            "Epoch 59/60\n",
            "189/189 [==============================] - 0s 358us/sample - loss: 0.1983 - acc: 0.9312 - val_loss: 1.5555 - val_acc: 0.5625\n",
            "Epoch 60/60\n",
            "189/189 [==============================] - 0s 360us/sample - loss: 0.1389 - acc: 0.9365 - val_loss: 1.3981 - val_acc: 0.5417\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "50/50 [==============================] - 0s 241us/sample - loss: 1.8042 - acc: 0.5200\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 151us/sample - loss: 2.4027 - acc: 0.3138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.4027202764429303, 0.31376976]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S63pLTHc1KZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8dfc4675-26f1-48b2-a72d-c042ead194f7"
      },
      "source": [
        "person_num = 1\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (188, 22, 1000)\n",
            "Training label shape for 1 person: (188,)\n",
            "Validation data shape for 1 person: (48, 22, 1000)\n",
            "Validation label shape for 1 person: (48,)\n",
            "Test data shape for 1 person: (50, 22, 1000)\n",
            "Test label shape for 1 person: (50,)\n",
            "Training data shape with slices: (188, 22, 600)\n",
            "Training label shape with slice: (188,)\n",
            "Validation data shape with slices: (48, 22, 600)\n",
            "Validation label shape with slice: (48,)\n",
            "Train on 188 samples, validate on 48 samples\n",
            "Epoch 1/60\n",
            "188/188 [==============================] - 1s 4ms/sample - loss: 4.4071 - acc: 0.2713 - val_loss: 1.3895 - val_acc: 0.2500\n",
            "Epoch 2/60\n",
            "188/188 [==============================] - 0s 386us/sample - loss: 2.0831 - acc: 0.2660 - val_loss: 2.1183 - val_acc: 0.2708\n",
            "Epoch 3/60\n",
            "188/188 [==============================] - 0s 377us/sample - loss: 1.8098 - acc: 0.2500 - val_loss: 1.8270 - val_acc: 0.2292\n",
            "Epoch 4/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 1.8765 - acc: 0.2340 - val_loss: 1.3582 - val_acc: 0.2292\n",
            "Epoch 5/60\n",
            "188/188 [==============================] - 0s 433us/sample - loss: 1.6681 - acc: 0.3085 - val_loss: 1.5845 - val_acc: 0.2708\n",
            "Epoch 6/60\n",
            "188/188 [==============================] - 0s 383us/sample - loss: 1.7112 - acc: 0.2287 - val_loss: 1.5485 - val_acc: 0.2917\n",
            "Epoch 7/60\n",
            "188/188 [==============================] - 0s 379us/sample - loss: 1.7575 - acc: 0.2340 - val_loss: 1.4763 - val_acc: 0.2917\n",
            "Epoch 8/60\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 1.6154 - acc: 0.3404 - val_loss: 1.5398 - val_acc: 0.3125\n",
            "Epoch 9/60\n",
            "188/188 [==============================] - 0s 410us/sample - loss: 1.5941 - acc: 0.3351 - val_loss: 1.5771 - val_acc: 0.3125\n",
            "Epoch 10/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 1.5473 - acc: 0.3723 - val_loss: 1.4302 - val_acc: 0.3542\n",
            "Epoch 11/60\n",
            "188/188 [==============================] - 0s 372us/sample - loss: 1.4676 - acc: 0.3564 - val_loss: 1.3693 - val_acc: 0.2500\n",
            "Epoch 12/60\n",
            "188/188 [==============================] - 0s 358us/sample - loss: 1.4263 - acc: 0.4096 - val_loss: 1.4790 - val_acc: 0.3125\n",
            "Epoch 13/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 1.4394 - acc: 0.4149 - val_loss: 1.4138 - val_acc: 0.2917\n",
            "Epoch 14/60\n",
            "188/188 [==============================] - 0s 377us/sample - loss: 1.4327 - acc: 0.3830 - val_loss: 1.4267 - val_acc: 0.2292\n",
            "Epoch 15/60\n",
            "188/188 [==============================] - 0s 366us/sample - loss: 1.2983 - acc: 0.4468 - val_loss: 1.4487 - val_acc: 0.3542\n",
            "Epoch 16/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 1.2758 - acc: 0.4787 - val_loss: 1.4208 - val_acc: 0.2500\n",
            "Epoch 17/60\n",
            "188/188 [==============================] - 0s 367us/sample - loss: 1.2918 - acc: 0.4309 - val_loss: 1.3784 - val_acc: 0.2708\n",
            "Epoch 18/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 1.2804 - acc: 0.4415 - val_loss: 1.3698 - val_acc: 0.3542\n",
            "Epoch 19/60\n",
            "188/188 [==============================] - 0s 389us/sample - loss: 1.3186 - acc: 0.5053 - val_loss: 1.3711 - val_acc: 0.3125\n",
            "Epoch 20/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 1.3179 - acc: 0.4628 - val_loss: 1.3743 - val_acc: 0.2500\n",
            "Epoch 21/60\n",
            "188/188 [==============================] - 0s 360us/sample - loss: 1.2191 - acc: 0.4734 - val_loss: 1.3756 - val_acc: 0.4167\n",
            "Epoch 22/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 1.1221 - acc: 0.5160 - val_loss: 1.3848 - val_acc: 0.1875\n",
            "Epoch 23/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 1.1618 - acc: 0.5053 - val_loss: 1.3734 - val_acc: 0.2500\n",
            "Epoch 24/60\n",
            "188/188 [==============================] - 0s 367us/sample - loss: 1.0705 - acc: 0.5691 - val_loss: 1.3767 - val_acc: 0.2917\n",
            "Epoch 25/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 1.1532 - acc: 0.5106 - val_loss: 1.3903 - val_acc: 0.2708\n",
            "Epoch 26/60\n",
            "188/188 [==============================] - 0s 396us/sample - loss: 1.0945 - acc: 0.5904 - val_loss: 1.4047 - val_acc: 0.3125\n",
            "Epoch 27/60\n",
            "188/188 [==============================] - 0s 393us/sample - loss: 1.0715 - acc: 0.5638 - val_loss: 1.4178 - val_acc: 0.2708\n",
            "Epoch 28/60\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 1.0340 - acc: 0.5798 - val_loss: 1.3885 - val_acc: 0.2500\n",
            "Epoch 29/60\n",
            "188/188 [==============================] - 0s 364us/sample - loss: 0.8939 - acc: 0.6277 - val_loss: 1.4119 - val_acc: 0.1875\n",
            "Epoch 30/60\n",
            "188/188 [==============================] - 0s 383us/sample - loss: 0.8245 - acc: 0.6809 - val_loss: 1.5020 - val_acc: 0.2917\n",
            "Epoch 31/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.8162 - acc: 0.6543 - val_loss: 1.5331 - val_acc: 0.2083\n",
            "Epoch 32/60\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.7700 - acc: 0.7021 - val_loss: 1.4616 - val_acc: 0.1875\n",
            "Epoch 33/60\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.6900 - acc: 0.7394 - val_loss: 1.4690 - val_acc: 0.2917\n",
            "Epoch 34/60\n",
            "188/188 [==============================] - 0s 365us/sample - loss: 0.6643 - acc: 0.7447 - val_loss: 1.4592 - val_acc: 0.2500\n",
            "Epoch 35/60\n",
            "188/188 [==============================] - 0s 405us/sample - loss: 0.5566 - acc: 0.7713 - val_loss: 1.6008 - val_acc: 0.2917\n",
            "Epoch 36/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.5736 - acc: 0.7606 - val_loss: 1.4451 - val_acc: 0.3333\n",
            "Epoch 37/60\n",
            "188/188 [==============================] - 0s 377us/sample - loss: 0.5457 - acc: 0.8032 - val_loss: 1.5706 - val_acc: 0.3125\n",
            "Epoch 38/60\n",
            "188/188 [==============================] - 0s 382us/sample - loss: 0.4198 - acc: 0.8245 - val_loss: 1.4795 - val_acc: 0.2500\n",
            "Epoch 39/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.4601 - acc: 0.8404 - val_loss: 1.5786 - val_acc: 0.2917\n",
            "Epoch 40/60\n",
            "188/188 [==============================] - 0s 369us/sample - loss: 0.4914 - acc: 0.7766 - val_loss: 1.3703 - val_acc: 0.3750\n",
            "Epoch 41/60\n",
            "188/188 [==============================] - 0s 369us/sample - loss: 0.4196 - acc: 0.8670 - val_loss: 1.5290 - val_acc: 0.2292\n",
            "Epoch 42/60\n",
            "188/188 [==============================] - 0s 356us/sample - loss: 0.3549 - acc: 0.8670 - val_loss: 1.3969 - val_acc: 0.3958\n",
            "Epoch 43/60\n",
            "188/188 [==============================] - 0s 339us/sample - loss: 0.3109 - acc: 0.8989 - val_loss: 1.6114 - val_acc: 0.3125\n",
            "Epoch 44/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.2707 - acc: 0.9202 - val_loss: 1.6013 - val_acc: 0.2917\n",
            "Epoch 45/60\n",
            "188/188 [==============================] - 0s 361us/sample - loss: 0.3089 - acc: 0.8883 - val_loss: 1.6838 - val_acc: 0.3125\n",
            "Epoch 46/60\n",
            "188/188 [==============================] - 0s 340us/sample - loss: 0.3019 - acc: 0.8989 - val_loss: 1.6355 - val_acc: 0.3750\n",
            "Epoch 47/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 0.2090 - acc: 0.8989 - val_loss: 1.7558 - val_acc: 0.3750\n",
            "Epoch 48/60\n",
            "188/188 [==============================] - 0s 356us/sample - loss: 0.2553 - acc: 0.9309 - val_loss: 1.7776 - val_acc: 0.3750\n",
            "Epoch 49/60\n",
            "188/188 [==============================] - 0s 458us/sample - loss: 0.1770 - acc: 0.9362 - val_loss: 1.6689 - val_acc: 0.3750\n",
            "Epoch 50/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.1352 - acc: 0.9521 - val_loss: 1.7874 - val_acc: 0.3333\n",
            "Epoch 51/60\n",
            "188/188 [==============================] - 0s 386us/sample - loss: 0.1856 - acc: 0.9362 - val_loss: 1.8444 - val_acc: 0.3333\n",
            "Epoch 52/60\n",
            "188/188 [==============================] - 0s 398us/sample - loss: 0.1536 - acc: 0.9521 - val_loss: 2.0806 - val_acc: 0.3750\n",
            "Epoch 53/60\n",
            "188/188 [==============================] - 0s 410us/sample - loss: 0.1021 - acc: 0.9681 - val_loss: 1.7717 - val_acc: 0.2917\n",
            "Epoch 54/60\n",
            "188/188 [==============================] - 0s 430us/sample - loss: 0.0892 - acc: 0.9787 - val_loss: 2.0273 - val_acc: 0.3542\n",
            "Epoch 55/60\n",
            "188/188 [==============================] - 0s 433us/sample - loss: 0.0703 - acc: 0.9787 - val_loss: 2.0333 - val_acc: 0.2708\n",
            "Epoch 56/60\n",
            "188/188 [==============================] - 0s 391us/sample - loss: 0.0494 - acc: 0.9894 - val_loss: 1.8015 - val_acc: 0.3333\n",
            "Epoch 57/60\n",
            "188/188 [==============================] - 0s 369us/sample - loss: 0.0509 - acc: 0.9894 - val_loss: 1.7621 - val_acc: 0.3333\n",
            "Epoch 58/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.0692 - acc: 0.9787 - val_loss: 1.6183 - val_acc: 0.3958\n",
            "Epoch 59/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.0607 - acc: 0.9787 - val_loss: 1.8551 - val_acc: 0.3542\n",
            "Epoch 60/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.1062 - acc: 0.9681 - val_loss: 2.0021 - val_acc: 0.3542\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "50/50 [==============================] - 0s 243us/sample - loss: 2.1523 - acc: 0.3600\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 181us/sample - loss: 2.5031 - acc: 0.3521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.503112441530077, 0.35214448]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJI6n0bf1L1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9787092-0e9a-48cd-f897-35135affbab0"
      },
      "source": [
        "person_num = 2\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (188, 22, 1000)\n",
            "Training label shape for 1 person: (188,)\n",
            "Validation data shape for 1 person: (48, 22, 1000)\n",
            "Validation label shape for 1 person: (48,)\n",
            "Test data shape for 1 person: (50, 22, 1000)\n",
            "Test label shape for 1 person: (50,)\n",
            "Training data shape with slices: (188, 22, 600)\n",
            "Training label shape with slice: (188,)\n",
            "Validation data shape with slices: (48, 22, 600)\n",
            "Validation label shape with slice: (48,)\n",
            "Train on 188 samples, validate on 48 samples\n",
            "Epoch 1/60\n",
            "188/188 [==============================] - 1s 4ms/sample - loss: 2.4297 - acc: 0.3138 - val_loss: 1.5118 - val_acc: 0.3125\n",
            "Epoch 2/60\n",
            "188/188 [==============================] - 0s 359us/sample - loss: 1.9522 - acc: 0.2606 - val_loss: 1.5750 - val_acc: 0.2083\n",
            "Epoch 3/60\n",
            "188/188 [==============================] - 0s 385us/sample - loss: 1.7718 - acc: 0.2606 - val_loss: 1.6682 - val_acc: 0.3125\n",
            "Epoch 4/60\n",
            "188/188 [==============================] - 0s 393us/sample - loss: 1.7338 - acc: 0.2766 - val_loss: 1.4221 - val_acc: 0.2083\n",
            "Epoch 5/60\n",
            "188/188 [==============================] - 0s 455us/sample - loss: 1.9601 - acc: 0.1809 - val_loss: 1.3701 - val_acc: 0.3125\n",
            "Epoch 6/60\n",
            "188/188 [==============================] - 0s 425us/sample - loss: 1.6593 - acc: 0.2500 - val_loss: 1.3589 - val_acc: 0.3125\n",
            "Epoch 7/60\n",
            "188/188 [==============================] - 0s 388us/sample - loss: 1.5689 - acc: 0.3191 - val_loss: 1.3403 - val_acc: 0.3125\n",
            "Epoch 8/60\n",
            "188/188 [==============================] - 0s 423us/sample - loss: 1.5559 - acc: 0.3191 - val_loss: 1.3212 - val_acc: 0.4792\n",
            "Epoch 9/60\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 1.5767 - acc: 0.3723 - val_loss: 1.3528 - val_acc: 0.3958\n",
            "Epoch 10/60\n",
            "188/188 [==============================] - 0s 390us/sample - loss: 1.4711 - acc: 0.3457 - val_loss: 1.3670 - val_acc: 0.3125\n",
            "Epoch 11/60\n",
            "188/188 [==============================] - 0s 371us/sample - loss: 1.5032 - acc: 0.3670 - val_loss: 1.3343 - val_acc: 0.2500\n",
            "Epoch 12/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 1.4452 - acc: 0.3457 - val_loss: 1.3117 - val_acc: 0.2917\n",
            "Epoch 13/60\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 1.2848 - acc: 0.4468 - val_loss: 1.4605 - val_acc: 0.2292\n",
            "Epoch 14/60\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 1.2698 - acc: 0.4787 - val_loss: 1.3387 - val_acc: 0.3125\n",
            "Epoch 15/60\n",
            "188/188 [==============================] - 0s 390us/sample - loss: 1.1862 - acc: 0.4787 - val_loss: 1.4311 - val_acc: 0.2500\n",
            "Epoch 16/60\n",
            "188/188 [==============================] - 0s 388us/sample - loss: 1.2166 - acc: 0.4840 - val_loss: 1.2699 - val_acc: 0.3750\n",
            "Epoch 17/60\n",
            "188/188 [==============================] - 0s 394us/sample - loss: 1.1014 - acc: 0.5638 - val_loss: 1.3170 - val_acc: 0.3333\n",
            "Epoch 18/60\n",
            "188/188 [==============================] - 0s 412us/sample - loss: 1.0860 - acc: 0.5426 - val_loss: 1.3068 - val_acc: 0.2917\n",
            "Epoch 19/60\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.9977 - acc: 0.5798 - val_loss: 1.2713 - val_acc: 0.3333\n",
            "Epoch 20/60\n",
            "188/188 [==============================] - 0s 371us/sample - loss: 0.9612 - acc: 0.6330 - val_loss: 1.2887 - val_acc: 0.3958\n",
            "Epoch 21/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.8308 - acc: 0.6649 - val_loss: 1.1209 - val_acc: 0.4792\n",
            "Epoch 22/60\n",
            "188/188 [==============================] - 0s 371us/sample - loss: 0.7166 - acc: 0.7340 - val_loss: 1.0756 - val_acc: 0.5625\n",
            "Epoch 23/60\n",
            "188/188 [==============================] - 0s 365us/sample - loss: 0.7445 - acc: 0.6862 - val_loss: 1.0834 - val_acc: 0.4792\n",
            "Epoch 24/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 0.6754 - acc: 0.7394 - val_loss: 1.0951 - val_acc: 0.5208\n",
            "Epoch 25/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.6310 - acc: 0.7553 - val_loss: 1.0457 - val_acc: 0.6250\n",
            "Epoch 26/60\n",
            "188/188 [==============================] - 0s 399us/sample - loss: 0.4618 - acc: 0.8298 - val_loss: 1.0768 - val_acc: 0.5625\n",
            "Epoch 27/60\n",
            "188/188 [==============================] - 0s 363us/sample - loss: 0.4862 - acc: 0.8298 - val_loss: 0.9667 - val_acc: 0.6042\n",
            "Epoch 28/60\n",
            "188/188 [==============================] - 0s 360us/sample - loss: 0.3343 - acc: 0.8670 - val_loss: 0.9392 - val_acc: 0.5833\n",
            "Epoch 29/60\n",
            "188/188 [==============================] - 0s 354us/sample - loss: 0.3406 - acc: 0.8723 - val_loss: 0.9556 - val_acc: 0.6250\n",
            "Epoch 30/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 0.2196 - acc: 0.9255 - val_loss: 0.9344 - val_acc: 0.6250\n",
            "Epoch 31/60\n",
            "188/188 [==============================] - 0s 369us/sample - loss: 0.2965 - acc: 0.8883 - val_loss: 0.8878 - val_acc: 0.6458\n",
            "Epoch 32/60\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 0.1843 - acc: 0.9309 - val_loss: 0.8779 - val_acc: 0.6250\n",
            "Epoch 33/60\n",
            "188/188 [==============================] - 0s 363us/sample - loss: 0.1824 - acc: 0.9309 - val_loss: 0.8782 - val_acc: 0.6042\n",
            "Epoch 34/60\n",
            "188/188 [==============================] - 0s 375us/sample - loss: 0.3293 - acc: 0.8936 - val_loss: 0.8660 - val_acc: 0.6458\n",
            "Epoch 35/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.1889 - acc: 0.9309 - val_loss: 0.9758 - val_acc: 0.6250\n",
            "Epoch 36/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.3100 - acc: 0.9096 - val_loss: 1.0249 - val_acc: 0.5625\n",
            "Epoch 37/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 0.2282 - acc: 0.9096 - val_loss: 0.8101 - val_acc: 0.7083\n",
            "Epoch 38/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.1254 - acc: 0.9628 - val_loss: 1.0308 - val_acc: 0.6458\n",
            "Epoch 39/60\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.1548 - acc: 0.9309 - val_loss: 0.9319 - val_acc: 0.6667\n",
            "Epoch 40/60\n",
            "188/188 [==============================] - 0s 362us/sample - loss: 0.1170 - acc: 0.9574 - val_loss: 0.8049 - val_acc: 0.7500\n",
            "Epoch 41/60\n",
            "188/188 [==============================] - 0s 362us/sample - loss: 0.1226 - acc: 0.9681 - val_loss: 0.9974 - val_acc: 0.6458\n",
            "Epoch 42/60\n",
            "188/188 [==============================] - 0s 384us/sample - loss: 0.1076 - acc: 0.9681 - val_loss: 0.8937 - val_acc: 0.6458\n",
            "Epoch 43/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.0590 - acc: 0.9840 - val_loss: 0.9315 - val_acc: 0.6458\n",
            "Epoch 44/60\n",
            "188/188 [==============================] - 0s 377us/sample - loss: 0.0733 - acc: 0.9840 - val_loss: 0.8970 - val_acc: 0.6875\n",
            "Epoch 45/60\n",
            "188/188 [==============================] - 0s 414us/sample - loss: 0.0309 - acc: 0.9947 - val_loss: 0.9397 - val_acc: 0.6250\n",
            "Epoch 46/60\n",
            "188/188 [==============================] - 0s 378us/sample - loss: 0.0367 - acc: 0.9840 - val_loss: 1.0400 - val_acc: 0.6250\n",
            "Epoch 47/60\n",
            "188/188 [==============================] - 0s 382us/sample - loss: 0.0676 - acc: 0.9734 - val_loss: 1.0723 - val_acc: 0.6042\n",
            "Epoch 48/60\n",
            "188/188 [==============================] - 0s 362us/sample - loss: 0.0482 - acc: 0.9840 - val_loss: 1.0394 - val_acc: 0.6458\n",
            "Epoch 49/60\n",
            "188/188 [==============================] - 0s 403us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 1.1348 - val_acc: 0.6042\n",
            "Epoch 50/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.0248 - acc: 0.9947 - val_loss: 0.9091 - val_acc: 0.7083\n",
            "Epoch 51/60\n",
            "188/188 [==============================] - 0s 340us/sample - loss: 0.0359 - acc: 0.9840 - val_loss: 1.2250 - val_acc: 0.6667\n",
            "Epoch 52/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 0.0303 - acc: 0.9947 - val_loss: 1.0783 - val_acc: 0.6250\n",
            "Epoch 53/60\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.0309 - acc: 0.9840 - val_loss: 1.0310 - val_acc: 0.6250\n",
            "Epoch 54/60\n",
            "188/188 [==============================] - 0s 335us/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 1.2657 - val_acc: 0.6667\n",
            "Epoch 55/60\n",
            "188/188 [==============================] - 0s 369us/sample - loss: 0.0556 - acc: 0.9894 - val_loss: 0.9379 - val_acc: 0.6042\n",
            "Epoch 56/60\n",
            "188/188 [==============================] - 0s 341us/sample - loss: 0.0263 - acc: 0.9894 - val_loss: 1.4068 - val_acc: 0.6042\n",
            "Epoch 57/60\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 0.0979 - acc: 0.9787 - val_loss: 0.8589 - val_acc: 0.7500\n",
            "Epoch 58/60\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 0.0399 - acc: 0.9894 - val_loss: 2.0068 - val_acc: 0.5625\n",
            "Epoch 59/60\n",
            "188/188 [==============================] - 0s 385us/sample - loss: 0.1231 - acc: 0.9628 - val_loss: 1.0135 - val_acc: 0.6875\n",
            "Epoch 60/60\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0661 - acc: 0.9734 - val_loss: 1.0324 - val_acc: 0.6458\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "50/50 [==============================] - 0s 238us/sample - loss: 1.8262 - acc: 0.4400\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 180us/sample - loss: 3.3189 - acc: 0.3725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.318917728170046, 0.37246048]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2jDdSFi1M1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21d0f050-d2e6-43f3-9758-6f768f349bd1"
      },
      "source": [
        "person_num = 3\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (187, 22, 1000)\n",
            "Training label shape for 1 person: (187,)\n",
            "Validation data shape for 1 person: (47, 22, 1000)\n",
            "Validation label shape for 1 person: (47,)\n",
            "Test data shape for 1 person: (50, 22, 1000)\n",
            "Test label shape for 1 person: (50,)\n",
            "Training data shape with slices: (187, 22, 600)\n",
            "Training label shape with slice: (187,)\n",
            "Validation data shape with slices: (47, 22, 600)\n",
            "Validation label shape with slice: (47,)\n",
            "Train on 187 samples, validate on 47 samples\n",
            "Epoch 1/60\n",
            "187/187 [==============================] - 1s 5ms/sample - loss: 3.5911 - acc: 0.2299 - val_loss: 1.5121 - val_acc: 0.3191\n",
            "Epoch 2/60\n",
            "187/187 [==============================] - 0s 468us/sample - loss: 2.2870 - acc: 0.2193 - val_loss: 1.3597 - val_acc: 0.2553\n",
            "Epoch 3/60\n",
            "187/187 [==============================] - 0s 417us/sample - loss: 1.8868 - acc: 0.2941 - val_loss: 1.5079 - val_acc: 0.4255\n",
            "Epoch 4/60\n",
            "187/187 [==============================] - 0s 400us/sample - loss: 1.8241 - acc: 0.2513 - val_loss: 1.3092 - val_acc: 0.4043\n",
            "Epoch 5/60\n",
            "187/187 [==============================] - 0s 439us/sample - loss: 1.6387 - acc: 0.2727 - val_loss: 1.2843 - val_acc: 0.3830\n",
            "Epoch 6/60\n",
            "187/187 [==============================] - 0s 411us/sample - loss: 1.6961 - acc: 0.2620 - val_loss: 1.3692 - val_acc: 0.4255\n",
            "Epoch 7/60\n",
            "187/187 [==============================] - 0s 385us/sample - loss: 1.6368 - acc: 0.2834 - val_loss: 1.2657 - val_acc: 0.4468\n",
            "Epoch 8/60\n",
            "187/187 [==============================] - 0s 387us/sample - loss: 1.5744 - acc: 0.3209 - val_loss: 1.2688 - val_acc: 0.4255\n",
            "Epoch 9/60\n",
            "187/187 [==============================] - 0s 382us/sample - loss: 1.5758 - acc: 0.3690 - val_loss: 1.2615 - val_acc: 0.4681\n",
            "Epoch 10/60\n",
            "187/187 [==============================] - 0s 388us/sample - loss: 1.4376 - acc: 0.3850 - val_loss: 1.2511 - val_acc: 0.4681\n",
            "Epoch 11/60\n",
            "187/187 [==============================] - 0s 382us/sample - loss: 1.4787 - acc: 0.3476 - val_loss: 1.2985 - val_acc: 0.3617\n",
            "Epoch 12/60\n",
            "187/187 [==============================] - 0s 396us/sample - loss: 1.4155 - acc: 0.3957 - val_loss: 1.2691 - val_acc: 0.4255\n",
            "Epoch 13/60\n",
            "187/187 [==============================] - 0s 396us/sample - loss: 1.5106 - acc: 0.3690 - val_loss: 1.2813 - val_acc: 0.4255\n",
            "Epoch 14/60\n",
            "187/187 [==============================] - 0s 377us/sample - loss: 1.5696 - acc: 0.3369 - val_loss: 1.2992 - val_acc: 0.4043\n",
            "Epoch 15/60\n",
            "187/187 [==============================] - 0s 411us/sample - loss: 1.4047 - acc: 0.3743 - val_loss: 1.2680 - val_acc: 0.4681\n",
            "Epoch 16/60\n",
            "187/187 [==============================] - 0s 398us/sample - loss: 1.3724 - acc: 0.4011 - val_loss: 1.2882 - val_acc: 0.3617\n",
            "Epoch 17/60\n",
            "187/187 [==============================] - 0s 376us/sample - loss: 1.2864 - acc: 0.4278 - val_loss: 1.3017 - val_acc: 0.3830\n",
            "Epoch 18/60\n",
            "187/187 [==============================] - 0s 379us/sample - loss: 1.3492 - acc: 0.3850 - val_loss: 1.2853 - val_acc: 0.4043\n",
            "Epoch 19/60\n",
            "187/187 [==============================] - 0s 366us/sample - loss: 1.2997 - acc: 0.4385 - val_loss: 1.3419 - val_acc: 0.3617\n",
            "Epoch 20/60\n",
            "187/187 [==============================] - 0s 386us/sample - loss: 1.2100 - acc: 0.5241 - val_loss: 1.2639 - val_acc: 0.5106\n",
            "Epoch 21/60\n",
            "187/187 [==============================] - 0s 395us/sample - loss: 1.1717 - acc: 0.4759 - val_loss: 1.3453 - val_acc: 0.3404\n",
            "Epoch 22/60\n",
            "187/187 [==============================] - 0s 363us/sample - loss: 1.1092 - acc: 0.5668 - val_loss: 1.2588 - val_acc: 0.4894\n",
            "Epoch 23/60\n",
            "187/187 [==============================] - 0s 384us/sample - loss: 1.1127 - acc: 0.5722 - val_loss: 1.2976 - val_acc: 0.4255\n",
            "Epoch 24/60\n",
            "187/187 [==============================] - 0s 365us/sample - loss: 1.0260 - acc: 0.5775 - val_loss: 1.2838 - val_acc: 0.4468\n",
            "Epoch 25/60\n",
            "187/187 [==============================] - 0s 405us/sample - loss: 0.9887 - acc: 0.5829 - val_loss: 1.2877 - val_acc: 0.3830\n",
            "Epoch 26/60\n",
            "187/187 [==============================] - 0s 386us/sample - loss: 0.9443 - acc: 0.5722 - val_loss: 1.2693 - val_acc: 0.4681\n",
            "Epoch 27/60\n",
            "187/187 [==============================] - 0s 382us/sample - loss: 0.8883 - acc: 0.6257 - val_loss: 1.2738 - val_acc: 0.4468\n",
            "Epoch 28/60\n",
            "187/187 [==============================] - 0s 432us/sample - loss: 0.7844 - acc: 0.6952 - val_loss: 1.2649 - val_acc: 0.4681\n",
            "Epoch 29/60\n",
            "187/187 [==============================] - 0s 368us/sample - loss: 0.8152 - acc: 0.6738 - val_loss: 1.2337 - val_acc: 0.4043\n",
            "Epoch 30/60\n",
            "187/187 [==============================] - 0s 390us/sample - loss: 0.8059 - acc: 0.6898 - val_loss: 1.2189 - val_acc: 0.4894\n",
            "Epoch 31/60\n",
            "187/187 [==============================] - 0s 373us/sample - loss: 0.7377 - acc: 0.7326 - val_loss: 1.3422 - val_acc: 0.4255\n",
            "Epoch 32/60\n",
            "187/187 [==============================] - 0s 383us/sample - loss: 0.7405 - acc: 0.7166 - val_loss: 1.2438 - val_acc: 0.4468\n",
            "Epoch 33/60\n",
            "187/187 [==============================] - 0s 381us/sample - loss: 0.6126 - acc: 0.7380 - val_loss: 1.2006 - val_acc: 0.5106\n",
            "Epoch 34/60\n",
            "187/187 [==============================] - 0s 370us/sample - loss: 0.5524 - acc: 0.7647 - val_loss: 1.2528 - val_acc: 0.4468\n",
            "Epoch 35/60\n",
            "187/187 [==============================] - 0s 379us/sample - loss: 0.5917 - acc: 0.7807 - val_loss: 1.2637 - val_acc: 0.3404\n",
            "Epoch 36/60\n",
            "187/187 [==============================] - 0s 390us/sample - loss: 0.5527 - acc: 0.7807 - val_loss: 1.2271 - val_acc: 0.3830\n",
            "Epoch 37/60\n",
            "187/187 [==============================] - 0s 377us/sample - loss: 0.5306 - acc: 0.8021 - val_loss: 1.2403 - val_acc: 0.4468\n",
            "Epoch 38/60\n",
            "187/187 [==============================] - 0s 386us/sample - loss: 0.4589 - acc: 0.7861 - val_loss: 1.2697 - val_acc: 0.3617\n",
            "Epoch 39/60\n",
            "187/187 [==============================] - 0s 392us/sample - loss: 0.4001 - acc: 0.8610 - val_loss: 1.2156 - val_acc: 0.4043\n",
            "Epoch 40/60\n",
            "187/187 [==============================] - 0s 393us/sample - loss: 0.3262 - acc: 0.8663 - val_loss: 1.2121 - val_acc: 0.5319\n",
            "Epoch 41/60\n",
            "187/187 [==============================] - 0s 424us/sample - loss: 0.3182 - acc: 0.8663 - val_loss: 1.1880 - val_acc: 0.5106\n",
            "Epoch 42/60\n",
            "187/187 [==============================] - 0s 391us/sample - loss: 0.3264 - acc: 0.8663 - val_loss: 1.1605 - val_acc: 0.4894\n",
            "Epoch 43/60\n",
            "187/187 [==============================] - 0s 378us/sample - loss: 0.3295 - acc: 0.8824 - val_loss: 1.3116 - val_acc: 0.4468\n",
            "Epoch 44/60\n",
            "187/187 [==============================] - 0s 358us/sample - loss: 0.2690 - acc: 0.9251 - val_loss: 1.2678 - val_acc: 0.3617\n",
            "Epoch 45/60\n",
            "187/187 [==============================] - 0s 342us/sample - loss: 0.3143 - acc: 0.8663 - val_loss: 1.2973 - val_acc: 0.4255\n",
            "Epoch 46/60\n",
            "187/187 [==============================] - 0s 380us/sample - loss: 0.2336 - acc: 0.8984 - val_loss: 1.2225 - val_acc: 0.4255\n",
            "Epoch 47/60\n",
            "187/187 [==============================] - 0s 365us/sample - loss: 0.3016 - acc: 0.8930 - val_loss: 1.2771 - val_acc: 0.4681\n",
            "Epoch 48/60\n",
            "187/187 [==============================] - 0s 356us/sample - loss: 0.2396 - acc: 0.9144 - val_loss: 1.1620 - val_acc: 0.4681\n",
            "Epoch 49/60\n",
            "187/187 [==============================] - 0s 362us/sample - loss: 0.1587 - acc: 0.9412 - val_loss: 1.0747 - val_acc: 0.5745\n",
            "Epoch 50/60\n",
            "187/187 [==============================] - 0s 378us/sample - loss: 0.1380 - acc: 0.9358 - val_loss: 1.0463 - val_acc: 0.5745\n",
            "Epoch 51/60\n",
            "187/187 [==============================] - 0s 435us/sample - loss: 0.1038 - acc: 0.9733 - val_loss: 1.0819 - val_acc: 0.5319\n",
            "Epoch 52/60\n",
            "187/187 [==============================] - 0s 395us/sample - loss: 0.0939 - acc: 0.9679 - val_loss: 1.1568 - val_acc: 0.4681\n",
            "Epoch 53/60\n",
            "187/187 [==============================] - 0s 418us/sample - loss: 0.1267 - acc: 0.9412 - val_loss: 1.2261 - val_acc: 0.4681\n",
            "Epoch 54/60\n",
            "187/187 [==============================] - 0s 479us/sample - loss: 0.1168 - acc: 0.9572 - val_loss: 1.2303 - val_acc: 0.5106\n",
            "Epoch 55/60\n",
            "187/187 [==============================] - 0s 420us/sample - loss: 0.1172 - acc: 0.9679 - val_loss: 1.2223 - val_acc: 0.4681\n",
            "Epoch 56/60\n",
            "187/187 [==============================] - 0s 406us/sample - loss: 0.1361 - acc: 0.9572 - val_loss: 1.2261 - val_acc: 0.5319\n",
            "Epoch 57/60\n",
            "187/187 [==============================] - 0s 431us/sample - loss: 0.1066 - acc: 0.9626 - val_loss: 1.1836 - val_acc: 0.4894\n",
            "Epoch 58/60\n",
            "187/187 [==============================] - 0s 392us/sample - loss: 0.0512 - acc: 0.9733 - val_loss: 1.3894 - val_acc: 0.5532\n",
            "Epoch 59/60\n",
            "187/187 [==============================] - 0s 395us/sample - loss: 0.1214 - acc: 0.9465 - val_loss: 1.1813 - val_acc: 0.5745\n",
            "Epoch 60/60\n",
            "187/187 [==============================] - 0s 410us/sample - loss: 0.0782 - acc: 0.9626 - val_loss: 1.4848 - val_acc: 0.4894\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "50/50 [==============================] - 0s 278us/sample - loss: 1.7628 - acc: 0.4200\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 178us/sample - loss: 2.2680 - acc: 0.3476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.268008071197613, 0.3476298]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64fO8cb61N3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14403db4-4553-4e3a-9e5a-d43e40dfd735"
      },
      "source": [
        "person_num = 4\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (188, 22, 1000)\n",
            "Training label shape for 1 person: (188,)\n",
            "Validation data shape for 1 person: (47, 22, 1000)\n",
            "Validation label shape for 1 person: (47,)\n",
            "Test data shape for 1 person: (47, 22, 1000)\n",
            "Test label shape for 1 person: (47,)\n",
            "Training data shape with slices: (188, 22, 600)\n",
            "Training label shape with slice: (188,)\n",
            "Validation data shape with slices: (47, 22, 600)\n",
            "Validation label shape with slice: (47,)\n",
            "Train on 188 samples, validate on 47 samples\n",
            "Epoch 1/60\n",
            "188/188 [==============================] - 1s 5ms/sample - loss: 3.8058 - acc: 0.2660 - val_loss: 1.3954 - val_acc: 0.3191\n",
            "Epoch 2/60\n",
            "188/188 [==============================] - 0s 453us/sample - loss: 1.9487 - acc: 0.2606 - val_loss: 1.3527 - val_acc: 0.3404\n",
            "Epoch 3/60\n",
            "188/188 [==============================] - 0s 407us/sample - loss: 1.8732 - acc: 0.2606 - val_loss: 1.2911 - val_acc: 0.4043\n",
            "Epoch 4/60\n",
            "188/188 [==============================] - 0s 408us/sample - loss: 1.8054 - acc: 0.2500 - val_loss: 1.4312 - val_acc: 0.3404\n",
            "Epoch 5/60\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 1.7258 - acc: 0.2979 - val_loss: 1.2847 - val_acc: 0.3830\n",
            "Epoch 6/60\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 1.5988 - acc: 0.3191 - val_loss: 1.3069 - val_acc: 0.4043\n",
            "Epoch 7/60\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 1.6093 - acc: 0.3191 - val_loss: 1.2688 - val_acc: 0.4468\n",
            "Epoch 8/60\n",
            "188/188 [==============================] - 0s 376us/sample - loss: 1.6180 - acc: 0.2660 - val_loss: 1.1979 - val_acc: 0.5106\n",
            "Epoch 9/60\n",
            "188/188 [==============================] - 0s 398us/sample - loss: 1.4105 - acc: 0.3777 - val_loss: 1.3872 - val_acc: 0.3191\n",
            "Epoch 10/60\n",
            "188/188 [==============================] - 0s 395us/sample - loss: 1.4885 - acc: 0.3511 - val_loss: 1.2101 - val_acc: 0.4681\n",
            "Epoch 11/60\n",
            "188/188 [==============================] - 0s 363us/sample - loss: 1.4128 - acc: 0.3457 - val_loss: 1.2476 - val_acc: 0.4681\n",
            "Epoch 12/60\n",
            "188/188 [==============================] - 0s 390us/sample - loss: 1.3172 - acc: 0.4468 - val_loss: 1.2753 - val_acc: 0.4681\n",
            "Epoch 13/60\n",
            "188/188 [==============================] - 0s 379us/sample - loss: 1.3542 - acc: 0.4043 - val_loss: 1.1925 - val_acc: 0.5106\n",
            "Epoch 14/60\n",
            "188/188 [==============================] - 0s 395us/sample - loss: 1.1568 - acc: 0.5426 - val_loss: 1.2670 - val_acc: 0.4255\n",
            "Epoch 15/60\n",
            "188/188 [==============================] - 0s 390us/sample - loss: 1.1766 - acc: 0.4787 - val_loss: 1.2300 - val_acc: 0.4894\n",
            "Epoch 16/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 1.0563 - acc: 0.5638 - val_loss: 1.1540 - val_acc: 0.5319\n",
            "Epoch 17/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 1.1042 - acc: 0.5319 - val_loss: 1.1773 - val_acc: 0.5745\n",
            "Epoch 18/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 1.0309 - acc: 0.5479 - val_loss: 1.1093 - val_acc: 0.4894\n",
            "Epoch 19/60\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.9702 - acc: 0.5851 - val_loss: 1.1532 - val_acc: 0.4255\n",
            "Epoch 20/60\n",
            "188/188 [==============================] - 0s 367us/sample - loss: 0.9383 - acc: 0.6330 - val_loss: 1.1440 - val_acc: 0.4894\n",
            "Epoch 21/60\n",
            "188/188 [==============================] - 0s 400us/sample - loss: 0.8815 - acc: 0.6064 - val_loss: 1.1217 - val_acc: 0.4894\n",
            "Epoch 22/60\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.8453 - acc: 0.6649 - val_loss: 1.1516 - val_acc: 0.4468\n",
            "Epoch 23/60\n",
            "188/188 [==============================] - 0s 391us/sample - loss: 0.7487 - acc: 0.7021 - val_loss: 1.0730 - val_acc: 0.5319\n",
            "Epoch 24/60\n",
            "188/188 [==============================] - 0s 370us/sample - loss: 0.6675 - acc: 0.7340 - val_loss: 1.0947 - val_acc: 0.3617\n",
            "Epoch 25/60\n",
            "188/188 [==============================] - 0s 390us/sample - loss: 0.6929 - acc: 0.7234 - val_loss: 1.0277 - val_acc: 0.5532\n",
            "Epoch 26/60\n",
            "188/188 [==============================] - 0s 367us/sample - loss: 0.7685 - acc: 0.6702 - val_loss: 1.0707 - val_acc: 0.5319\n",
            "Epoch 27/60\n",
            "188/188 [==============================] - 0s 396us/sample - loss: 0.7185 - acc: 0.6915 - val_loss: 1.0521 - val_acc: 0.5319\n",
            "Epoch 28/60\n",
            "188/188 [==============================] - 0s 410us/sample - loss: 0.7126 - acc: 0.7181 - val_loss: 1.1172 - val_acc: 0.4894\n",
            "Epoch 29/60\n",
            "188/188 [==============================] - 0s 374us/sample - loss: 0.6969 - acc: 0.7181 - val_loss: 1.0602 - val_acc: 0.4681\n",
            "Epoch 30/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 0.6091 - acc: 0.7660 - val_loss: 1.1945 - val_acc: 0.4681\n",
            "Epoch 31/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.5755 - acc: 0.7872 - val_loss: 1.0684 - val_acc: 0.5106\n",
            "Epoch 32/60\n",
            "188/188 [==============================] - 0s 382us/sample - loss: 0.4506 - acc: 0.8032 - val_loss: 1.1047 - val_acc: 0.4043\n",
            "Epoch 33/60\n",
            "188/188 [==============================] - 0s 384us/sample - loss: 0.3943 - acc: 0.8511 - val_loss: 1.0683 - val_acc: 0.4255\n",
            "Epoch 34/60\n",
            "188/188 [==============================] - 0s 400us/sample - loss: 0.3246 - acc: 0.8989 - val_loss: 1.0514 - val_acc: 0.4681\n",
            "Epoch 35/60\n",
            "188/188 [==============================] - 0s 416us/sample - loss: 0.2326 - acc: 0.8989 - val_loss: 1.0882 - val_acc: 0.4468\n",
            "Epoch 36/60\n",
            "188/188 [==============================] - 0s 394us/sample - loss: 0.2629 - acc: 0.9043 - val_loss: 1.1499 - val_acc: 0.4681\n",
            "Epoch 37/60\n",
            "188/188 [==============================] - 0s 378us/sample - loss: 0.2466 - acc: 0.8989 - val_loss: 1.1501 - val_acc: 0.5532\n",
            "Epoch 38/60\n",
            "188/188 [==============================] - 0s 385us/sample - loss: 0.2190 - acc: 0.9255 - val_loss: 1.2429 - val_acc: 0.3404\n",
            "Epoch 39/60\n",
            "188/188 [==============================] - 0s 380us/sample - loss: 0.2198 - acc: 0.9255 - val_loss: 1.2789 - val_acc: 0.3830\n",
            "Epoch 40/60\n",
            "188/188 [==============================] - 0s 368us/sample - loss: 0.1709 - acc: 0.9309 - val_loss: 1.3448 - val_acc: 0.3830\n",
            "Epoch 41/60\n",
            "188/188 [==============================] - 0s 371us/sample - loss: 0.1559 - acc: 0.9628 - val_loss: 1.2469 - val_acc: 0.4468\n",
            "Epoch 42/60\n",
            "188/188 [==============================] - 0s 392us/sample - loss: 0.1336 - acc: 0.9574 - val_loss: 1.3166 - val_acc: 0.4681\n",
            "Epoch 43/60\n",
            "188/188 [==============================] - 0s 345us/sample - loss: 0.1877 - acc: 0.9309 - val_loss: 1.1258 - val_acc: 0.5106\n",
            "Epoch 44/60\n",
            "188/188 [==============================] - 0s 381us/sample - loss: 0.1548 - acc: 0.9574 - val_loss: 1.0545 - val_acc: 0.5106\n",
            "Epoch 45/60\n",
            "188/188 [==============================] - 0s 355us/sample - loss: 0.1497 - acc: 0.9521 - val_loss: 1.2277 - val_acc: 0.5106\n",
            "Epoch 46/60\n",
            "188/188 [==============================] - 0s 439us/sample - loss: 0.1576 - acc: 0.9468 - val_loss: 1.1410 - val_acc: 0.4681\n",
            "Epoch 47/60\n",
            "188/188 [==============================] - 0s 396us/sample - loss: 0.1766 - acc: 0.9309 - val_loss: 1.0205 - val_acc: 0.5319\n",
            "Epoch 48/60\n",
            "188/188 [==============================] - 0s 431us/sample - loss: 0.1381 - acc: 0.9468 - val_loss: 1.0110 - val_acc: 0.5319\n",
            "Epoch 49/60\n",
            "188/188 [==============================] - 0s 411us/sample - loss: 0.1472 - acc: 0.9468 - val_loss: 1.1382 - val_acc: 0.4894\n",
            "Epoch 50/60\n",
            "188/188 [==============================] - 0s 405us/sample - loss: 0.1204 - acc: 0.9521 - val_loss: 1.1572 - val_acc: 0.5957\n",
            "Epoch 51/60\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.0987 - acc: 0.9681 - val_loss: 1.1439 - val_acc: 0.5106\n",
            "Epoch 52/60\n",
            "188/188 [==============================] - 0s 387us/sample - loss: 0.0955 - acc: 0.9734 - val_loss: 1.1671 - val_acc: 0.4894\n",
            "Epoch 53/60\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.0830 - acc: 0.9840 - val_loss: 1.1268 - val_acc: 0.4681\n",
            "Epoch 54/60\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.0752 - acc: 0.9787 - val_loss: 1.0223 - val_acc: 0.5745\n",
            "Epoch 55/60\n",
            "188/188 [==============================] - 0s 406us/sample - loss: 0.1172 - acc: 0.9734 - val_loss: 1.1866 - val_acc: 0.4681\n",
            "Epoch 56/60\n",
            "188/188 [==============================] - 0s 409us/sample - loss: 0.1411 - acc: 0.9362 - val_loss: 1.1373 - val_acc: 0.5532\n",
            "Epoch 57/60\n",
            "188/188 [==============================] - 0s 397us/sample - loss: 0.1458 - acc: 0.9468 - val_loss: 1.0237 - val_acc: 0.5319\n",
            "Epoch 58/60\n",
            "188/188 [==============================] - 0s 401us/sample - loss: 0.1567 - acc: 0.9521 - val_loss: 0.9771 - val_acc: 0.5319\n",
            "Epoch 59/60\n",
            "188/188 [==============================] - 0s 409us/sample - loss: 0.0985 - acc: 0.9734 - val_loss: 1.0060 - val_acc: 0.5532\n",
            "Epoch 60/60\n",
            "188/188 [==============================] - 0s 373us/sample - loss: 0.0639 - acc: 0.9787 - val_loss: 1.1086 - val_acc: 0.6170\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "47/47 [==============================] - 0s 263us/sample - loss: 2.2085 - acc: 0.4894\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 169us/sample - loss: 3.2394 - acc: 0.3454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.2393899372953325, 0.34537247]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoLbkQ004NHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3276fe81-217a-433a-88f9-891f3714465f"
      },
      "source": [
        "person_num = 7\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (185, 22, 1000)\n",
            "Training label shape for 1 person: (185,)\n",
            "Validation data shape for 1 person: (47, 22, 1000)\n",
            "Validation label shape for 1 person: (47,)\n",
            "Test data shape for 1 person: (50, 22, 1000)\n",
            "Test label shape for 1 person: (50,)\n",
            "Training data shape with slices: (185, 22, 600)\n",
            "Training label shape with slice: (185,)\n",
            "Validation data shape with slices: (47, 22, 600)\n",
            "Validation label shape with slice: (47,)\n",
            "Train on 185 samples, validate on 47 samples\n",
            "Epoch 1/60\n",
            "185/185 [==============================] - 1s 7ms/sample - loss: 3.3258 - acc: 0.2757 - val_loss: 1.9008 - val_acc: 0.3191\n",
            "Epoch 2/60\n",
            "185/185 [==============================] - 0s 416us/sample - loss: 2.1526 - acc: 0.2486 - val_loss: 1.9341 - val_acc: 0.3191\n",
            "Epoch 3/60\n",
            "185/185 [==============================] - 0s 369us/sample - loss: 1.6887 - acc: 0.3297 - val_loss: 1.9784 - val_acc: 0.2128\n",
            "Epoch 4/60\n",
            "185/185 [==============================] - 0s 439us/sample - loss: 1.8072 - acc: 0.2811 - val_loss: 2.7217 - val_acc: 0.3404\n",
            "Epoch 5/60\n",
            "185/185 [==============================] - 0s 422us/sample - loss: 1.6154 - acc: 0.3081 - val_loss: 2.0827 - val_acc: 0.2553\n",
            "Epoch 6/60\n",
            "185/185 [==============================] - 0s 408us/sample - loss: 1.6837 - acc: 0.2757 - val_loss: 1.7674 - val_acc: 0.3617\n",
            "Epoch 7/60\n",
            "185/185 [==============================] - 0s 394us/sample - loss: 1.4878 - acc: 0.4000 - val_loss: 1.7369 - val_acc: 0.3830\n",
            "Epoch 8/60\n",
            "185/185 [==============================] - 0s 386us/sample - loss: 1.4514 - acc: 0.3622 - val_loss: 1.8433 - val_acc: 0.2979\n",
            "Epoch 9/60\n",
            "185/185 [==============================] - 0s 372us/sample - loss: 1.5146 - acc: 0.3784 - val_loss: 1.5297 - val_acc: 0.2979\n",
            "Epoch 10/60\n",
            "185/185 [==============================] - 0s 394us/sample - loss: 1.4475 - acc: 0.3297 - val_loss: 1.6357 - val_acc: 0.3617\n",
            "Epoch 11/60\n",
            "185/185 [==============================] - 0s 405us/sample - loss: 1.4410 - acc: 0.3892 - val_loss: 1.5286 - val_acc: 0.2979\n",
            "Epoch 12/60\n",
            "185/185 [==============================] - 0s 397us/sample - loss: 1.3445 - acc: 0.4378 - val_loss: 1.4700 - val_acc: 0.2766\n",
            "Epoch 13/60\n",
            "185/185 [==============================] - 0s 396us/sample - loss: 1.3456 - acc: 0.4108 - val_loss: 1.4631 - val_acc: 0.2979\n",
            "Epoch 14/60\n",
            "185/185 [==============================] - 0s 398us/sample - loss: 1.3402 - acc: 0.4054 - val_loss: 1.4191 - val_acc: 0.3191\n",
            "Epoch 15/60\n",
            "185/185 [==============================] - 0s 388us/sample - loss: 1.2993 - acc: 0.4541 - val_loss: 1.4455 - val_acc: 0.2979\n",
            "Epoch 16/60\n",
            "185/185 [==============================] - 0s 427us/sample - loss: 1.2548 - acc: 0.4541 - val_loss: 1.3905 - val_acc: 0.2128\n",
            "Epoch 17/60\n",
            "185/185 [==============================] - 0s 484us/sample - loss: 1.2057 - acc: 0.4541 - val_loss: 1.3871 - val_acc: 0.3404\n",
            "Epoch 18/60\n",
            "185/185 [==============================] - 0s 426us/sample - loss: 1.2105 - acc: 0.4811 - val_loss: 1.3585 - val_acc: 0.2979\n",
            "Epoch 19/60\n",
            "185/185 [==============================] - 0s 401us/sample - loss: 1.0992 - acc: 0.5297 - val_loss: 1.3589 - val_acc: 0.2553\n",
            "Epoch 20/60\n",
            "185/185 [==============================] - 0s 442us/sample - loss: 1.1354 - acc: 0.5081 - val_loss: 1.3334 - val_acc: 0.2553\n",
            "Epoch 21/60\n",
            "185/185 [==============================] - 0s 392us/sample - loss: 1.0773 - acc: 0.5459 - val_loss: 1.3241 - val_acc: 0.2979\n",
            "Epoch 22/60\n",
            "185/185 [==============================] - 0s 393us/sample - loss: 0.9302 - acc: 0.6054 - val_loss: 1.3065 - val_acc: 0.3404\n",
            "Epoch 23/60\n",
            "185/185 [==============================] - 0s 403us/sample - loss: 0.9352 - acc: 0.6432 - val_loss: 1.3007 - val_acc: 0.2766\n",
            "Epoch 24/60\n",
            "185/185 [==============================] - 0s 398us/sample - loss: 0.9719 - acc: 0.5622 - val_loss: 1.2863 - val_acc: 0.3830\n",
            "Epoch 25/60\n",
            "185/185 [==============================] - 0s 404us/sample - loss: 0.9125 - acc: 0.6108 - val_loss: 1.3044 - val_acc: 0.3617\n",
            "Epoch 26/60\n",
            "185/185 [==============================] - 0s 429us/sample - loss: 0.7982 - acc: 0.6811 - val_loss: 1.2981 - val_acc: 0.4255\n",
            "Epoch 27/60\n",
            "185/185 [==============================] - 0s 409us/sample - loss: 0.7086 - acc: 0.7514 - val_loss: 1.2521 - val_acc: 0.3191\n",
            "Epoch 28/60\n",
            "185/185 [==============================] - 0s 401us/sample - loss: 0.6692 - acc: 0.7351 - val_loss: 1.2327 - val_acc: 0.4255\n",
            "Epoch 29/60\n",
            "185/185 [==============================] - 0s 402us/sample - loss: 0.6730 - acc: 0.7135 - val_loss: 1.2685 - val_acc: 0.4043\n",
            "Epoch 30/60\n",
            "185/185 [==============================] - 0s 408us/sample - loss: 0.6555 - acc: 0.7568 - val_loss: 1.2310 - val_acc: 0.5319\n",
            "Epoch 31/60\n",
            "185/185 [==============================] - 0s 421us/sample - loss: 0.4581 - acc: 0.8108 - val_loss: 1.2228 - val_acc: 0.4681\n",
            "Epoch 32/60\n",
            "185/185 [==============================] - 0s 401us/sample - loss: 0.4505 - acc: 0.8108 - val_loss: 1.2947 - val_acc: 0.4468\n",
            "Epoch 33/60\n",
            "185/185 [==============================] - 0s 377us/sample - loss: 0.3677 - acc: 0.8486 - val_loss: 1.2191 - val_acc: 0.4894\n",
            "Epoch 34/60\n",
            "185/185 [==============================] - 0s 408us/sample - loss: 0.2873 - acc: 0.9135 - val_loss: 1.2536 - val_acc: 0.4468\n",
            "Epoch 35/60\n",
            "185/185 [==============================] - 0s 451us/sample - loss: 0.2536 - acc: 0.9351 - val_loss: 1.2398 - val_acc: 0.5106\n",
            "Epoch 36/60\n",
            "185/185 [==============================] - 0s 440us/sample - loss: 0.2212 - acc: 0.9351 - val_loss: 1.2301 - val_acc: 0.5106\n",
            "Epoch 37/60\n",
            "185/185 [==============================] - 0s 456us/sample - loss: 0.2802 - acc: 0.9027 - val_loss: 1.2715 - val_acc: 0.4894\n",
            "Epoch 38/60\n",
            "185/185 [==============================] - 0s 444us/sample - loss: 0.2538 - acc: 0.8973 - val_loss: 1.3558 - val_acc: 0.4681\n",
            "Epoch 39/60\n",
            "185/185 [==============================] - 0s 415us/sample - loss: 0.3105 - acc: 0.8919 - val_loss: 1.2321 - val_acc: 0.4468\n",
            "Epoch 40/60\n",
            "185/185 [==============================] - 0s 422us/sample - loss: 0.1865 - acc: 0.9351 - val_loss: 1.2335 - val_acc: 0.5106\n",
            "Epoch 41/60\n",
            "185/185 [==============================] - 0s 446us/sample - loss: 0.1631 - acc: 0.9622 - val_loss: 1.2205 - val_acc: 0.5745\n",
            "Epoch 42/60\n",
            "185/185 [==============================] - 0s 438us/sample - loss: 0.1207 - acc: 0.9568 - val_loss: 1.2240 - val_acc: 0.5745\n",
            "Epoch 43/60\n",
            "185/185 [==============================] - 0s 433us/sample - loss: 0.1478 - acc: 0.9459 - val_loss: 1.3555 - val_acc: 0.5319\n",
            "Epoch 44/60\n",
            "185/185 [==============================] - 0s 417us/sample - loss: 0.2672 - acc: 0.9135 - val_loss: 1.4436 - val_acc: 0.4681\n",
            "Epoch 45/60\n",
            "185/185 [==============================] - 0s 423us/sample - loss: 0.2270 - acc: 0.9135 - val_loss: 1.3889 - val_acc: 0.5745\n",
            "Epoch 46/60\n",
            "185/185 [==============================] - 0s 431us/sample - loss: 0.1025 - acc: 0.9622 - val_loss: 1.2917 - val_acc: 0.5532\n",
            "Epoch 47/60\n",
            "185/185 [==============================] - 0s 419us/sample - loss: 0.1303 - acc: 0.9514 - val_loss: 1.4362 - val_acc: 0.5106\n",
            "Epoch 48/60\n",
            "185/185 [==============================] - 0s 401us/sample - loss: 0.1159 - acc: 0.9514 - val_loss: 1.4553 - val_acc: 0.4894\n",
            "Epoch 49/60\n",
            "185/185 [==============================] - 0s 405us/sample - loss: 0.0786 - acc: 0.9730 - val_loss: 1.3648 - val_acc: 0.4894\n",
            "Epoch 50/60\n",
            "185/185 [==============================] - 0s 402us/sample - loss: 0.0967 - acc: 0.9730 - val_loss: 1.3274 - val_acc: 0.5532\n",
            "Epoch 51/60\n",
            "185/185 [==============================] - 0s 393us/sample - loss: 0.0910 - acc: 0.9622 - val_loss: 1.3035 - val_acc: 0.5532\n",
            "Epoch 52/60\n",
            "185/185 [==============================] - 0s 410us/sample - loss: 0.0722 - acc: 0.9784 - val_loss: 1.4225 - val_acc: 0.4894\n",
            "Epoch 53/60\n",
            "185/185 [==============================] - 0s 380us/sample - loss: 0.0567 - acc: 0.9784 - val_loss: 1.4054 - val_acc: 0.4894\n",
            "Epoch 54/60\n",
            "185/185 [==============================] - 0s 419us/sample - loss: 0.0354 - acc: 0.9946 - val_loss: 1.3335 - val_acc: 0.5745\n",
            "Epoch 55/60\n",
            "185/185 [==============================] - 0s 417us/sample - loss: 0.0835 - acc: 0.9838 - val_loss: 1.4056 - val_acc: 0.5745\n",
            "Epoch 56/60\n",
            "185/185 [==============================] - 0s 384us/sample - loss: 0.0650 - acc: 0.9784 - val_loss: 1.7657 - val_acc: 0.5319\n",
            "Epoch 57/60\n",
            "185/185 [==============================] - 0s 384us/sample - loss: 0.1173 - acc: 0.9514 - val_loss: 1.5127 - val_acc: 0.5319\n",
            "Epoch 58/60\n",
            "185/185 [==============================] - 0s 404us/sample - loss: 0.1524 - acc: 0.9568 - val_loss: 1.4658 - val_acc: 0.5319\n",
            "Epoch 59/60\n",
            "185/185 [==============================] - 0s 379us/sample - loss: 0.0521 - acc: 0.9730 - val_loss: 1.5878 - val_acc: 0.4894\n",
            "Epoch 60/60\n",
            "185/185 [==============================] - 0s 397us/sample - loss: 0.0489 - acc: 0.9892 - val_loss: 1.6711 - val_acc: 0.4894\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "50/50 [==============================] - 0s 259us/sample - loss: 2.4284 - acc: 0.4800\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 175us/sample - loss: 2.6121 - acc: 0.3363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.612136176692713, 0.3363431]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pR0Unv720HI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17e6f98d-b901-4edd-d962-ad7a45ec3878"
      },
      "source": [
        "person_num = 8\n",
        "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
        "indices_test = np.where(person_test == person_num)[0]\n",
        "\n",
        "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
        "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
        "\n",
        "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
        "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
        "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
        "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
        "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
        "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
        "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
        "\n",
        "single_person_X_test = X_test[indices_test]\n",
        "single_person_y_test = y_test[indices_test]\n",
        "\n",
        "\n",
        "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
        "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
        "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
        "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
        "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
        "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))\n",
        "\n",
        "TIME_WINDOW = 600\n",
        "TIME_STRIDE = 1000\n",
        "\n",
        "# cut the slices\n",
        "X_train_slices, y_train_slices = sliding_window(single_person_X_train, \n",
        "                                                single_person_y_train, \n",
        "                                                time_window=TIME_WINDOW,  \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_valid_slices, y_valid_slices = sliding_window(single_person_X_valid, \n",
        "                                                single_person_y_valid, \n",
        "                                                time_window=TIME_WINDOW, \n",
        "                                                time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
        "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
        "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
        "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
        "\n",
        "deep_aug_model_600_005 = construct_augmented_deep_model(TIME_WINDOW)\n",
        "deep_aug_model_600_005.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "deep_aug_model_600_005.fit(X_train_slices, y_train_slices,\n",
        "                       validation_data = (X_valid_slices, y_valid_slices),\n",
        "                       epochs = 60)\n",
        "\n",
        "X_test_slices, y_test_slices = sliding_window(single_person_X_test, \n",
        "                                              single_person_y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "\n",
        "X_overall_test_slices, y_overall_test_slices = sliding_window(X_test, \n",
        "                                              y_test, \n",
        "                                              time_window=600, \n",
        "                                              time_stride=TIME_STRIDE)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Single Person test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_test_slices, y_test_slices)\n",
        "\n",
        "print(\"\\n\\n Now Evaluating on Entire test set\")\n",
        "\n",
        "deep_aug_model_600_005.evaluate(X_overall_test_slices, y_overall_test_slices)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data shape for 1 person: (184, 22, 1000)\n",
            "Training label shape for 1 person: (184,)\n",
            "Validation data shape for 1 person: (47, 22, 1000)\n",
            "Validation label shape for 1 person: (47,)\n",
            "Test data shape for 1 person: (47, 22, 1000)\n",
            "Test label shape for 1 person: (47,)\n",
            "Training data shape with slices: (184, 22, 600)\n",
            "Training label shape with slice: (184,)\n",
            "Validation data shape with slices: (47, 22, 600)\n",
            "Validation label shape with slice: (47,)\n",
            "Train on 184 samples, validate on 47 samples\n",
            "Epoch 1/60\n",
            "184/184 [==============================] - 1s 7ms/sample - loss: 2.9552 - acc: 0.2989 - val_loss: 1.8001 - val_acc: 0.2340\n",
            "Epoch 2/60\n",
            "184/184 [==============================] - 0s 371us/sample - loss: 1.9708 - acc: 0.2772 - val_loss: 1.4615 - val_acc: 0.2340\n",
            "Epoch 3/60\n",
            "184/184 [==============================] - 0s 377us/sample - loss: 1.5908 - acc: 0.2826 - val_loss: 1.2493 - val_acc: 0.3617\n",
            "Epoch 4/60\n",
            "184/184 [==============================] - 0s 375us/sample - loss: 1.4390 - acc: 0.3641 - val_loss: 2.0227 - val_acc: 0.2979\n",
            "Epoch 5/60\n",
            "184/184 [==============================] - 0s 389us/sample - loss: 1.1988 - acc: 0.4565 - val_loss: 1.6991 - val_acc: 0.3191\n",
            "Epoch 6/60\n",
            "184/184 [==============================] - 0s 396us/sample - loss: 1.1623 - acc: 0.4837 - val_loss: 1.4483 - val_acc: 0.3404\n",
            "Epoch 7/60\n",
            "184/184 [==============================] - 0s 417us/sample - loss: 1.0140 - acc: 0.5870 - val_loss: 1.6943 - val_acc: 0.3404\n",
            "Epoch 8/60\n",
            "184/184 [==============================] - 0s 404us/sample - loss: 1.1187 - acc: 0.5272 - val_loss: 1.3778 - val_acc: 0.3191\n",
            "Epoch 9/60\n",
            "184/184 [==============================] - 0s 432us/sample - loss: 1.1456 - acc: 0.5815 - val_loss: 1.5522 - val_acc: 0.3830\n",
            "Epoch 10/60\n",
            "184/184 [==============================] - 0s 402us/sample - loss: 0.9717 - acc: 0.6087 - val_loss: 1.5297 - val_acc: 0.4043\n",
            "Epoch 11/60\n",
            "184/184 [==============================] - 0s 401us/sample - loss: 0.9070 - acc: 0.6250 - val_loss: 1.3705 - val_acc: 0.4468\n",
            "Epoch 12/60\n",
            "184/184 [==============================] - 0s 378us/sample - loss: 0.7703 - acc: 0.6848 - val_loss: 1.2460 - val_acc: 0.5106\n",
            "Epoch 13/60\n",
            "184/184 [==============================] - 0s 385us/sample - loss: 0.7149 - acc: 0.7446 - val_loss: 1.1197 - val_acc: 0.5532\n",
            "Epoch 14/60\n",
            "184/184 [==============================] - 0s 375us/sample - loss: 0.6353 - acc: 0.7772 - val_loss: 1.1118 - val_acc: 0.5106\n",
            "Epoch 15/60\n",
            "184/184 [==============================] - 0s 404us/sample - loss: 0.5304 - acc: 0.8261 - val_loss: 0.8779 - val_acc: 0.6170\n",
            "Epoch 16/60\n",
            "184/184 [==============================] - 0s 379us/sample - loss: 0.4980 - acc: 0.7989 - val_loss: 1.0813 - val_acc: 0.5106\n",
            "Epoch 17/60\n",
            "184/184 [==============================] - 0s 404us/sample - loss: 0.5300 - acc: 0.8207 - val_loss: 0.9659 - val_acc: 0.5745\n",
            "Epoch 18/60\n",
            "184/184 [==============================] - 0s 394us/sample - loss: 0.3825 - acc: 0.8533 - val_loss: 0.7482 - val_acc: 0.7447\n",
            "Epoch 19/60\n",
            "184/184 [==============================] - 0s 401us/sample - loss: 0.4007 - acc: 0.8152 - val_loss: 1.0654 - val_acc: 0.5745\n",
            "Epoch 20/60\n",
            "184/184 [==============================] - 0s 386us/sample - loss: 0.4426 - acc: 0.8152 - val_loss: 0.9855 - val_acc: 0.6383\n",
            "Epoch 21/60\n",
            "184/184 [==============================] - 0s 394us/sample - loss: 0.3735 - acc: 0.8533 - val_loss: 0.8701 - val_acc: 0.6383\n",
            "Epoch 22/60\n",
            "184/184 [==============================] - 0s 430us/sample - loss: 0.2063 - acc: 0.9185 - val_loss: 0.8569 - val_acc: 0.6383\n",
            "Epoch 23/60\n",
            "184/184 [==============================] - 0s 388us/sample - loss: 0.1827 - acc: 0.9348 - val_loss: 0.8403 - val_acc: 0.5957\n",
            "Epoch 24/60\n",
            "184/184 [==============================] - 0s 363us/sample - loss: 0.2288 - acc: 0.9239 - val_loss: 0.8933 - val_acc: 0.6383\n",
            "Epoch 25/60\n",
            "184/184 [==============================] - 0s 385us/sample - loss: 0.1807 - acc: 0.9185 - val_loss: 0.9884 - val_acc: 0.5745\n",
            "Epoch 26/60\n",
            "184/184 [==============================] - 0s 388us/sample - loss: 0.1319 - acc: 0.9674 - val_loss: 0.9630 - val_acc: 0.5957\n",
            "Epoch 27/60\n",
            "184/184 [==============================] - 0s 376us/sample - loss: 0.1394 - acc: 0.9402 - val_loss: 1.0687 - val_acc: 0.5957\n",
            "Epoch 28/60\n",
            "184/184 [==============================] - 0s 392us/sample - loss: 0.1099 - acc: 0.9565 - val_loss: 1.3623 - val_acc: 0.5319\n",
            "Epoch 29/60\n",
            "184/184 [==============================] - 0s 379us/sample - loss: 0.0862 - acc: 0.9783 - val_loss: 1.1053 - val_acc: 0.6170\n",
            "Epoch 30/60\n",
            "184/184 [==============================] - 0s 473us/sample - loss: 0.0990 - acc: 0.9620 - val_loss: 1.0063 - val_acc: 0.5957\n",
            "Epoch 31/60\n",
            "184/184 [==============================] - 0s 408us/sample - loss: 0.1066 - acc: 0.9728 - val_loss: 1.0760 - val_acc: 0.6170\n",
            "Epoch 32/60\n",
            "184/184 [==============================] - 0s 443us/sample - loss: 0.0760 - acc: 0.9674 - val_loss: 1.1079 - val_acc: 0.5745\n",
            "Epoch 33/60\n",
            "184/184 [==============================] - 0s 420us/sample - loss: 0.0403 - acc: 0.9946 - val_loss: 1.4243 - val_acc: 0.5745\n",
            "Epoch 34/60\n",
            "184/184 [==============================] - 0s 428us/sample - loss: 0.0680 - acc: 0.9783 - val_loss: 1.0704 - val_acc: 0.5957\n",
            "Epoch 35/60\n",
            "184/184 [==============================] - 0s 438us/sample - loss: 0.0483 - acc: 0.9891 - val_loss: 1.3439 - val_acc: 0.5532\n",
            "Epoch 36/60\n",
            "184/184 [==============================] - 0s 407us/sample - loss: 0.0736 - acc: 0.9674 - val_loss: 1.8047 - val_acc: 0.4681\n",
            "Epoch 37/60\n",
            "184/184 [==============================] - 0s 403us/sample - loss: 0.0811 - acc: 0.9728 - val_loss: 1.7962 - val_acc: 0.4468\n",
            "Epoch 38/60\n",
            "184/184 [==============================] - 0s 402us/sample - loss: 0.1517 - acc: 0.9511 - val_loss: 1.1183 - val_acc: 0.6383\n",
            "Epoch 39/60\n",
            "184/184 [==============================] - 0s 421us/sample - loss: 0.0739 - acc: 0.9728 - val_loss: 1.0383 - val_acc: 0.6383\n",
            "Epoch 40/60\n",
            "184/184 [==============================] - 0s 408us/sample - loss: 0.0518 - acc: 0.9837 - val_loss: 0.7645 - val_acc: 0.6809\n",
            "Epoch 41/60\n",
            "184/184 [==============================] - 0s 419us/sample - loss: 0.0672 - acc: 0.9674 - val_loss: 1.0780 - val_acc: 0.6596\n",
            "Epoch 42/60\n",
            "184/184 [==============================] - 0s 404us/sample - loss: 0.0855 - acc: 0.9674 - val_loss: 0.9336 - val_acc: 0.7447\n",
            "Epoch 43/60\n",
            "184/184 [==============================] - 0s 395us/sample - loss: 0.0630 - acc: 0.9837 - val_loss: 0.8972 - val_acc: 0.6596\n",
            "Epoch 44/60\n",
            "184/184 [==============================] - 0s 419us/sample - loss: 0.0644 - acc: 0.9728 - val_loss: 0.8957 - val_acc: 0.7021\n",
            "Epoch 45/60\n",
            "184/184 [==============================] - 0s 386us/sample - loss: 0.0447 - acc: 0.9837 - val_loss: 1.2153 - val_acc: 0.6383\n",
            "Epoch 46/60\n",
            "184/184 [==============================] - 0s 399us/sample - loss: 0.0447 - acc: 0.9783 - val_loss: 1.5971 - val_acc: 0.5532\n",
            "Epoch 47/60\n",
            "184/184 [==============================] - 0s 383us/sample - loss: 0.0242 - acc: 0.9946 - val_loss: 1.1151 - val_acc: 0.6596\n",
            "Epoch 48/60\n",
            "184/184 [==============================] - 0s 419us/sample - loss: 0.0179 - acc: 0.9946 - val_loss: 1.4555 - val_acc: 0.5745\n",
            "Epoch 49/60\n",
            "184/184 [==============================] - 0s 375us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 1.6647 - val_acc: 0.5106\n",
            "Epoch 50/60\n",
            "184/184 [==============================] - 0s 397us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 1.4891 - val_acc: 0.5745\n",
            "Epoch 51/60\n",
            "184/184 [==============================] - 0s 402us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 1.3282 - val_acc: 0.6170\n",
            "Epoch 52/60\n",
            "184/184 [==============================] - 0s 392us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 1.3488 - val_acc: 0.5957\n",
            "Epoch 53/60\n",
            "184/184 [==============================] - 0s 375us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 1.6767 - val_acc: 0.5319\n",
            "Epoch 54/60\n",
            "184/184 [==============================] - 0s 374us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 1.8492 - val_acc: 0.4894\n",
            "Epoch 55/60\n",
            "184/184 [==============================] - 0s 412us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 1.5014 - val_acc: 0.5745\n",
            "Epoch 56/60\n",
            "184/184 [==============================] - 0s 414us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 1.4132 - val_acc: 0.5532\n",
            "Epoch 57/60\n",
            "184/184 [==============================] - 0s 402us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 1.8350 - val_acc: 0.5106\n",
            "Epoch 58/60\n",
            "184/184 [==============================] - 0s 399us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 2.2302 - val_acc: 0.4255\n",
            "Epoch 59/60\n",
            "184/184 [==============================] - 0s 401us/sample - loss: 0.0207 - acc: 0.9891 - val_loss: 2.0057 - val_acc: 0.4894\n",
            "Epoch 60/60\n",
            "184/184 [==============================] - 0s 457us/sample - loss: 0.0129 - acc: 0.9946 - val_loss: 1.9418 - val_acc: 0.5319\n",
            "\n",
            "\n",
            " Now Evaluating on Single Person test set\n",
            "47/47 [==============================] - 0s 305us/sample - loss: 2.7229 - acc: 0.4894\n",
            "\n",
            "\n",
            " Now Evaluating on Entire test set\n",
            "443/443 [==============================] - 0s 177us/sample - loss: 8.6540 - acc: 0.2777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8.653981265849508, 0.27765238]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpzNJgYj3A8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}