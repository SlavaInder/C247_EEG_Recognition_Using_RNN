{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This architecture was described in \"Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG\", by R. T. Schirrmeister et al, 2018. In this notebook we conduct experiments showing dependency between accuracy and the number of timestamps in a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# import tf\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# import os functions\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./EEG_data/X_test.npy\")\n",
    "y_test = np.load(\"./EEG_data/y_test.npy\") - 769\n",
    "person_train_valid = np.load(\"./EEG_data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./EEG_data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./EEG_data/y_train_valid.npy\") - 769\n",
    "person_test = np.load(\"./EEG_data/person_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid  shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"training/Valid data shape: {}\".format(X_train_valid.shape))       # training data of many persons\n",
    "print(\"Test data shape: {}\".format(X_test.shape))                        # test data of many persons\n",
    "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))     # training labels of many persons\n",
    "print(\"Test target shape: {}\".format(y_test.shape))                      # test labels of many persons\n",
    "print(\"Person train/valid  shape: {}\".format(person_train_valid.shape))  # which person correspond to the trail in test set\n",
    "print(\"Person test shape: {}\".format(person_test.shape))                 # which person correspond to the trail in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1692, 22, 1000)\n",
      "Training label shape: (1692,)\n",
      "Validation data shape: (423, 22, 1000)\n",
      "Validation label shape: (423,)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Test label shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(X_train_valid.shape[0])\n",
    "num_train = int(0.8 * X_train_valid.shape[0])\n",
    "num_valid = X_train_valid.shape[0] - num_train\n",
    "X_train =  X_train_valid[perm[0:num_train]]\n",
    "y_train =  y_train_valid[perm[0:num_train]]\n",
    "X_valid = X_train_valid[perm[num_train: ]]\n",
    "y_valid = y_train_valid[perm[num_train: ]]\n",
    "\n",
    "\n",
    "print(\"Training data shape: {}\".format(X_train.shape))\n",
    "print(\"Training label shape: {}\".format(y_train.shape))\n",
    "print(\"Validation data shape: {}\".format(X_valid.shape))\n",
    "print(\"Validation label shape: {}\".format(y_valid.shape))\n",
    "print(\"Test data shape: {}\".format(X_test.shape))\n",
    "print(\"Test label shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(X_arr, y_arr, time_window=100, time_step=1, time_stride=1):\n",
    "    temp_x = np.moveaxis(X_arr, 2, 0)\n",
    "    temp_x = temp_x.astype(np.float32)\n",
    "    buff = []\n",
    "    \n",
    "    num_slices = (len(temp_x)-time_window*time_step) // time_stride + 1\n",
    "    \n",
    "    # get time slices for data\n",
    "    for i in range(num_slices):\n",
    "        buff.append(temp_x[i*time_stride:i*time_stride + time_window*time_step:time_step])\n",
    "        buff[i] = np.moveaxis(buff[i], 0, 2)\n",
    "        # uncomment this if additional dimension is needed\n",
    "        # buff[i] = buff[i].reshape(1, buff[i].shape[0], buff[i].shape[1], buff[i].shape[2])\n",
    "        \n",
    "    temp_x = np.concatenate(buff)\n",
    "        \n",
    "    # get time slice for labels\n",
    "    temp_y = np.ones((X_arr.shape[0],num_slices))\n",
    "    \n",
    "    for i in range(len(y_arr)):\n",
    "        temp_y[i] = temp_y[i] * y_arr[i]\n",
    "        \n",
    "    temp_y = temp_y.reshape((-1))\n",
    "    \n",
    "    return temp_x, temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: shallow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we show that:\n",
    "1. shallow model can achieve 61% of validation accuracy given samples with 1000 timestamps;\n",
    "2. shallow model achieves peak validation accuracy after being trained for 12 epochs, after which it starts to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ksquare(x):\n",
    "    return K.pow(x, 2)\n",
    "\n",
    "def Klog(x):\n",
    "    return K.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_shallow_model(TIME_WINDOW):\n",
    "    # input\n",
    "    shallow_input = layers.Input(shape=(22, TIME_WINDOW))\n",
    "\n",
    "    # conv accross time domain\n",
    "    r1 = layers.Reshape((22, TIME_WINDOW, 1))(shallow_input)\n",
    "    c1 = layers.Conv2D(40, (1, 25), strides=(1, 1), activation=\"elu\")(r1)\n",
    "    new_size = TIME_WINDOW - 25 + 1\n",
    "    t1 = tf.keras.layers.Permute((2, 3, 1))(c1)\n",
    "    \n",
    "    \n",
    "    # conv accross time domain\n",
    "    r2 = layers.Reshape((new_size, 40*22, 1))(t1)\n",
    "    c2 = layers.Conv2D(40, (1, 40*22), strides=(1, 1), activation=\"elu\")(r2)\n",
    "\n",
    "    sq1 = layers.Activation(Ksquare)(c2)\n",
    "    r3 = layers.Reshape((new_size, 40, 1))(sq1)\n",
    "    apool1 = layers.AveragePooling2D(pool_size=(75, 1), strides=(15, 1))(r3)\n",
    "\n",
    "    log1 = layers.Activation(Klog)(apool1)\n",
    "    f1 = layers.Flatten()(log1)\n",
    "\n",
    "    # output\n",
    "    shallow_output = layers.Dense(4, activation=\"softmax\")(f1)\n",
    "    \n",
    "    return keras.Model(inputs = shallow_input, outputs = shallow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000 = construct_shallow_model(1000)\n",
    "shallow_model_1000.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 22, 1000)]        0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 22, 1000, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 976, 40)       1040      \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 976, 40, 22)       0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 976, 880, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 976, 1, 40)        35240     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 976, 1, 40)        0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 976, 40, 1)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2440)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 9764      \n",
      "=================================================================\n",
      "Total params: 46,044\n",
      "Trainable params: 46,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shallow_model_1000.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.8517 - acc: 0.3047\n",
      "Epoch 00001: val_loss improved from inf to 1.43534, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 1.8460 - acc: 0.3026 - val_loss: 1.4353 - val_acc: 0.2908\n",
      "Epoch 2/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2931 - acc: 0.4032\n",
      "Epoch 00002: val_loss improved from 1.43534 to 1.34584, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.2937 - acc: 0.4031 - val_loss: 1.3458 - val_acc: 0.3546\n",
      "Epoch 3/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1751 - acc: 0.4880\n",
      "Epoch 00003: val_loss improved from 1.34584 to 1.31797, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.1764 - acc: 0.4864 - val_loss: 1.3180 - val_acc: 0.4113\n",
      "Epoch 4/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0885 - acc: 0.5409\n",
      "Epoch 00004: val_loss improved from 1.31797 to 1.27002, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.0924 - acc: 0.5390 - val_loss: 1.2700 - val_acc: 0.4397\n",
      "Epoch 5/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9902 - acc: 0.6022\n",
      "Epoch 00005: val_loss improved from 1.27002 to 1.21522, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.9884 - acc: 0.6022 - val_loss: 1.2152 - val_acc: 0.4657\n",
      "Epoch 6/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8812 - acc: 0.6538\n",
      "Epoch 00006: val_loss did not improve from 1.21522\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.8813 - acc: 0.6531 - val_loss: 1.2206 - val_acc: 0.4894\n",
      "Epoch 7/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7885 - acc: 0.6965\n",
      "Epoch 00007: val_loss improved from 1.21522 to 1.10676, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.7876 - acc: 0.6974 - val_loss: 1.1068 - val_acc: 0.5272\n",
      "Epoch 8/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7147 - acc: 0.7320\n",
      "Epoch 00008: val_loss did not improve from 1.10676\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.7184 - acc: 0.7293 - val_loss: 1.1545 - val_acc: 0.5414\n",
      "Epoch 9/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6345 - acc: 0.7770\n",
      "Epoch 00009: val_loss improved from 1.10676 to 1.05534, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.6351 - acc: 0.7760 - val_loss: 1.0553 - val_acc: 0.5887\n",
      "Epoch 10/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8089\n",
      "Epoch 00010: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.5418 - acc: 0.8097 - val_loss: 1.1351 - val_acc: 0.5697\n",
      "Epoch 11/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8359\n",
      "Epoch 00011: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.5006 - acc: 0.8316 - val_loss: 1.0984 - val_acc: 0.6123\n",
      "Epoch 12/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.8227\n",
      "Epoch 00012: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.4915 - acc: 0.8233 - val_loss: 1.0746 - val_acc: 0.6052\n",
      "Epoch 13/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8654\n",
      "Epoch 00013: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.4126 - acc: 0.8635 - val_loss: 1.1003 - val_acc: 0.5816\n",
      "Epoch 14/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.8990\n",
      "Epoch 00014: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.3470 - acc: 0.8983 - val_loss: 1.1358 - val_acc: 0.6028\n",
      "Epoch 15/15\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3036 - acc: 0.9062\n",
      "Epoch 00015: val_loss did not improve from 1.05534\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.3039 - acc: 0.9060 - val_loss: 1.1417 - val_acc: 0.5934\n"
     ]
    }
   ],
   "source": [
    "shallow_model_loss_hist = shallow_model_1000.fit(X_train, y_train,\n",
    "                                                 validation_data = (X_valid, y_valid),\n",
    "                                                 epochs = 15,\n",
    "                                                 callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1db00327d68>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = shallow_model_loss_hist.history\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist['acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: shallow model with normilized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we shaow that data normalization does not help to improve validation accuracy. For the following experiment with shallow model, we do not try to normilize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normilize the data USING ONLY TRAIN DATA MEAN AND STANDARD DEVIATION\n",
    "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_valid_norm = (X_valid - np.mean(X_train))/np.std(X_train)\n",
    "X_test_norm = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000_norm = construct_shallow_model(1000)\n",
    "shallow_model_1000_norm.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000_norm',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/15\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 2.7574 - acc: 0.2683 - val_loss: 1.5336 - val_acc: 0.2931\n",
      "Epoch 2/15\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.3980 - acc: 0.3387 - val_loss: 1.4137 - val_acc: 0.3215\n",
      "Epoch 3/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.3183 - acc: 0.3818 - val_loss: 1.3911 - val_acc: 0.3522\n",
      "Epoch 4/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.2948 - acc: 0.4072 - val_loss: 1.3900 - val_acc: 0.3357\n",
      "Epoch 5/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.2434 - acc: 0.4297 - val_loss: 1.3935 - val_acc: 0.3522\n",
      "Epoch 6/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.2194 - acc: 0.4527 - val_loss: 1.3943 - val_acc: 0.3593\n",
      "Epoch 7/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.1908 - acc: 0.4740 - val_loss: 1.4091 - val_acc: 0.3593\n",
      "Epoch 8/15\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 1.1466 - acc: 0.5148 - val_loss: 1.3149 - val_acc: 0.4137\n",
      "Epoch 9/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.0923 - acc: 0.5390 - val_loss: 1.2916 - val_acc: 0.4468\n",
      "Epoch 10/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.0504 - acc: 0.5591 - val_loss: 1.2500 - val_acc: 0.4657\n",
      "Epoch 11/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 1.0073 - acc: 0.5904 - val_loss: 1.2487 - val_acc: 0.4823\n",
      "Epoch 12/15\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.9397 - acc: 0.6147 - val_loss: 1.1815 - val_acc: 0.5035\n",
      "Epoch 13/15\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.8873 - acc: 0.6395 - val_loss: 1.1975 - val_acc: 0.4941\n",
      "Epoch 14/15\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.8384 - acc: 0.6566 - val_loss: 1.2053 - val_acc: 0.5035\n",
      "Epoch 15/15\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.8112 - acc: 0.6720 - val_loss: 1.1614 - val_acc: 0.5272\n"
     ]
    }
   ],
   "source": [
    "shallow_model_1000_norm.fit(X_train_norm, y_train,\n",
    "                            validation_data = (X_valid_norm, y_valid),\n",
    "                            epochs = 15,\n",
    "                            callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.7886 - acc: 0.6814 - val_loss: 1.1313 - val_acc: 0.5508\n",
      "Epoch 2/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.7274 - acc: 0.7281 - val_loss: 1.1775 - val_acc: 0.5366\n",
      "Epoch 3/10\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.6945 - acc: 0.7364 - val_loss: 1.1211 - val_acc: 0.5437\n",
      "Epoch 4/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.6469 - acc: 0.7571 - val_loss: 1.0982 - val_acc: 0.5579\n",
      "Epoch 5/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.6145 - acc: 0.7707 - val_loss: 1.0945 - val_acc: 0.5485\n",
      "Epoch 6/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.5804 - acc: 0.7807 - val_loss: 1.1278 - val_acc: 0.5650\n",
      "Epoch 7/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.5631 - acc: 0.7837 - val_loss: 1.0588 - val_acc: 0.5768\n",
      "Epoch 8/10\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.5101 - acc: 0.8251 - val_loss: 1.0640 - val_acc: 0.5603\n",
      "Epoch 9/10\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.4811 - acc: 0.8316 - val_loss: 1.1080 - val_acc: 0.5816\n",
      "Epoch 10/10\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.4320 - acc: 0.8576 - val_loss: 1.1087 - val_acc: 0.5579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db0278f710>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_model_1000_norm.fit(X_train_norm, y_train,\n",
    "                            validation_data = (X_valid_norm, y_valid),\n",
    "                            epochs = 10,\n",
    "                            callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: shallow model - accuracy vs number of timestamps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 300)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 300)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.5946 - acc: 0.2867\n",
      "Epoch 00001: val_loss improved from inf to 1.36080, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 1.5923 - acc: 0.2866 - val_loss: 1.3608 - val_acc: 0.3546\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.3122 - acc: 0.3924\n",
      "Epoch 00002: val_loss did not improve from 1.36080\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 1.3115 - acc: 0.3948 - val_loss: 1.3750 - val_acc: 0.3215\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2518 - acc: 0.4399\n",
      "Epoch 00003: val_loss improved from 1.36080 to 1.21479, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 1.2534 - acc: 0.4397 - val_loss: 1.2148 - val_acc: 0.4515\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1736 - acc: 0.4880\n",
      "Epoch 00004: val_loss improved from 1.21479 to 1.19543, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 1.1693 - acc: 0.4905 - val_loss: 1.1954 - val_acc: 0.4799\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1093 - acc: 0.5186\n",
      "Epoch 00005: val_loss improved from 1.19543 to 1.10414, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 1.1064 - acc: 0.5213 - val_loss: 1.1041 - val_acc: 0.5343\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0517 - acc: 0.5613\n",
      "Epoch 00006: val_loss did not improve from 1.10414\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 1.0535 - acc: 0.5603 - val_loss: 1.1862 - val_acc: 0.4823\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0408 - acc: 0.5523\n",
      "Epoch 00007: val_loss did not improve from 1.10414\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 1.0392 - acc: 0.5532 - val_loss: 1.1051 - val_acc: 0.5366\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9622 - acc: 0.6190\n",
      "Epoch 00008: val_loss improved from 1.10414 to 1.09505, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.9639 - acc: 0.6182 - val_loss: 1.0951 - val_acc: 0.5461\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8967 - acc: 0.6304\n",
      "Epoch 00009: val_loss improved from 1.09505 to 1.03937, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 0.8967 - acc: 0.6312 - val_loss: 1.0394 - val_acc: 0.5792\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9157 - acc: 0.6238\n",
      "Epoch 00010: val_loss did not improve from 1.03937\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.9179 - acc: 0.6223 - val_loss: 1.0670 - val_acc: 0.5508\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8110 - acc: 0.6839\n",
      "Epoch 00011: val_loss improved from 1.03937 to 1.02618, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 0.8122 - acc: 0.6832 - val_loss: 1.0262 - val_acc: 0.5957\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7614 - acc: 0.6971\n",
      "Epoch 00012: val_loss improved from 1.02618 to 0.99774, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 0.7641 - acc: 0.6956 - val_loss: 0.9977 - val_acc: 0.6028\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.7175\n",
      "Epoch 00013: val_loss did not improve from 0.99774\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.7521 - acc: 0.7193 - val_loss: 1.0816 - val_acc: 0.5839\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6853 - acc: 0.7392\n",
      "Epoch 00014: val_loss did not improve from 0.99774\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.6861 - acc: 0.7400 - val_loss: 1.0243 - val_acc: 0.5887\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6781 - acc: 0.7536\n",
      "Epoch 00015: val_loss improved from 0.99774 to 0.96790, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300\\assets\n",
      "1692/1692 [==============================] - 7s 4ms/sample - loss: 0.6782 - acc: 0.7524 - val_loss: 0.9679 - val_acc: 0.6288\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.7740\n",
      "Epoch 00016: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.6336 - acc: 0.7730 - val_loss: 1.0385 - val_acc: 0.5863\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6122 - acc: 0.7758\n",
      "Epoch 00017: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.6135 - acc: 0.7748 - val_loss: 1.0576 - val_acc: 0.5957\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.7770\n",
      "Epoch 00018: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.5878 - acc: 0.7772 - val_loss: 0.9749 - val_acc: 0.6454\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5553 - acc: 0.7981\n",
      "Epoch 00019: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.5575 - acc: 0.7967 - val_loss: 1.0056 - val_acc: 0.6336\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5038 - acc: 0.8227\n",
      "Epoch 00020: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.5020 - acc: 0.8239 - val_loss: 1.0062 - val_acc: 0.6194\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5071 - acc: 0.8203\n",
      "Epoch 00021: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.5066 - acc: 0.8209 - val_loss: 1.0435 - val_acc: 0.6170\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.8474\n",
      "Epoch 00022: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.4471 - acc: 0.8457 - val_loss: 1.0817 - val_acc: 0.5839\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8552\n",
      "Epoch 00023: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 4ms/sample - loss: 0.4326 - acc: 0.8546 - val_loss: 1.1317 - val_acc: 0.5910\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8678\n",
      "Epoch 00024: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.4071 - acc: 0.8652 - val_loss: 1.0714 - val_acc: 0.6028\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8900\n",
      "Epoch 00025: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.3512 - acc: 0.8907 - val_loss: 1.0333 - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.9117\n",
      "Epoch 00026: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.3133 - acc: 0.9131 - val_loss: 1.1607 - val_acc: 0.5697\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9183\n",
      "Epoch 00027: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.3091 - acc: 0.9161 - val_loss: 1.0767 - val_acc: 0.6123\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2732 - acc: 0.9303\n",
      "Epoch 00028: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.2750 - acc: 0.9285 - val_loss: 1.2377 - val_acc: 0.6147\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2586 - acc: 0.9273\n",
      "Epoch 00029: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.2627 - acc: 0.9255 - val_loss: 1.1244 - val_acc: 0.6147\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.9327\n",
      "Epoch 00030: val_loss did not improve from 0.96790\n",
      "1692/1692 [==============================] - 6s 3ms/sample - loss: 0.2482 - acc: 0.9320 - val_loss: 1.1122 - val_acc: 0.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db068ab080>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 300\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_300 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_300.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_300.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 500)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 500)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.6477 - acc: 0.3221\n",
      "Epoch 00001: val_loss improved from inf to 1.38288, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 1.6453 - acc: 0.3203 - val_loss: 1.3829 - val_acc: 0.3759\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2595 - acc: 0.4309\n",
      "Epoch 00002: val_loss improved from 1.38288 to 1.25625, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 1.2624 - acc: 0.4291 - val_loss: 1.2563 - val_acc: 0.4303\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1486 - acc: 0.5096\n",
      "Epoch 00003: val_loss improved from 1.25625 to 1.20976, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 1.1500 - acc: 0.5089 - val_loss: 1.2098 - val_acc: 0.4728\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0565 - acc: 0.5643\n",
      "Epoch 00004: val_loss improved from 1.20976 to 1.17008, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 11s 6ms/sample - loss: 1.0592 - acc: 0.5609 - val_loss: 1.1701 - val_acc: 0.4775\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9719 - acc: 0.5956\n",
      "Epoch 00005: val_loss improved from 1.17008 to 1.08097, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 0.9763 - acc: 0.5928 - val_loss: 1.0810 - val_acc: 0.5650\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9124 - acc: 0.6286\n",
      "Epoch 00006: val_loss did not improve from 1.08097\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.9105 - acc: 0.6300 - val_loss: 1.1528 - val_acc: 0.5272\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8661 - acc: 0.6611\n",
      "Epoch 00007: val_loss improved from 1.08097 to 1.05516, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.8633 - acc: 0.6625 - val_loss: 1.0552 - val_acc: 0.5556\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8193 - acc: 0.6803\n",
      "Epoch 00008: val_loss did not improve from 1.05516\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.8177 - acc: 0.6809 - val_loss: 1.0739 - val_acc: 0.5792\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7549 - acc: 0.7109\n",
      "Epoch 00009: val_loss improved from 1.05516 to 0.97721, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.7536 - acc: 0.7104 - val_loss: 0.9772 - val_acc: 0.6028\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6795 - acc: 0.7620\n",
      "Epoch 00010: val_loss improved from 0.97721 to 0.94221, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500\\assets\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.6855 - acc: 0.7589 - val_loss: 0.9422 - val_acc: 0.6241\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.7722\n",
      "Epoch 00011: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.6235 - acc: 0.7719 - val_loss: 1.0487 - val_acc: 0.5603\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6460 - acc: 0.7542\n",
      "Epoch 00012: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.6465 - acc: 0.7547 - val_loss: 0.9859 - val_acc: 0.5934\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.7891\n",
      "Epoch 00013: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.5761 - acc: 0.7890 - val_loss: 0.9556 - val_acc: 0.6076\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4983 - acc: 0.8257\n",
      "Epoch 00014: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.4978 - acc: 0.8257 - val_loss: 0.9661 - val_acc: 0.6076\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4793 - acc: 0.8341\n",
      "Epoch 00015: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.4802 - acc: 0.8345 - val_loss: 0.9744 - val_acc: 0.6265\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4388 - acc: 0.8558\n",
      "Epoch 00016: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.4375 - acc: 0.8564 - val_loss: 1.0621 - val_acc: 0.5934\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8726\n",
      "Epoch 00017: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.3958 - acc: 0.8723 - val_loss: 1.0166 - val_acc: 0.5981\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8804\n",
      "Epoch 00018: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.3611 - acc: 0.8824 - val_loss: 1.0002 - val_acc: 0.6194\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3524 - acc: 0.8870\n",
      "Epoch 00019: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.3523 - acc: 0.8865 - val_loss: 1.0474 - val_acc: 0.6359\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2899 - acc: 0.9249\n",
      "Epoch 00020: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.2900 - acc: 0.9255 - val_loss: 1.0269 - val_acc: 0.6454\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9465\n",
      "Epoch 00021: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.2373 - acc: 0.9450 - val_loss: 1.0226 - val_acc: 0.6265\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9417\n",
      "Epoch 00022: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.2304 - acc: 0.9421 - val_loss: 1.0711 - val_acc: 0.6217\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9567\n",
      "Epoch 00023: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.2003 - acc: 0.9569 - val_loss: 1.1818 - val_acc: 0.6052\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9561\n",
      "Epoch 00024: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.1905 - acc: 0.9563 - val_loss: 1.1285 - val_acc: 0.6123\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9663\n",
      "Epoch 00025: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.1605 - acc: 0.9663 - val_loss: 1.1542 - val_acc: 0.6123\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9760\n",
      "Epoch 00026: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.1402 - acc: 0.9752 - val_loss: 1.1916 - val_acc: 0.6052\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9772\n",
      "Epoch 00027: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.1301 - acc: 0.9775 - val_loss: 1.2355 - val_acc: 0.5887\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9838\n",
      "Epoch 00028: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.1108 - acc: 0.9835 - val_loss: 1.1930 - val_acc: 0.6123\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9874\n",
      "Epoch 00029: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.0992 - acc: 0.9876 - val_loss: 1.2647 - val_acc: 0.5981\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9886\n",
      "Epoch 00030: val_loss did not improve from 0.94221\n",
      "1692/1692 [==============================] - 10s 6ms/sample - loss: 0.0869 - acc: 0.9888 - val_loss: 1.2320 - val_acc: 0.6241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db035a7d30>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 500\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_500 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_500.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_500.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 600)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 600)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.7909 - acc: 0.3005\n",
      "Epoch 00001: val_loss improved from inf to 1.41949, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 1.7862 - acc: 0.3020 - val_loss: 1.4195 - val_acc: 0.3168\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2718 - acc: 0.4159\n",
      "Epoch 00002: val_loss improved from 1.41949 to 1.34799, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 1.2738 - acc: 0.4161 - val_loss: 1.3480 - val_acc: 0.3806\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.4892\n",
      "Epoch 00003: val_loss improved from 1.34799 to 1.29477, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 1.1734 - acc: 0.4888 - val_loss: 1.2948 - val_acc: 0.4113\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0647 - acc: 0.5475\n",
      "Epoch 00004: val_loss improved from 1.29477 to 1.26219, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 1.0651 - acc: 0.5473 - val_loss: 1.2622 - val_acc: 0.4397\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9846 - acc: 0.5895\n",
      "Epoch 00005: val_loss improved from 1.26219 to 1.17961, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.9851 - acc: 0.5887 - val_loss: 1.1796 - val_acc: 0.4799\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9101 - acc: 0.6256\n",
      "Epoch 00006: val_loss improved from 1.17961 to 1.11525, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.9110 - acc: 0.6259 - val_loss: 1.1152 - val_acc: 0.5485\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8563 - acc: 0.6635\n",
      "Epoch 00007: val_loss did not improve from 1.11525\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.8551 - acc: 0.6643 - val_loss: 1.1520 - val_acc: 0.5083\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8131 - acc: 0.6809\n",
      "Epoch 00008: val_loss did not improve from 1.11525\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.8133 - acc: 0.6814 - val_loss: 1.1250 - val_acc: 0.5319\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7244 - acc: 0.7332\n",
      "Epoch 00009: val_loss improved from 1.11525 to 1.08751, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.7301 - acc: 0.7305 - val_loss: 1.0875 - val_acc: 0.5721\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6666 - acc: 0.7560\n",
      "Epoch 00010: val_loss improved from 1.08751 to 1.06806, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.6653 - acc: 0.7571 - val_loss: 1.0681 - val_acc: 0.5461\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6325 - acc: 0.7680\n",
      "Epoch 00011: val_loss did not improve from 1.06806\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.6290 - acc: 0.7695 - val_loss: 1.0844 - val_acc: 0.5745\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5759 - acc: 0.8005\n",
      "Epoch 00012: val_loss improved from 1.06806 to 1.06134, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.5744 - acc: 0.8002 - val_loss: 1.0613 - val_acc: 0.5839\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5073 - acc: 0.8245\n",
      "Epoch 00013: val_loss improved from 1.06134 to 1.04738, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600\\assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.5087 - acc: 0.8239 - val_loss: 1.0474 - val_acc: 0.6028\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4513 - acc: 0.8401\n",
      "Epoch 00014: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.4511 - acc: 0.8398 - val_loss: 1.0713 - val_acc: 0.6052\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.8221\n",
      "Epoch 00015: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.4873 - acc: 0.8215 - val_loss: 1.0876 - val_acc: 0.5768\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8834\n",
      "Epoch 00016: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 0.3897 - acc: 0.8836 - val_loss: 1.0995 - val_acc: 0.5839\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3659 - acc: 0.8810\n",
      "Epoch 00017: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.3649 - acc: 0.8818 - val_loss: 1.0777 - val_acc: 0.6028\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3070 - acc: 0.9075\n",
      "Epoch 00018: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.3085 - acc: 0.9066 - val_loss: 1.1111 - val_acc: 0.6005\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9062\n",
      "Epoch 00019: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.2950 - acc: 0.9043 - val_loss: 1.3003 - val_acc: 0.5768\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9231\n",
      "Epoch 00020: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.2745 - acc: 0.9232 - val_loss: 1.2291 - val_acc: 0.5910\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9411\n",
      "Epoch 00021: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.2131 - acc: 0.9409 - val_loss: 1.2672 - val_acc: 0.5721\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9519\n",
      "Epoch 00022: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.1952 - acc: 0.9521 - val_loss: 1.1835 - val_acc: 0.5981\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9706\n",
      "Epoch 00023: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.1603 - acc: 0.9699 - val_loss: 1.2429 - val_acc: 0.5839\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9688\n",
      "Epoch 00024: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.1516 - acc: 0.9687 - val_loss: 1.2550 - val_acc: 0.5816\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9778\n",
      "Epoch 00025: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 0.1307 - acc: 0.9775 - val_loss: 1.3027 - val_acc: 0.5887\n",
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9760\n",
      "Epoch 00026: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.1223 - acc: 0.9758 - val_loss: 1.3528 - val_acc: 0.5934\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9868\n",
      "Epoch 00027: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 0.0985 - acc: 0.9870 - val_loss: 1.3053 - val_acc: 0.6147\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9898\n",
      "Epoch 00028: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.0882 - acc: 0.9894 - val_loss: 1.3739 - val_acc: 0.6099\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9850\n",
      "Epoch 00029: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.0933 - acc: 0.9846 - val_loss: 1.3512 - val_acc: 0.6052\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9940\n",
      "Epoch 00030: val_loss did not improve from 1.04738\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.0684 - acc: 0.9941 - val_loss: 1.3889 - val_acc: 0.6052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db035bb828>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 600\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_600 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_600.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_600.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 700)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 700)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.6697 - acc: 0.3011\n",
      "Epoch 00001: val_loss improved from inf to 1.37731, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 16s 9ms/sample - loss: 1.6664 - acc: 0.2996 - val_loss: 1.3773 - val_acc: 0.3286\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2785 - acc: 0.4050\n",
      "Epoch 00002: val_loss improved from 1.37731 to 1.31116, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 1.2786 - acc: 0.4060 - val_loss: 1.3112 - val_acc: 0.3830\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.4976\n",
      "Epoch 00003: val_loss improved from 1.31116 to 1.25544, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 1.1678 - acc: 0.4988 - val_loss: 1.2554 - val_acc: 0.4350\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0676 - acc: 0.5487\n",
      "Epoch 00004: val_loss improved from 1.25544 to 1.20076, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 1.0692 - acc: 0.5485 - val_loss: 1.2008 - val_acc: 0.4634\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9525 - acc: 0.6136\n",
      "Epoch 00005: val_loss improved from 1.20076 to 1.10691, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.9527 - acc: 0.6123 - val_loss: 1.1069 - val_acc: 0.5437\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8703 - acc: 0.6490\n",
      "Epoch 00006: val_loss improved from 1.10691 to 1.03130, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.8697 - acc: 0.6495 - val_loss: 1.0313 - val_acc: 0.5650\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7965 - acc: 0.6725\n",
      "Epoch 00007: val_loss did not improve from 1.03130\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.8004 - acc: 0.6714 - val_loss: 1.0709 - val_acc: 0.5839\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7510 - acc: 0.7085\n",
      "Epoch 00008: val_loss did not improve from 1.03130\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.7482 - acc: 0.7104 - val_loss: 1.0474 - val_acc: 0.5721\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6450 - acc: 0.7662\n",
      "Epoch 00009: val_loss did not improve from 1.03130\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.6438 - acc: 0.7660 - val_loss: 1.0317 - val_acc: 0.5910\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5871 - acc: 0.7831\n",
      "Epoch 00010: val_loss improved from 1.03130 to 1.01957, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700\\assets\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.5884 - acc: 0.7831 - val_loss: 1.0196 - val_acc: 0.5768\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5522 - acc: 0.7903\n",
      "Epoch 00011: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.5515 - acc: 0.7896 - val_loss: 1.0372 - val_acc: 0.5839\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.8311\n",
      "Epoch 00012: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.4670 - acc: 0.8316 - val_loss: 1.0236 - val_acc: 0.5957\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.8564\n",
      "Epoch 00013: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.4282 - acc: 0.8546 - val_loss: 1.0209 - val_acc: 0.6170\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8774\n",
      "Epoch 00014: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.3782 - acc: 0.8759 - val_loss: 1.0466 - val_acc: 0.6099\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8798\n",
      "Epoch 00015: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.3552 - acc: 0.8806 - val_loss: 1.1287 - val_acc: 0.5839\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8864\n",
      "Epoch 00016: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.3464 - acc: 0.8859 - val_loss: 1.0677 - val_acc: 0.6076\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9321\n",
      "Epoch 00017: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.2549 - acc: 0.9314 - val_loss: 1.1469 - val_acc: 0.5816\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9483\n",
      "Epoch 00018: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.2230 - acc: 0.9462 - val_loss: 1.2184 - val_acc: 0.5792\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9441\n",
      "Epoch 00019: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.2114 - acc: 0.9450 - val_loss: 1.1971 - val_acc: 0.5887\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9633\n",
      "Epoch 00020: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.1646 - acc: 0.9628 - val_loss: 1.1860 - val_acc: 0.5957\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9591\n",
      "Epoch 00021: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.1731 - acc: 0.9580 - val_loss: 1.2814 - val_acc: 0.5934\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9706\n",
      "Epoch 00022: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.1344 - acc: 0.9704 - val_loss: 1.2338 - val_acc: 0.5934\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9910\n",
      "Epoch 00023: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.0924 - acc: 0.9911 - val_loss: 1.3126 - val_acc: 0.5816\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9928\n",
      "Epoch 00024: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.0869 - acc: 0.9929 - val_loss: 1.3710 - val_acc: 0.5816\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9982\n",
      "Epoch 00025: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.0657 - acc: 0.9982 - val_loss: 1.3364 - val_acc: 0.5745\n",
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9976\n",
      "Epoch 00026: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.0521 - acc: 0.9976 - val_loss: 1.3368 - val_acc: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9994\n",
      "Epoch 00027: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.0430 - acc: 0.9994 - val_loss: 1.4242 - val_acc: 0.5745\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.0357 - acc: 1.0000 - val_loss: 1.3901 - val_acc: 0.6099\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 1.4471 - val_acc: 0.5863\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 1.01957\n",
      "1692/1692 [==============================] - 16s 10ms/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 1.4533 - val_acc: 0.5839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db06b7de10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 700\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_700 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_700.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_700.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 800)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 800)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.7975 - acc: 0.2969\n",
      "Epoch 00001: val_loss improved from inf to 1.36795, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 23s 13ms/sample - loss: 1.7903 - acc: 0.2985 - val_loss: 1.3680 - val_acc: 0.3381\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2641 - acc: 0.4165\n",
      "Epoch 00002: val_loss did not improve from 1.36795\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 1.2683 - acc: 0.4125 - val_loss: 1.3713 - val_acc: 0.3452\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1760 - acc: 0.4934\n",
      "Epoch 00003: val_loss improved from 1.36795 to 1.31076, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 1.1748 - acc: 0.4935 - val_loss: 1.3108 - val_acc: 0.3641\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0923 - acc: 0.5258\n",
      "Epoch 00004: val_loss improved from 1.31076 to 1.24336, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 1.0912 - acc: 0.5248 - val_loss: 1.2434 - val_acc: 0.4303\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9797 - acc: 0.6022\n",
      "Epoch 00005: val_loss improved from 1.24336 to 1.17650, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 25s 14ms/sample - loss: 0.9826 - acc: 0.6005 - val_loss: 1.1765 - val_acc: 0.4894\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8979 - acc: 0.6322\n",
      "Epoch 00006: val_loss improved from 1.17650 to 1.09940, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.9018 - acc: 0.6312 - val_loss: 1.0994 - val_acc: 0.5248\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7959 - acc: 0.7001\n",
      "Epoch 00007: val_loss did not improve from 1.09940\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.7998 - acc: 0.6974 - val_loss: 1.1143 - val_acc: 0.5201\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7330 - acc: 0.7230\n",
      "Epoch 00008: val_loss improved from 1.09940 to 1.07899, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.7312 - acc: 0.7234 - val_loss: 1.0790 - val_acc: 0.5508\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6537 - acc: 0.7662\n",
      "Epoch 00009: val_loss improved from 1.07899 to 1.07161, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.6544 - acc: 0.7636 - val_loss: 1.0716 - val_acc: 0.5839\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5762 - acc: 0.7939\n",
      "Epoch 00010: val_loss improved from 1.07161 to 1.02742, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800\\assets\n",
      "1692/1692 [==============================] - 25s 15ms/sample - loss: 0.5782 - acc: 0.7937 - val_loss: 1.0274 - val_acc: 0.5863\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5466 - acc: 0.8065\n",
      "Epoch 00011: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.5453 - acc: 0.8073 - val_loss: 1.1031 - val_acc: 0.5508\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8161\n",
      "Epoch 00012: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.4958 - acc: 0.8174 - val_loss: 1.0503 - val_acc: 0.5721\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8528\n",
      "Epoch 00013: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.4317 - acc: 0.8522 - val_loss: 1.1093 - val_acc: 0.6052\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.8786\n",
      "Epoch 00014: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.3730 - acc: 0.8794 - val_loss: 1.0358 - val_acc: 0.6076\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8954\n",
      "Epoch 00015: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.3380 - acc: 0.8948 - val_loss: 1.1564 - val_acc: 0.5839\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.9056\n",
      "Epoch 00016: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.3192 - acc: 0.9048 - val_loss: 1.0549 - val_acc: 0.6005\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9135\n",
      "Epoch 00017: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.2935 - acc: 0.9131 - val_loss: 1.1753 - val_acc: 0.5768\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9261\n",
      "Epoch 00018: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.2505 - acc: 0.9238 - val_loss: 1.1152 - val_acc: 0.6028\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9471\n",
      "Epoch 00019: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.2049 - acc: 0.9468 - val_loss: 1.2000 - val_acc: 0.6005\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9669\n",
      "Epoch 00020: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 17s 10ms/sample - loss: 0.1666 - acc: 0.9663 - val_loss: 1.2163 - val_acc: 0.6028\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9507\n",
      "Epoch 00021: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.1834 - acc: 0.9509 - val_loss: 1.2988 - val_acc: 0.5981\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9645\n",
      "Epoch 00022: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.1523 - acc: 0.9639 - val_loss: 1.2404 - val_acc: 0.6147\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9663\n",
      "Epoch 00023: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 20s 12ms/sample - loss: 0.1408 - acc: 0.9663 - val_loss: 1.3416 - val_acc: 0.5863\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9718\n",
      "Epoch 00024: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.1346 - acc: 0.9716 - val_loss: 1.2327 - val_acc: 0.6194\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9814\n",
      "Epoch 00025: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.1090 - acc: 0.9811 - val_loss: 1.3081 - val_acc: 0.6005\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9868\n",
      "Epoch 00026: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.0833 - acc: 0.9864 - val_loss: 1.3352 - val_acc: 0.6217\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9970\n",
      "Epoch 00027: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.0505 - acc: 0.9970 - val_loss: 1.3732 - val_acc: 0.6147\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.0400 - acc: 0.9994 - val_loss: 1.3607 - val_acc: 0.6123\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 1.4076 - val_acc: 0.6123\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 1.02742\n",
      "1692/1692 [==============================] - 19s 11ms/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 1.3957 - val_acc: 0.6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db06d6f748>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 800\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_800 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_800.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_800.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 900)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 900)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.8060 - acc: 0.3161\n",
      "Epoch 00001: val_loss improved from inf to 1.33194, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.8007 - acc: 0.3150 - val_loss: 1.3319 - val_acc: 0.3522\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2826 - acc: 0.4129\n",
      "Epoch 00002: val_loss improved from 1.33194 to 1.26616, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.2830 - acc: 0.4119 - val_loss: 1.2662 - val_acc: 0.4161\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1599 - acc: 0.4976\n",
      "Epoch 00003: val_loss improved from 1.26616 to 1.21888, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.1585 - acc: 0.4970 - val_loss: 1.2189 - val_acc: 0.4208\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0595 - acc: 0.5643\n",
      "Epoch 00004: val_loss improved from 1.21888 to 1.17217, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 1.0614 - acc: 0.5621 - val_loss: 1.1722 - val_acc: 0.5012\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9522 - acc: 0.6076\n",
      "Epoch 00005: val_loss improved from 1.17217 to 1.08470, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.9534 - acc: 0.6070 - val_loss: 1.0847 - val_acc: 0.5319\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8617 - acc: 0.6550\n",
      "Epoch 00006: val_loss improved from 1.08470 to 1.04866, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.8599 - acc: 0.6554 - val_loss: 1.0487 - val_acc: 0.5626\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7638 - acc: 0.7175\n",
      "Epoch 00007: val_loss did not improve from 1.04866\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.7629 - acc: 0.7175 - val_loss: 1.1145 - val_acc: 0.5296\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7250 - acc: 0.7145\n",
      "Epoch 00008: val_loss improved from 1.04866 to 1.03514, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.7239 - acc: 0.7157 - val_loss: 1.0351 - val_acc: 0.5792\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.7752\n",
      "Epoch 00009: val_loss improved from 1.03514 to 0.99471, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.6185 - acc: 0.7736 - val_loss: 0.9947 - val_acc: 0.5839\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.7969\n",
      "Epoch 00010: val_loss improved from 0.99471 to 0.99014, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900\\assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.5711 - acc: 0.7955 - val_loss: 0.9901 - val_acc: 0.6194\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5114 - acc: 0.8215\n",
      "Epoch 00011: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.5143 - acc: 0.8186 - val_loss: 1.0935 - val_acc: 0.6005\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4761 - acc: 0.8359\n",
      "Epoch 00012: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.4752 - acc: 0.8357 - val_loss: 1.0899 - val_acc: 0.5981\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8474\n",
      "Epoch 00013: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.4424 - acc: 0.8475 - val_loss: 1.0425 - val_acc: 0.6076\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3807 - acc: 0.8642\n",
      "Epoch 00014: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.3834 - acc: 0.8629 - val_loss: 1.0410 - val_acc: 0.6005\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.8864\n",
      "Epoch 00015: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.3449 - acc: 0.8871 - val_loss: 1.0353 - val_acc: 0.6241\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9231\n",
      "Epoch 00016: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.2722 - acc: 0.9220 - val_loss: 1.0135 - val_acc: 0.6407\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9507\n",
      "Epoch 00017: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.2121 - acc: 0.9504 - val_loss: 1.0778 - val_acc: 0.6147\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9585\n",
      "Epoch 00018: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.1812 - acc: 0.9580 - val_loss: 1.1755 - val_acc: 0.5957\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9507\n",
      "Epoch 00019: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.1962 - acc: 0.9509 - val_loss: 1.0781 - val_acc: 0.6407\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9886\n",
      "Epoch 00020: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 23s 13ms/sample - loss: 0.1224 - acc: 0.9888 - val_loss: 1.1440 - val_acc: 0.6147\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9916\n",
      "Epoch 00021: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.0970 - acc: 0.9917 - val_loss: 1.1549 - val_acc: 0.6312\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9976\n",
      "Epoch 00022: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.0763 - acc: 0.9976 - val_loss: 1.1670 - val_acc: 0.6336\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9940\n",
      "Epoch 00023: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.0740 - acc: 0.9941 - val_loss: 1.2449 - val_acc: 0.6312\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9832\n",
      "Epoch 00024: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.1004 - acc: 0.9835 - val_loss: 1.3147 - val_acc: 0.6288\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9904\n",
      "Epoch 00025: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.0745 - acc: 0.9905 - val_loss: 1.2639 - val_acc: 0.6383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9982\n",
      "Epoch 00026: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.0519 - acc: 0.9982 - val_loss: 1.2970 - val_acc: 0.6288\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.0343 - acc: 1.0000 - val_loss: 1.3019 - val_acc: 0.6407\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 1.2999 - val_acc: 0.6383\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 1.3590 - val_acc: 0.6288\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 0.99014\n",
      "1692/1692 [==============================] - 21s 12ms/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 1.3136 - val_acc: 0.6454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db035a7a20>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 900\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_900 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_900.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_900.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 1s 1ms/sample - loss: 0.7043 - acc: 0.7400\n",
      "423/423 [==============================] - 1s 2ms/sample - loss: 0.6906 - acc: 0.7400\n",
      "423/423 [==============================] - 1s 2ms/sample - loss: 0.5866 - acc: 0.7943\n",
      "423/423 [==============================] - 1s 3ms/sample - loss: 0.6460 - acc: 0.7683\n",
      "423/423 [==============================] - 1s 3ms/sample - loss: 0.6541 - acc: 0.7423\n",
      "423/423 [==============================] - 1s 3ms/sample - loss: 0.5836 - acc: 0.7967\n",
      "423/423 [==============================] - 1s 3ms/sample - loss: 0.6752 - acc: 0.7494\n"
     ]
    }
   ],
   "source": [
    "best_shallow_model_300 = keras.models.load_model('./model_checkpoints/shallow_model_300')\n",
    "best_shallow_model_500 = keras.models.load_model('./model_checkpoints/shallow_model_500')\n",
    "best_shallow_model_600 = keras.models.load_model('./model_checkpoints/shallow_model_600')\n",
    "best_shallow_model_700 = keras.models.load_model('./model_checkpoints/shallow_model_700')\n",
    "best_shallow_model_800 = keras.models.load_model('./model_checkpoints/shallow_model_800')\n",
    "best_shallow_model_900 = keras.models.load_model('./model_checkpoints/shallow_model_900')\n",
    "best_shallow_model_1000 = keras.models.load_model('./model_checkpoints/shallow_model_1000')\n",
    "\n",
    "number_of_samples = [300, 500, 600, 700, 800, 900, 1000]\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "# ==================================== 300 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=300, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_300.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 500 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=500, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_500.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 600 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=600, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_600.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 700 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=700, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_700.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 800 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=800, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_800.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 900 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=900, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_900.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 1000 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=1000, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_1000.evaluate(X_valid_slices, y_valid_slices)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.xlabel('number of samples')\n",
    "plt.ylabel('accuracy')\n",
    "ax.plot(number_of_samples, accuracies);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 2s 4ms/sample - loss: 1.0691 - acc: 0.5598\n",
      "443/443 [==============================] - 1s 2ms/sample - loss: 6.3275 - acc: 0.3702\n",
      "443/443 [==============================] - 1s 2ms/sample - loss: 1.0087 - acc: 0.5937\n",
      "\n",
      "# Evaluate on test data\n",
      "Shallow model test loss, test acc: [1.0690552577477277, 0.5598194]\n",
      "Deep model test loss, test acc: [6.3275180401167, 0.37020317]\n",
      "Deep model with augmentations test loss, test acc: [1.0086767906260006, 0.5936795]\n"
     ]
    }
   ],
   "source": [
    "shallow_model_results = shallow_model.evaluate(X_test, y_test, batch_size=128)\n",
    "deep_model_results = deep_model.evaluate(X_test, y_test, batch_size=128)\n",
    "deep_aug_model_results = deep_aug_model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "print('Shallow model test loss, test acc:', shallow_model_results)\n",
    "print('Deep model test loss, test acc:', deep_model_results)\n",
    "print('Deep model with augmentations test loss, test acc:', deep_aug_model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_prj_C247",
   "language": "python",
   "name": "venv_prj_c247"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 654.545454,
   "position": {
    "height": "40px",
    "left": "266.375px",
    "right": "20px",
    "top": "2px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
