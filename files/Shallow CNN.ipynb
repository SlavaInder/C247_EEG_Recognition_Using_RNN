{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This architecture was described in \"Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG\", by R. T. Schirrmeister et al, 2018. In this notebook we conduct experiments showing dependency between accuracy and the number of timestamps in a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# import tf\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# import os functions\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./EEG_data/X_test.npy\")\n",
    "y_test = np.load(\"./EEG_data/y_test.npy\") - 769\n",
    "person_train_valid = np.load(\"./EEG_data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./EEG_data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./EEG_data/y_train_valid.npy\") - 769\n",
    "person_test = np.load(\"./EEG_data/person_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid  shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"training/Valid data shape: {}\".format(X_train_valid.shape))       # training data of many persons\n",
    "print(\"Test data shape: {}\".format(X_test.shape))                        # test data of many persons\n",
    "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))     # training labels of many persons\n",
    "print(\"Test target shape: {}\".format(y_test.shape))                      # test labels of many persons\n",
    "print(\"Person train/valid  shape: {}\".format(person_train_valid.shape))  # which person correspond to the trail in test set\n",
    "print(\"Person test shape: {}\".format(person_test.shape))                 # which person correspond to the trail in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1692, 22, 1000)\n",
      "Training label shape: (1692,)\n",
      "Validation data shape: (423, 22, 1000)\n",
      "Validation label shape: (423,)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Test label shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(X_train_valid.shape[0])\n",
    "num_train = int(0.8 * X_train_valid.shape[0])\n",
    "num_valid = X_train_valid.shape[0] - num_train\n",
    "X_train =  X_train_valid[perm[0:num_train]]\n",
    "y_train =  y_train_valid[perm[0:num_train]]\n",
    "X_valid = X_train_valid[perm[num_train: ]]\n",
    "y_valid = y_train_valid[perm[num_train: ]]\n",
    "\n",
    "\n",
    "print(\"Training data shape: {}\".format(X_train.shape))\n",
    "print(\"Training label shape: {}\".format(y_train.shape))\n",
    "print(\"Validation data shape: {}\".format(X_valid.shape))\n",
    "print(\"Validation label shape: {}\".format(y_valid.shape))\n",
    "print(\"Test data shape: {}\".format(X_test.shape))\n",
    "print(\"Test label shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(X_arr, y_arr, time_window=100, time_step=1, time_stride=1):\n",
    "    temp_x = np.moveaxis(X_arr, 2, 0)\n",
    "    temp_x = temp_x.astype(np.float32)\n",
    "    buff = []\n",
    "    \n",
    "    num_slices = (len(temp_x)-time_window*time_step) // time_stride + 1\n",
    "    \n",
    "    # get time slices for data\n",
    "    for i in range(num_slices):\n",
    "        buff.append(temp_x[i*time_stride:i*time_stride + time_window*time_step:time_step])\n",
    "        buff[i] = np.moveaxis(buff[i], 0, 2)\n",
    "        # uncomment this if additional dimension is needed\n",
    "        # buff[i] = buff[i].reshape(1, buff[i].shape[0], buff[i].shape[1], buff[i].shape[2])\n",
    "        \n",
    "    temp_x = np.concatenate(buff)\n",
    "        \n",
    "    # get time slice for labels\n",
    "    temp_y = np.ones((X_arr.shape[0],num_slices))\n",
    "    \n",
    "    for i in range(len(y_arr)):\n",
    "        temp_y[i] = temp_y[i] * y_arr[i]\n",
    "        \n",
    "    temp_y = temp_y.reshape((-1))\n",
    "    \n",
    "    return temp_x, temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: shallow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we show that:\n",
    "1. shallow model can achieve up to 61.5% of validation accuracy given samples with 1000 timestamps;\n",
    "2. shallow model achieves lowest validation loss after being trained for 9 epochs, after which it starts to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ksquare(x):\n",
    "    return K.pow(x, 2)\n",
    "\n",
    "def Klog(x):\n",
    "    return K.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_shallow_model(TIME_WINDOW):\n",
    "    # input\n",
    "    shallow_input = layers.Input(shape=(22, TIME_WINDOW))\n",
    "\n",
    "    # conv accross time domain\n",
    "    r1 = layers.Reshape((22, TIME_WINDOW, 1))(shallow_input)\n",
    "    c1 = layers.Conv2D(40, (1, 25), strides=(1, 1), activation=\"elu\")(r1)\n",
    "    new_size = TIME_WINDOW - 25 + 1\n",
    "    t1 = tf.keras.layers.Permute((2, 3, 1))(c1)\n",
    "    \n",
    "    \n",
    "    # conv accross time domain\n",
    "    r2 = layers.Reshape((new_size, 40*22, 1))(t1)\n",
    "    c2 = layers.Conv2D(40, (1, 40*22), strides=(1, 1), activation=\"elu\")(r2)\n",
    "\n",
    "    sq1 = layers.Activation(Ksquare)(c2)\n",
    "    r3 = layers.Reshape((new_size, 40, 1))(sq1)\n",
    "    apool1 = layers.AveragePooling2D(pool_size=(75, 1), strides=(15, 1))(r3)\n",
    "\n",
    "    log1 = layers.Activation(Klog)(apool1)\n",
    "    f1 = layers.Flatten()(log1)\n",
    "\n",
    "    # output\n",
    "    shallow_output = layers.Dense(4, activation=\"softmax\")(f1)\n",
    "    \n",
    "    return keras.Model(inputs = shallow_input, outputs = shallow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000 = construct_shallow_model(1000)\n",
    "shallow_model_1000.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 22, 1000)]        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 22, 1000, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 22, 976, 40)       1040      \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 976, 40, 22)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 976, 880, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 976, 1, 40)        35240     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 976, 1, 40)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 976, 40, 1)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 9764      \n",
      "=================================================================\n",
      "Total params: 46,044\n",
      "Trainable params: 46,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shallow_model_1000.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.3968 - acc: 0.3305\n",
      "Epoch 00001: val_loss improved from inf to 1.38306, saving model to ./model_checkpoints/shallow_model_1000\n",
      "WARNING:tensorflow:From /home/slavchic/Desktop/C247/venv_C247/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 1.3928 - acc: 0.3316 - val_loss: 1.3831 - val_acc: 0.3381\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2522 - acc: 0.4111\n",
      "Epoch 00002: val_loss improved from 1.38306 to 1.33519, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 1.2505 - acc: 0.4137 - val_loss: 1.3352 - val_acc: 0.3664\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1563 - acc: 0.4934\n",
      "Epoch 00003: val_loss improved from 1.33519 to 1.29117, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 38s 23ms/sample - loss: 1.1536 - acc: 0.4953 - val_loss: 1.2912 - val_acc: 0.4161\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0461 - acc: 0.5541\n",
      "Epoch 00004: val_loss did not improve from 1.29117\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 1.0463 - acc: 0.5544 - val_loss: 1.2972 - val_acc: 0.4066\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9310 - acc: 0.6358\n",
      "Epoch 00005: val_loss improved from 1.29117 to 1.23112, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.9310 - acc: 0.6353 - val_loss: 1.2311 - val_acc: 0.4894\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8625 - acc: 0.6599\n",
      "Epoch 00006: val_loss improved from 1.23112 to 1.20580, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.8610 - acc: 0.6608 - val_loss: 1.2058 - val_acc: 0.4894\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8050 - acc: 0.6929\n",
      "Epoch 00007: val_loss did not improve from 1.20580\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.8036 - acc: 0.6939 - val_loss: 1.2278 - val_acc: 0.5130\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7117 - acc: 0.7212\n",
      "Epoch 00008: val_loss improved from 1.20580 to 1.18020, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.7094 - acc: 0.7216 - val_loss: 1.1802 - val_acc: 0.5272\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6195 - acc: 0.7704\n",
      "Epoch 00009: val_loss improved from 1.18020 to 1.16646, saving model to ./model_checkpoints/shallow_model_1000\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.6211 - acc: 0.7713 - val_loss: 1.1665 - val_acc: 0.5414\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.8107\n",
      "Epoch 00010: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 41s 25ms/sample - loss: 0.5672 - acc: 0.8109 - val_loss: 1.2016 - val_acc: 0.5296\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8275\n",
      "Epoch 00011: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.5050 - acc: 0.8257 - val_loss: 1.1902 - val_acc: 0.5579\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8618\n",
      "Epoch 00012: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.4427 - acc: 0.8599 - val_loss: 1.2379 - val_acc: 0.5650\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3982 - acc: 0.8786\n",
      "Epoch 00013: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.4020 - acc: 0.8753 - val_loss: 1.2492 - val_acc: 0.5272\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8606\n",
      "Epoch 00014: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.4017 - acc: 0.8599 - val_loss: 1.3162 - val_acc: 0.5248\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.9183\n",
      "Epoch 00015: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 43s 26ms/sample - loss: 0.3076 - acc: 0.9167 - val_loss: 1.2167 - val_acc: 0.5792\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2724 - acc: 0.9267\n",
      "Epoch 00016: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.2742 - acc: 0.9267 - val_loss: 1.2776 - val_acc: 0.5792\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9507\n",
      "Epoch 00017: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 43s 26ms/sample - loss: 0.2244 - acc: 0.9504 - val_loss: 1.4122 - val_acc: 0.5603\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9519\n",
      "Epoch 00018: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 47s 28ms/sample - loss: 0.1967 - acc: 0.9521 - val_loss: 1.3585 - val_acc: 0.5792\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9748\n",
      "Epoch 00019: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 48s 29ms/sample - loss: 0.1549 - acc: 0.9746 - val_loss: 1.3662 - val_acc: 0.5934\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9832\n",
      "Epoch 00020: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 45s 26ms/sample - loss: 0.1197 - acc: 0.9835 - val_loss: 1.3757 - val_acc: 0.6005\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9874\n",
      "Epoch 00021: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.1041 - acc: 0.9876 - val_loss: 1.4346 - val_acc: 0.5816\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9958\n",
      "Epoch 00022: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.0881 - acc: 0.9959 - val_loss: 1.4347 - val_acc: 0.6099\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9976\n",
      "Epoch 00023: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.0691 - acc: 0.9959 - val_loss: 1.5040 - val_acc: 0.5839\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9964\n",
      "Epoch 00024: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 43s 26ms/sample - loss: 0.0696 - acc: 0.9965 - val_loss: 1.5294 - val_acc: 0.5816\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9988\n",
      "Epoch 00025: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 43s 26ms/sample - loss: 0.0536 - acc: 0.9988 - val_loss: 1.5779 - val_acc: 0.6005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 00026: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 1.5535 - val_acc: 0.6099\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.0300 - acc: 1.0000 - val_loss: 1.5781 - val_acc: 0.5863\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 1.6070 - val_acc: 0.6147\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 1.6278 - val_acc: 0.5981\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 1.16646\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 1.6525 - val_acc: 0.6028\n"
     ]
    }
   ],
   "source": [
    "shallow_model_loss_hist = shallow_model_1000.fit(X_train, y_train,\n",
    "                                                 validation_data = (X_valid, y_valid),\n",
    "                                                 epochs = 30,\n",
    "                                                 callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7facdc4e0710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad0c57ae48>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = shallow_model_loss_hist.history\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist['acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: shallow model with normilized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we shaow that data normalization does not help to improve validation accuracy. For the following experiment with shallow model, we do not try to normilize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normilize the data USING ONLY TRAIN DATA MEAN AND STANDARD DEVIATION\n",
    "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_valid_norm = (X_valid - np.mean(X_train))/np.std(X_train)\n",
    "X_test_norm = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000_norm = construct_shallow_model(1000)\n",
    "shallow_model_1000_norm.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000_norm',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.9727 - acc: 0.2686\n",
      "Epoch 00001: val_loss improved from inf to 1.46535, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 43s 25ms/sample - loss: 1.9629 - acc: 0.2701 - val_loss: 1.4654 - val_acc: 0.2955\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.3639 - acc: 0.3558\n",
      "Epoch 00002: val_loss improved from 1.46535 to 1.39377, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 1.3610 - acc: 0.3582 - val_loss: 1.3938 - val_acc: 0.3428\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.3326 - acc: 0.3810\n",
      "Epoch 00003: val_loss did not improve from 1.39377\n",
      "1692/1692 [==============================] - 43s 25ms/sample - loss: 1.3289 - acc: 0.3848 - val_loss: 1.4472 - val_acc: 0.3617\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2882 - acc: 0.4153\n",
      "Epoch 00004: val_loss improved from 1.39377 to 1.37097, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 1.2880 - acc: 0.4178 - val_loss: 1.3710 - val_acc: 0.3759\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2551 - acc: 0.4315\n",
      "Epoch 00005: val_loss did not improve from 1.37097\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 1.2518 - acc: 0.4332 - val_loss: 1.4031 - val_acc: 0.3428\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2357 - acc: 0.4489\n",
      "Epoch 00006: val_loss did not improve from 1.37097\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 1.2324 - acc: 0.4504 - val_loss: 1.4013 - val_acc: 0.3499\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2150 - acc: 0.4597\n",
      "Epoch 00007: val_loss did not improve from 1.37097\n",
      "1692/1692 [==============================] - 49s 29ms/sample - loss: 1.2145 - acc: 0.4592 - val_loss: 1.3870 - val_acc: 0.3617\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1667 - acc: 0.4940\n",
      "Epoch 00008: val_loss improved from 1.37097 to 1.33349, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 1.1676 - acc: 0.4953 - val_loss: 1.3335 - val_acc: 0.3972\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1130 - acc: 0.5270\n",
      "Epoch 00009: val_loss improved from 1.33349 to 1.31001, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 1.1130 - acc: 0.5260 - val_loss: 1.3100 - val_acc: 0.4444\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0904 - acc: 0.5385\n",
      "Epoch 00010: val_loss did not improve from 1.31001\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 1.0890 - acc: 0.5396 - val_loss: 1.3480 - val_acc: 0.4137\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0473 - acc: 0.5607\n",
      "Epoch 00011: val_loss improved from 1.31001 to 1.28877, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 48s 28ms/sample - loss: 1.0456 - acc: 0.5621 - val_loss: 1.2888 - val_acc: 0.4350\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9660 - acc: 0.6088\n",
      "Epoch 00012: val_loss improved from 1.28877 to 1.23971, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.9641 - acc: 0.6111 - val_loss: 1.2397 - val_acc: 0.4846\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9058 - acc: 0.6436\n",
      "Epoch 00013: val_loss improved from 1.23971 to 1.21879, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 45s 26ms/sample - loss: 0.9074 - acc: 0.6413 - val_loss: 1.2188 - val_acc: 0.4988\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8587 - acc: 0.6605\n",
      "Epoch 00014: val_loss did not improve from 1.21879\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.8631 - acc: 0.6566 - val_loss: 1.2236 - val_acc: 0.4941\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8349 - acc: 0.6725\n",
      "Epoch 00015: val_loss improved from 1.21879 to 1.18605, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 48s 29ms/sample - loss: 0.8355 - acc: 0.6732 - val_loss: 1.1860 - val_acc: 0.5272\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7791 - acc: 0.6953\n",
      "Epoch 00016: val_loss did not improve from 1.18605\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.7786 - acc: 0.6962 - val_loss: 1.1967 - val_acc: 0.5272\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7463 - acc: 0.7212\n",
      "Epoch 00017: val_loss did not improve from 1.18605\n",
      "1692/1692 [==============================] - 47s 28ms/sample - loss: 0.7477 - acc: 0.7199 - val_loss: 1.1971 - val_acc: 0.5154\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7168 - acc: 0.7260\n",
      "Epoch 00018: val_loss improved from 1.18605 to 1.17352, saving model to ./model_checkpoints/shallow_model_1000_norm\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_1000_norm/assets\n",
      "1692/1692 [==============================] - 47s 28ms/sample - loss: 0.7186 - acc: 0.7240 - val_loss: 1.1735 - val_acc: 0.5343\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6772 - acc: 0.7494\n",
      "Epoch 00019: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 43s 25ms/sample - loss: 0.6775 - acc: 0.7488 - val_loss: 1.1849 - val_acc: 0.5532\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6254 - acc: 0.7668\n",
      "Epoch 00020: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.6292 - acc: 0.7654 - val_loss: 1.1872 - val_acc: 0.5319\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5985 - acc: 0.7861\n",
      "Epoch 00021: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.6010 - acc: 0.7843 - val_loss: 1.1868 - val_acc: 0.5556\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5612 - acc: 0.7993\n",
      "Epoch 00022: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.5622 - acc: 0.7991 - val_loss: 1.1943 - val_acc: 0.5532\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5256 - acc: 0.8233\n",
      "Epoch 00023: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.5232 - acc: 0.8239 - val_loss: 1.2319 - val_acc: 0.5390\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5130 - acc: 0.8137\n",
      "Epoch 00024: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.5146 - acc: 0.8132 - val_loss: 1.1813 - val_acc: 0.5650\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8161\n",
      "Epoch 00025: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.4964 - acc: 0.8180 - val_loss: 1.1747 - val_acc: 0.5674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8474\n",
      "Epoch 00026: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 45s 27ms/sample - loss: 0.4588 - acc: 0.8469 - val_loss: 1.1824 - val_acc: 0.5603\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8630\n",
      "Epoch 00027: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.4372 - acc: 0.8641 - val_loss: 1.2285 - val_acc: 0.5674\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3981 - acc: 0.8768\n",
      "Epoch 00028: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 46s 27ms/sample - loss: 0.4016 - acc: 0.8753 - val_loss: 1.2245 - val_acc: 0.5650\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3846 - acc: 0.8798\n",
      "Epoch 00029: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 48s 28ms/sample - loss: 0.3862 - acc: 0.8788 - val_loss: 1.2118 - val_acc: 0.5697\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3723 - acc: 0.8756\n",
      "Epoch 00030: val_loss did not improve from 1.17352\n",
      "1692/1692 [==============================] - 52s 31ms/sample - loss: 0.3713 - acc: 0.8765 - val_loss: 1.2170 - val_acc: 0.5768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc4815f8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_model_1000_norm.fit(X_train_norm, y_train,\n",
    "                            validation_data = (X_valid_norm, y_valid),\n",
    "                            epochs = 30,\n",
    "                            callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: shallow model - accuracy vs number of timestamps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we show that accuracy peaks at 700 timestamps per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 300)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 300)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.5962 - acc: 0.3071\n",
      "Epoch 00001: val_loss improved from inf to 1.39737, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 15s 9ms/sample - loss: 1.5955 - acc: 0.3061 - val_loss: 1.3974 - val_acc: 0.3239\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.3132 - acc: 0.3744\n",
      "Epoch 00002: val_loss improved from 1.39737 to 1.31302, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 15s 9ms/sample - loss: 1.3122 - acc: 0.3759 - val_loss: 1.3130 - val_acc: 0.4019\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2239 - acc: 0.4447\n",
      "Epoch 00003: val_loss improved from 1.31302 to 1.30098, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 14s 8ms/sample - loss: 1.2269 - acc: 0.4415 - val_loss: 1.3010 - val_acc: 0.4043\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1428 - acc: 0.5096\n",
      "Epoch 00004: val_loss improved from 1.30098 to 1.25969, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 14s 8ms/sample - loss: 1.1440 - acc: 0.5100 - val_loss: 1.2597 - val_acc: 0.4255\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0580 - acc: 0.5529\n",
      "Epoch 00005: val_loss improved from 1.25969 to 1.17569, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 1.0552 - acc: 0.5550 - val_loss: 1.1757 - val_acc: 0.4799\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0530 - acc: 0.5487\n",
      "Epoch 00006: val_loss did not improve from 1.17569\n",
      "1692/1692 [==============================] - 11s 7ms/sample - loss: 1.0583 - acc: 0.5455 - val_loss: 1.2443 - val_acc: 0.4184\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0102 - acc: 0.5829\n",
      "Epoch 00007: val_loss improved from 1.17569 to 1.17399, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 1.0121 - acc: 0.5810 - val_loss: 1.1740 - val_acc: 0.4965\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9570 - acc: 0.6004\n",
      "Epoch 00008: val_loss improved from 1.17399 to 1.14981, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 13s 7ms/sample - loss: 0.9559 - acc: 0.6005 - val_loss: 1.1498 - val_acc: 0.5225\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8887 - acc: 0.6617\n",
      "Epoch 00009: val_loss did not improve from 1.14981\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.8880 - acc: 0.6619 - val_loss: 1.2810 - val_acc: 0.4610\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8780 - acc: 0.6478\n",
      "Epoch 00010: val_loss improved from 1.14981 to 1.14252, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 15s 9ms/sample - loss: 0.8805 - acc: 0.6472 - val_loss: 1.1425 - val_acc: 0.5201\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8316 - acc: 0.6677\n",
      "Epoch 00011: val_loss did not improve from 1.14252\n",
      "1692/1692 [==============================] - 14s 8ms/sample - loss: 0.8323 - acc: 0.6678 - val_loss: 1.1851 - val_acc: 0.5154\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7827 - acc: 0.6857\n",
      "Epoch 00012: val_loss improved from 1.14252 to 1.09863, saving model to ./model_checkpoints/shallow_model_300\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_300/assets\n",
      "1692/1692 [==============================] - 14s 8ms/sample - loss: 0.7824 - acc: 0.6862 - val_loss: 1.0986 - val_acc: 0.5296\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6921 - acc: 0.7446\n",
      "Epoch 00013: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.6905 - acc: 0.7459 - val_loss: 1.1327 - val_acc: 0.5461\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6604 - acc: 0.7536\n",
      "Epoch 00014: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.6582 - acc: 0.7535 - val_loss: 1.2233 - val_acc: 0.5390\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6704 - acc: 0.7428\n",
      "Epoch 00015: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.6699 - acc: 0.7429 - val_loss: 1.1402 - val_acc: 0.5272\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6068 - acc: 0.7698\n",
      "Epoch 00016: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.6086 - acc: 0.7689 - val_loss: 1.2317 - val_acc: 0.5106\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.8083\n",
      "Epoch 00017: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.5530 - acc: 0.8097 - val_loss: 1.2086 - val_acc: 0.5343\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5163 - acc: 0.8305\n",
      "Epoch 00018: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.5174 - acc: 0.8316 - val_loss: 1.2392 - val_acc: 0.5201\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.8359\n",
      "Epoch 00019: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.4777 - acc: 0.8363 - val_loss: 1.1992 - val_acc: 0.5130\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4206 - acc: 0.8660\n",
      "Epoch 00020: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.4231 - acc: 0.8635 - val_loss: 1.2117 - val_acc: 0.5414\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8732\n",
      "Epoch 00021: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.4010 - acc: 0.8729 - val_loss: 1.2400 - val_acc: 0.5414\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3834 - acc: 0.8768\n",
      "Epoch 00022: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.3869 - acc: 0.8747 - val_loss: 1.2691 - val_acc: 0.5319\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3690 - acc: 0.8750\n",
      "Epoch 00023: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.3671 - acc: 0.8765 - val_loss: 1.2812 - val_acc: 0.5485\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9081\n",
      "Epoch 00024: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 7ms/sample - loss: 0.3118 - acc: 0.9066 - val_loss: 1.3456 - val_acc: 0.5437\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.9099\n",
      "Epoch 00025: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.3062 - acc: 0.9096 - val_loss: 1.3401 - val_acc: 0.5508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9183\n",
      "Epoch 00026: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.2943 - acc: 0.9161 - val_loss: 1.3608 - val_acc: 0.5343\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9345\n",
      "Epoch 00027: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 13s 8ms/sample - loss: 0.2533 - acc: 0.9350 - val_loss: 1.6543 - val_acc: 0.4823\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9369\n",
      "Epoch 00028: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.2344 - acc: 0.9350 - val_loss: 1.4228 - val_acc: 0.5319\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1953 - acc: 0.9519\n",
      "Epoch 00029: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 12s 7ms/sample - loss: 0.1969 - acc: 0.9509 - val_loss: 1.4548 - val_acc: 0.5414\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9742\n",
      "Epoch 00030: val_loss did not improve from 1.09863\n",
      "1692/1692 [==============================] - 15s 9ms/sample - loss: 0.1584 - acc: 0.9734 - val_loss: 1.4317 - val_acc: 0.5485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc36eb70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 300\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_300 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_300.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_300.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 500)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 500)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.6511 - acc: 0.3149\n",
      "Epoch 00001: val_loss improved from inf to 1.35016, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 26s 15ms/sample - loss: 1.6480 - acc: 0.3150 - val_loss: 1.3502 - val_acc: 0.3712\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2611 - acc: 0.4177\n",
      "Epoch 00002: val_loss improved from 1.35016 to 1.28976, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 1.2620 - acc: 0.4161 - val_loss: 1.2898 - val_acc: 0.4184\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1513 - acc: 0.4904\n",
      "Epoch 00003: val_loss improved from 1.28976 to 1.20041, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 25s 15ms/sample - loss: 1.1533 - acc: 0.4882 - val_loss: 1.2004 - val_acc: 0.4846\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0425 - acc: 0.5625\n",
      "Epoch 00004: val_loss improved from 1.20041 to 1.18841, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 1.0434 - acc: 0.5638 - val_loss: 1.1884 - val_acc: 0.5059\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9656 - acc: 0.6094\n",
      "Epoch 00005: val_loss improved from 1.18841 to 1.16241, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.9642 - acc: 0.6087 - val_loss: 1.1624 - val_acc: 0.4941\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9155 - acc: 0.6274\n",
      "Epoch 00006: val_loss improved from 1.16241 to 1.15156, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 26s 16ms/sample - loss: 0.9191 - acc: 0.6259 - val_loss: 1.1516 - val_acc: 0.5201\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8156 - acc: 0.6797\n",
      "Epoch 00007: val_loss improved from 1.15156 to 1.06627, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.8153 - acc: 0.6803 - val_loss: 1.0663 - val_acc: 0.5863\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7465 - acc: 0.7145\n",
      "Epoch 00008: val_loss improved from 1.06627 to 0.99309, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 25s 15ms/sample - loss: 0.7481 - acc: 0.7157 - val_loss: 0.9931 - val_acc: 0.6217\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6661 - acc: 0.7506\n",
      "Epoch 00009: val_loss improved from 0.99309 to 0.98818, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 25s 15ms/sample - loss: 0.6662 - acc: 0.7506 - val_loss: 0.9882 - val_acc: 0.6217\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6240 - acc: 0.7596\n",
      "Epoch 00010: val_loss did not improve from 0.98818\n",
      "1692/1692 [==============================] - 21s 13ms/sample - loss: 0.6265 - acc: 0.7583 - val_loss: 1.0322 - val_acc: 0.5957\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6233 - acc: 0.7656\n",
      "Epoch 00011: val_loss did not improve from 0.98818\n",
      "1692/1692 [==============================] - 23s 13ms/sample - loss: 0.6236 - acc: 0.7654 - val_loss: 1.0034 - val_acc: 0.6147\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.8005\n",
      "Epoch 00012: val_loss did not improve from 0.98818\n",
      "1692/1692 [==============================] - 22s 13ms/sample - loss: 0.5528 - acc: 0.8026 - val_loss: 0.9890 - val_acc: 0.6359\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4837 - acc: 0.8329\n",
      "Epoch 00013: val_loss improved from 0.98818 to 0.97089, saving model to ./model_checkpoints/shallow_model_500\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_500/assets\n",
      "1692/1692 [==============================] - 26s 16ms/sample - loss: 0.4837 - acc: 0.8322 - val_loss: 0.9709 - val_acc: 0.6359\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4412 - acc: 0.8425\n",
      "Epoch 00014: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.4414 - acc: 0.8422 - val_loss: 1.0335 - val_acc: 0.6312\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4216 - acc: 0.8552\n",
      "Epoch 00015: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.4187 - acc: 0.8564 - val_loss: 1.1027 - val_acc: 0.6099\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3571 - acc: 0.8786\n",
      "Epoch 00016: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.3554 - acc: 0.8788 - val_loss: 1.0305 - val_acc: 0.6548\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3442 - acc: 0.8846\n",
      "Epoch 00017: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.3447 - acc: 0.8836 - val_loss: 1.1917 - val_acc: 0.5934\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.9165\n",
      "Epoch 00018: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.2833 - acc: 0.9155 - val_loss: 1.0726 - val_acc: 0.6407\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9279\n",
      "Epoch 00019: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.2465 - acc: 0.9291 - val_loss: 1.1355 - val_acc: 0.6525\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9147\n",
      "Epoch 00020: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.2581 - acc: 0.9161 - val_loss: 1.1641 - val_acc: 0.6383\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9537\n",
      "Epoch 00021: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.1950 - acc: 0.9545 - val_loss: 1.1750 - val_acc: 0.6383\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9627\n",
      "Epoch 00022: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 24s 14ms/sample - loss: 0.1689 - acc: 0.9628 - val_loss: 1.1192 - val_acc: 0.6572\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9591\n",
      "Epoch 00023: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.1693 - acc: 0.9598 - val_loss: 1.1575 - val_acc: 0.6572\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9796\n",
      "Epoch 00024: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 13ms/sample - loss: 0.1235 - acc: 0.9787 - val_loss: 1.1970 - val_acc: 0.6809\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9880\n",
      "Epoch 00025: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.0997 - acc: 0.9882 - val_loss: 1.1814 - val_acc: 0.6525\n",
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9946\n",
      "Epoch 00026: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 13ms/sample - loss: 0.0851 - acc: 0.9941 - val_loss: 1.2083 - val_acc: 0.6856\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9970\n",
      "Epoch 00027: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.0638 - acc: 0.9970 - val_loss: 1.2502 - val_acc: 0.6667\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 1.2713 - val_acc: 0.6548\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 1.3118 - val_acc: 0.6690\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9994\n",
      "Epoch 00030: val_loss did not improve from 0.97089\n",
      "1692/1692 [==============================] - 23s 14ms/sample - loss: 0.0390 - acc: 0.9994 - val_loss: 1.3325 - val_acc: 0.6548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc1833c8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 500\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_500 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_500.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_500.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 600)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 600)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.6810 - acc: 0.3095\n",
      "Epoch 00001: val_loss improved from inf to 1.35520, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 26s 15ms/sample - loss: 1.6761 - acc: 0.3073 - val_loss: 1.3552 - val_acc: 0.3404\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2589 - acc: 0.4267\n",
      "Epoch 00002: val_loss improved from 1.35520 to 1.31261, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 1.2605 - acc: 0.4243 - val_loss: 1.3126 - val_acc: 0.3735\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1757 - acc: 0.4820\n",
      "Epoch 00003: val_loss improved from 1.31261 to 1.27012, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 1.1771 - acc: 0.4811 - val_loss: 1.2701 - val_acc: 0.4208\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0774 - acc: 0.5529\n",
      "Epoch 00004: val_loss improved from 1.27012 to 1.19135, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 26s 15ms/sample - loss: 1.0756 - acc: 0.5550 - val_loss: 1.1914 - val_acc: 0.4374\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9954 - acc: 0.5859\n",
      "Epoch 00005: val_loss improved from 1.19135 to 1.12999, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.9947 - acc: 0.5857 - val_loss: 1.1300 - val_acc: 0.5083\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9006 - acc: 0.6466\n",
      "Epoch 00006: val_loss improved from 1.12999 to 1.10539, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 26s 15ms/sample - loss: 0.9003 - acc: 0.6472 - val_loss: 1.1054 - val_acc: 0.5296\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8478 - acc: 0.6587\n",
      "Epoch 00007: val_loss improved from 1.10539 to 1.02172, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.8469 - acc: 0.6584 - val_loss: 1.0217 - val_acc: 0.5816\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7589 - acc: 0.7037\n",
      "Epoch 00008: val_loss did not improve from 1.02172\n",
      "1692/1692 [==============================] - 25s 15ms/sample - loss: 0.7580 - acc: 0.7039 - val_loss: 1.0783 - val_acc: 0.5579\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7048 - acc: 0.7398\n",
      "Epoch 00009: val_loss improved from 1.02172 to 1.00930, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.7062 - acc: 0.7382 - val_loss: 1.0093 - val_acc: 0.5816\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6545 - acc: 0.7554\n",
      "Epoch 00010: val_loss did not improve from 1.00930\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.6593 - acc: 0.7535 - val_loss: 1.0628 - val_acc: 0.6076\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5987 - acc: 0.7746\n",
      "Epoch 00011: val_loss did not improve from 1.00930\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.5989 - acc: 0.7736 - val_loss: 1.1093 - val_acc: 0.5745\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5800 - acc: 0.7722\n",
      "Epoch 00012: val_loss did not improve from 1.00930\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.5869 - acc: 0.7701 - val_loss: 1.0683 - val_acc: 0.6194\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5408 - acc: 0.8089\n",
      "Epoch 00013: val_loss did not improve from 1.00930\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.5377 - acc: 0.8109 - val_loss: 1.0923 - val_acc: 0.5981\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8287\n",
      "Epoch 00014: val_loss improved from 1.00930 to 0.97224, saving model to ./model_checkpoints/shallow_model_600\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_600/assets\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.4953 - acc: 0.8286 - val_loss: 0.9722 - val_acc: 0.6430\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4259 - acc: 0.8534\n",
      "Epoch 00015: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.4254 - acc: 0.8540 - val_loss: 1.0405 - val_acc: 0.6548\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8666\n",
      "Epoch 00016: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.4004 - acc: 0.8664 - val_loss: 1.0499 - val_acc: 0.6430\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.8834\n",
      "Epoch 00017: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.3483 - acc: 0.8842 - val_loss: 1.0805 - val_acc: 0.6123\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3263 - acc: 0.9038\n",
      "Epoch 00018: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.3265 - acc: 0.9025 - val_loss: 1.1178 - val_acc: 0.6454\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2875 - acc: 0.9147\n",
      "Epoch 00019: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 27s 16ms/sample - loss: 0.2891 - acc: 0.9143 - val_loss: 1.0218 - val_acc: 0.6501\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9393\n",
      "Epoch 00020: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.2383 - acc: 0.9397 - val_loss: 1.0838 - val_acc: 0.6312\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9405\n",
      "Epoch 00021: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.2296 - acc: 0.9368 - val_loss: 1.1224 - val_acc: 0.6430\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9363\n",
      "Epoch 00022: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.2257 - acc: 0.9350 - val_loss: 1.0570 - val_acc: 0.6478\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9519\n",
      "Epoch 00023: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 31s 18ms/sample - loss: 0.1918 - acc: 0.9515 - val_loss: 1.1189 - val_acc: 0.6288\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9681\n",
      "Epoch 00024: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 30s 18ms/sample - loss: 0.1550 - acc: 0.9687 - val_loss: 1.2412 - val_acc: 0.6430\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9772\n",
      "Epoch 00025: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 17ms/sample - loss: 0.1288 - acc: 0.9770 - val_loss: 1.2899 - val_acc: 0.6265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9826\n",
      "Epoch 00026: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 26s 16ms/sample - loss: 0.1106 - acc: 0.9829 - val_loss: 1.2188 - val_acc: 0.6217\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9892\n",
      "Epoch 00027: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 28s 16ms/sample - loss: 0.0959 - acc: 0.9894 - val_loss: 1.2209 - val_acc: 0.6501\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9880\n",
      "Epoch 00028: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.0916 - acc: 0.9882 - val_loss: 1.2423 - val_acc: 0.6241\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9856\n",
      "Epoch 00029: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 30s 18ms/sample - loss: 0.0990 - acc: 0.9858 - val_loss: 1.3182 - val_acc: 0.6241\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9976\n",
      "Epoch 00030: val_loss did not improve from 0.97224\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.0691 - acc: 0.9976 - val_loss: 1.2971 - val_acc: 0.6478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc0a04a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 600\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_600 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_600.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_600.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 700)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 700)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.7667 - acc: 0.2951\n",
      "Epoch 00001: val_loss improved from inf to 1.38685, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 1.7625 - acc: 0.2943 - val_loss: 1.3868 - val_acc: 0.3144\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2869 - acc: 0.3924\n",
      "Epoch 00002: val_loss improved from 1.38685 to 1.32235, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 1.2903 - acc: 0.3901 - val_loss: 1.3224 - val_acc: 0.3759\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2012 - acc: 0.4573\n",
      "Epoch 00003: val_loss improved from 1.32235 to 1.30938, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 1.1976 - acc: 0.4592 - val_loss: 1.3094 - val_acc: 0.4019\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0890 - acc: 0.5373\n",
      "Epoch 00004: val_loss improved from 1.30938 to 1.19382, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 1.0874 - acc: 0.5402 - val_loss: 1.1938 - val_acc: 0.4610\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9896 - acc: 0.6022\n",
      "Epoch 00005: val_loss improved from 1.19382 to 1.14446, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.9919 - acc: 0.5993 - val_loss: 1.1445 - val_acc: 0.5012\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9312 - acc: 0.6082\n",
      "Epoch 00006: val_loss improved from 1.14446 to 1.10624, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 0.9325 - acc: 0.6070 - val_loss: 1.1062 - val_acc: 0.5414\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8207 - acc: 0.6809\n",
      "Epoch 00007: val_loss improved from 1.10624 to 1.01959, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 0.8230 - acc: 0.6791 - val_loss: 1.0196 - val_acc: 0.5910\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7773 - acc: 0.7049\n",
      "Epoch 00008: val_loss did not improve from 1.01959\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.7767 - acc: 0.7069 - val_loss: 1.0265 - val_acc: 0.5887\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7063 - acc: 0.7302\n",
      "Epoch 00009: val_loss did not improve from 1.01959\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.7065 - acc: 0.7287 - val_loss: 1.0654 - val_acc: 0.5957\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7044 - acc: 0.7194\n",
      "Epoch 00010: val_loss did not improve from 1.01959\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.7030 - acc: 0.7187 - val_loss: 1.1409 - val_acc: 0.5437\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6303 - acc: 0.7716\n",
      "Epoch 00011: val_loss did not improve from 1.01959\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.6353 - acc: 0.7689 - val_loss: 1.0295 - val_acc: 0.6005\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.7933\n",
      "Epoch 00012: val_loss improved from 1.01959 to 0.99902, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.5491 - acc: 0.7955 - val_loss: 0.9990 - val_acc: 0.6005\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.8197\n",
      "Epoch 00013: val_loss improved from 0.99902 to 0.99153, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.5260 - acc: 0.8186 - val_loss: 0.9915 - val_acc: 0.6359\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4699 - acc: 0.8323\n",
      "Epoch 00014: val_loss did not improve from 0.99153\n",
      "1692/1692 [==============================] - 29s 17ms/sample - loss: 0.4727 - acc: 0.8304 - val_loss: 1.0085 - val_acc: 0.6217\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4150 - acc: 0.8600\n",
      "Epoch 00015: val_loss did not improve from 0.99153\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.4140 - acc: 0.8599 - val_loss: 1.1452 - val_acc: 0.6028\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8654\n",
      "Epoch 00016: val_loss did not improve from 0.99153\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.3962 - acc: 0.8647 - val_loss: 1.2454 - val_acc: 0.5887\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.8840\n",
      "Epoch 00017: val_loss improved from 0.99153 to 0.98868, saving model to ./model_checkpoints/shallow_model_700\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_700/assets\n",
      "1692/1692 [==============================] - 30s 18ms/sample - loss: 0.3482 - acc: 0.8853 - val_loss: 0.9887 - val_acc: 0.6690\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3043 - acc: 0.9050\n",
      "Epoch 00018: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.3050 - acc: 0.9043 - val_loss: 1.0859 - val_acc: 0.6147\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9087\n",
      "Epoch 00019: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.2904 - acc: 0.9072 - val_loss: 1.1146 - val_acc: 0.5957\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9020\n",
      "Epoch 00020: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 0.2989 - acc: 0.9007 - val_loss: 1.0518 - val_acc: 0.6359\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9393\n",
      "Epoch 00021: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.2278 - acc: 0.9391 - val_loss: 1.1274 - val_acc: 0.6359\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9615\n",
      "Epoch 00022: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.1884 - acc: 0.9598 - val_loss: 1.1342 - val_acc: 0.6383\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9387\n",
      "Epoch 00023: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.2059 - acc: 0.9374 - val_loss: 1.1913 - val_acc: 0.6336\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9675\n",
      "Epoch 00024: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.1541 - acc: 0.9681 - val_loss: 1.1795 - val_acc: 0.6478\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9754\n",
      "Epoch 00025: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.1332 - acc: 0.9746 - val_loss: 1.1919 - val_acc: 0.6619\n",
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9790\n",
      "Epoch 00026: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.1182 - acc: 0.9793 - val_loss: 1.2270 - val_acc: 0.6217\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9748\n",
      "Epoch 00027: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.1217 - acc: 0.9752 - val_loss: 1.2960 - val_acc: 0.6288\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9904\n",
      "Epoch 00028: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 32s 19ms/sample - loss: 0.0837 - acc: 0.9900 - val_loss: 1.2787 - val_acc: 0.6572\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9934\n",
      "Epoch 00029: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.0706 - acc: 0.9935 - val_loss: 1.2670 - val_acc: 0.6501\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9946\n",
      "Epoch 00030: val_loss did not improve from 0.98868\n",
      "1692/1692 [==============================] - 33s 19ms/sample - loss: 0.0594 - acc: 0.9947 - val_loss: 1.3552 - val_acc: 0.6643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc0b5080>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 700\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_700 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_700.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_700.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 800)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 800)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.8781 - acc: 0.3077\n",
      "Epoch 00001: val_loss improved from inf to 1.40559, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 38s 23ms/sample - loss: 1.8691 - acc: 0.3073 - val_loss: 1.4056 - val_acc: 0.3381\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2894 - acc: 0.4002\n",
      "Epoch 00002: val_loss did not improve from 1.40559\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 1.2850 - acc: 0.4019 - val_loss: 1.4072 - val_acc: 0.3783\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1747 - acc: 0.4928\n",
      "Epoch 00003: val_loss improved from 1.40559 to 1.31006, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 1.1725 - acc: 0.4947 - val_loss: 1.3101 - val_acc: 0.4137\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0686 - acc: 0.5457\n",
      "Epoch 00004: val_loss improved from 1.31006 to 1.25636, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 34s 20ms/sample - loss: 1.0706 - acc: 0.5455 - val_loss: 1.2564 - val_acc: 0.4586\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9603 - acc: 0.6202\n",
      "Epoch 00005: val_loss improved from 1.25636 to 1.20203, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.9629 - acc: 0.6188 - val_loss: 1.2020 - val_acc: 0.4539\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8808 - acc: 0.6496\n",
      "Epoch 00006: val_loss improved from 1.20203 to 1.16409, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.8837 - acc: 0.6489 - val_loss: 1.1641 - val_acc: 0.5272\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7663 - acc: 0.7169\n",
      "Epoch 00007: val_loss improved from 1.16409 to 1.12887, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 0.7632 - acc: 0.7181 - val_loss: 1.1289 - val_acc: 0.5532\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6983 - acc: 0.7458\n",
      "Epoch 00008: val_loss improved from 1.12887 to 1.09008, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.6990 - acc: 0.7447 - val_loss: 1.0901 - val_acc: 0.5650\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6437 - acc: 0.7548\n",
      "Epoch 00009: val_loss improved from 1.09008 to 1.08127, saving model to ./model_checkpoints/shallow_model_800\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_800/assets\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.6497 - acc: 0.7518 - val_loss: 1.0813 - val_acc: 0.5768\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.7662\n",
      "Epoch 00010: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 0.6259 - acc: 0.7636 - val_loss: 1.1450 - val_acc: 0.5390\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.7963\n",
      "Epoch 00011: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.5558 - acc: 0.7961 - val_loss: 1.1078 - val_acc: 0.5532\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8365\n",
      "Epoch 00012: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.4826 - acc: 0.8351 - val_loss: 1.1499 - val_acc: 0.5650\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8498\n",
      "Epoch 00013: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.4489 - acc: 0.8475 - val_loss: 1.2107 - val_acc: 0.5957\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8816\n",
      "Epoch 00014: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.3797 - acc: 0.8806 - val_loss: 1.2160 - val_acc: 0.5721\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8750\n",
      "Epoch 00015: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.3736 - acc: 0.8771 - val_loss: 1.2092 - val_acc: 0.5957\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.9147\n",
      "Epoch 00016: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.3073 - acc: 0.9131 - val_loss: 1.1927 - val_acc: 0.5910\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9345\n",
      "Epoch 00017: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.2510 - acc: 0.9320 - val_loss: 1.1663 - val_acc: 0.5957\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9183\n",
      "Epoch 00018: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 33s 20ms/sample - loss: 0.2547 - acc: 0.9190 - val_loss: 1.2616 - val_acc: 0.5839\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9501\n",
      "Epoch 00019: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.2081 - acc: 0.9486 - val_loss: 1.2744 - val_acc: 0.5934\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9579\n",
      "Epoch 00020: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.1822 - acc: 0.9580 - val_loss: 1.2870 - val_acc: 0.5981\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9579\n",
      "Epoch 00021: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 0.1696 - acc: 0.9557 - val_loss: 1.3379 - val_acc: 0.5887\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9675\n",
      "Epoch 00022: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.1545 - acc: 0.9669 - val_loss: 1.3345 - val_acc: 0.5957\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9712\n",
      "Epoch 00023: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.1357 - acc: 0.9710 - val_loss: 1.3091 - val_acc: 0.5981\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9730\n",
      "Epoch 00024: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 37s 22ms/sample - loss: 0.1266 - acc: 0.9734 - val_loss: 1.3625 - val_acc: 0.6147\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9892\n",
      "Epoch 00025: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.0802 - acc: 0.9894 - val_loss: 1.4032 - val_acc: 0.6076\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9952\n",
      "Epoch 00026: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 35s 21ms/sample - loss: 0.0577 - acc: 0.9953 - val_loss: 1.4056 - val_acc: 0.6265\n",
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 35s 20ms/sample - loss: 0.0439 - acc: 1.0000 - val_loss: 1.4711 - val_acc: 0.6028\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 22ms/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 1.4720 - val_acc: 0.5981\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 1.4734 - val_acc: 0.6099\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 1.08127\n",
      "1692/1692 [==============================] - 36s 21ms/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 1.5104 - val_acc: 0.6099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facdc19f358>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 800\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_800 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_800.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_800.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape with slices: (1692, 22, 900)\n",
      "Training label shape with slice: (1692,)\n",
      "Validation data shape with slices: (423, 22, 900)\n",
      "Validation label shape with slice: (423,)\n",
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.8942 - acc: 0.2879\n",
      "Epoch 00001: val_loss improved from inf to 1.38605, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 1.8866 - acc: 0.2884 - val_loss: 1.3860 - val_acc: 0.3570\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.2639 - acc: 0.4201\n",
      "Epoch 00002: val_loss improved from 1.38605 to 1.32799, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 1.2656 - acc: 0.4178 - val_loss: 1.3280 - val_acc: 0.3641\n",
      "Epoch 3/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.1934 - acc: 0.4736\n",
      "Epoch 00003: val_loss did not improve from 1.32799\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 1.1956 - acc: 0.4722 - val_loss: 1.3345 - val_acc: 0.4184\n",
      "Epoch 4/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0965 - acc: 0.5264\n",
      "Epoch 00004: val_loss improved from 1.32799 to 1.24781, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 1.0945 - acc: 0.5290 - val_loss: 1.2478 - val_acc: 0.4208\n",
      "Epoch 5/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 1.0040 - acc: 0.5787\n",
      "Epoch 00005: val_loss improved from 1.24781 to 1.23711, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 43s 25ms/sample - loss: 1.0050 - acc: 0.5798 - val_loss: 1.2371 - val_acc: 0.4468\n",
      "Epoch 6/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.9228 - acc: 0.6328\n",
      "Epoch 00006: val_loss improved from 1.23711 to 1.21366, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.9238 - acc: 0.6306 - val_loss: 1.2137 - val_acc: 0.4728\n",
      "Epoch 7/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.8531 - acc: 0.6671\n",
      "Epoch 00007: val_loss improved from 1.21366 to 1.17705, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.8513 - acc: 0.6678 - val_loss: 1.1771 - val_acc: 0.5106\n",
      "Epoch 8/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7737 - acc: 0.6905\n",
      "Epoch 00008: val_loss did not improve from 1.17705\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 0.7729 - acc: 0.6921 - val_loss: 1.1800 - val_acc: 0.5296\n",
      "Epoch 9/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.7066 - acc: 0.7440\n",
      "Epoch 00009: val_loss did not improve from 1.17705\n",
      "1692/1692 [==============================] - 43s 26ms/sample - loss: 0.7043 - acc: 0.7447 - val_loss: 1.2070 - val_acc: 0.5485\n",
      "Epoch 10/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.6248 - acc: 0.7752\n",
      "Epoch 00010: val_loss improved from 1.17705 to 1.08576, saving model to ./model_checkpoints/shallow_model_900\n",
      "INFO:tensorflow:Assets written to: ./model_checkpoints/shallow_model_900/assets\n",
      "1692/1692 [==============================] - 44s 26ms/sample - loss: 0.6226 - acc: 0.7766 - val_loss: 1.0858 - val_acc: 0.5721\n",
      "Epoch 11/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.5321 - acc: 0.8065\n",
      "Epoch 00011: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 43s 25ms/sample - loss: 0.5326 - acc: 0.8061 - val_loss: 1.1581 - val_acc: 0.5721\n",
      "Epoch 12/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4985 - acc: 0.8233\n",
      "Epoch 00012: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.5011 - acc: 0.8221 - val_loss: 1.1180 - val_acc: 0.5461\n",
      "Epoch 13/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8570\n",
      "Epoch 00013: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.4422 - acc: 0.8564 - val_loss: 1.2282 - val_acc: 0.5461\n",
      "Epoch 14/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.4237 - acc: 0.8546\n",
      "Epoch 00014: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.4243 - acc: 0.8546 - val_loss: 1.1200 - val_acc: 0.5556\n",
      "Epoch 15/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3360 - acc: 0.8960\n",
      "Epoch 00015: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.3371 - acc: 0.8948 - val_loss: 1.1504 - val_acc: 0.5792\n",
      "Epoch 16/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.3019 - acc: 0.9159\n",
      "Epoch 00016: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 39s 23ms/sample - loss: 0.3008 - acc: 0.9167 - val_loss: 1.2003 - val_acc: 0.5650\n",
      "Epoch 17/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2770 - acc: 0.9231\n",
      "Epoch 00017: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.2759 - acc: 0.9238 - val_loss: 1.2083 - val_acc: 0.5934\n",
      "Epoch 18/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9393\n",
      "Epoch 00018: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.2271 - acc: 0.9397 - val_loss: 1.1891 - val_acc: 0.5863\n",
      "Epoch 19/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9495\n",
      "Epoch 00019: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 25ms/sample - loss: 0.1982 - acc: 0.9504 - val_loss: 1.2738 - val_acc: 0.5816\n",
      "Epoch 20/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9736\n",
      "Epoch 00020: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.1519 - acc: 0.9734 - val_loss: 1.4321 - val_acc: 0.5626\n",
      "Epoch 21/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9567\n",
      "Epoch 00021: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.1784 - acc: 0.9569 - val_loss: 1.3301 - val_acc: 0.5839\n",
      "Epoch 22/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9688\n",
      "Epoch 00022: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.1464 - acc: 0.9681 - val_loss: 1.4422 - val_acc: 0.5934\n",
      "Epoch 23/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9772\n",
      "Epoch 00023: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.1177 - acc: 0.9775 - val_loss: 1.3598 - val_acc: 0.5910\n",
      "Epoch 24/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9964\n",
      "Epoch 00024: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.0849 - acc: 0.9965 - val_loss: 1.4108 - val_acc: 0.5957\n",
      "Epoch 25/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9940\n",
      "Epoch 00025: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 0.0762 - acc: 0.9941 - val_loss: 1.4904 - val_acc: 0.5792\n",
      "Epoch 26/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9994\n",
      "Epoch 00026: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 42s 25ms/sample - loss: 0.0531 - acc: 0.9994 - val_loss: 1.4724 - val_acc: 0.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9994\n",
      "Epoch 00027: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 0.0498 - acc: 0.9994 - val_loss: 1.5012 - val_acc: 0.5957\n",
      "Epoch 28/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9994\n",
      "Epoch 00028: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 0.0412 - acc: 0.9994 - val_loss: 1.5195 - val_acc: 0.5863\n",
      "Epoch 29/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 00029: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 40s 24ms/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 1.5090 - val_acc: 0.5981\n",
      "Epoch 30/30\n",
      "1664/1692 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 00030: val_loss did not improve from 1.08576\n",
      "1692/1692 [==============================] - 41s 24ms/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 1.5538 - val_acc: 0.5981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7facd457bf28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TIME_WINDOW = 900\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_900 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_900.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_900.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 1s 2ms/sample - loss: 1.0986 - acc: 0.5296\n",
      "423/423 [==============================] - 2s 4ms/sample - loss: 0.9709 - acc: 0.6359\n",
      "423/423 [==============================] - 2s 5ms/sample - loss: 0.9722 - acc: 0.6430\n",
      "423/423 [==============================] - 3s 6ms/sample - loss: 0.9887 - acc: 0.6690\n",
      "423/423 [==============================] - 3s 7ms/sample - loss: 1.0813 - acc: 0.5768\n",
      "423/423 [==============================] - 3s 8ms/sample - loss: 1.0858 - acc: 0.5721\n",
      "423/423 [==============================] - 4s 9ms/sample - loss: 1.1665 - acc: 0.5414\n"
     ]
    }
   ],
   "source": [
    "best_shallow_model_300 = keras.models.load_model('./model_checkpoints/shallow_model_300')\n",
    "best_shallow_model_500 = keras.models.load_model('./model_checkpoints/shallow_model_500')\n",
    "best_shallow_model_600 = keras.models.load_model('./model_checkpoints/shallow_model_600')\n",
    "best_shallow_model_700 = keras.models.load_model('./model_checkpoints/shallow_model_700')\n",
    "best_shallow_model_800 = keras.models.load_model('./model_checkpoints/shallow_model_800')\n",
    "best_shallow_model_900 = keras.models.load_model('./model_checkpoints/shallow_model_900')\n",
    "best_shallow_model_1000 = keras.models.load_model('./model_checkpoints/shallow_model_1000')\n",
    "\n",
    "number_of_samples = [300, 500, 600, 700, 800, 900, 1000]\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "# ==================================== 300 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=300, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_300.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 500 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=500, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_500.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 600 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=600, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_600.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 700 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=700, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_700.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 800 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=800, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_800.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 900 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=900, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_900.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 1000 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=1000, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_1000.evaluate(X_valid_slices, y_valid_slices)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facdc3855c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.xlabel('number of samples')\n",
    "plt.ylabel('accuracy')\n",
    "ax.plot(number_of_samples, accuracies);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 2s 5ms/sample - loss: 1.0659 - acc: 0.6208\n",
      "\n",
      "# Evaluate on test data\n",
      "Optimal shallow model test loss: 1.0659487419688136\n",
      "Optimal shallow model test acc: 0.6207675\n"
     ]
    }
   ],
   "source": [
    "X_test_slices, y_test_slices = sliding_window(X_test, \n",
    "                                              y_test, \n",
    "                                              time_window=700, \n",
    "                                              time_stride=TIME_STRIDE)\n",
    "\n",
    "shallow_model_results = best_shallow_model_700.evaluate(X_test_slices, y_test_slices)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "print('Optimal shallow model test loss:', shallow_model_results[0])\n",
    "print('Optimal shallow model test acc:', shallow_model_results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_C247",
   "language": "python",
   "name": "venv_c247"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 654.545454,
   "position": {
    "height": "40px",
    "left": "266.375px",
    "right": "20px",
    "top": "2px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
