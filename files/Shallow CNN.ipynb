{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This architecture was described in \"Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG\", by R. T. Schirrmeister et al, 2018. In this notebook we conduct experiments showing dependency between accuracy and the number of timestamps in a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# import tf\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# import os functions\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sriramsonti/Desktop/project_C247\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./EEG_data/X_test.npy\")\n",
    "y_test = np.load(\"./EEG_data/y_test.npy\") - 769\n",
    "person_train_valid = np.load(\"./EEG_data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./EEG_data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./EEG_data/y_train_valid.npy\") - 769\n",
    "person_test = np.load(\"./EEG_data/person_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid  shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"training/Valid data shape: {}\".format(X_train_valid.shape))       # training data of many persons\n",
    "print(\"Test data shape: {}\".format(X_test.shape))                        # test data of many persons\n",
    "print(\"Training/Valid target shape: {}\".format(y_train_valid.shape))     # training labels of many persons\n",
    "print(\"Test target shape: {}\".format(y_test.shape))                      # test labels of many persons\n",
    "print(\"Person train/valid  shape: {}\".format(person_train_valid.shape))  # which person correspond to the trail in test set\n",
    "print(\"Person test shape: {}\".format(person_test.shape))                 # which person correspond to the trail in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1692, 22, 1000)\n",
      "Training label shape: (1692,)\n",
      "Validation data shape: (423, 22, 1000)\n",
      "Validation label shape: (423,)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Test label shape: (443,)\n"
     ]
    }
   ],
   "source": [
    "perm = np.random.permutation(X_train_valid.shape[0])\n",
    "num_train = int(0.8 * X_train_valid.shape[0])\n",
    "num_valid = X_train_valid.shape[0] - num_train\n",
    "X_train =  X_train_valid[perm[0:num_train]]\n",
    "y_train =  y_train_valid[perm[0:num_train]]\n",
    "X_valid = X_train_valid[perm[num_train: ]]\n",
    "y_valid = y_train_valid[perm[num_train: ]]\n",
    "\n",
    "\n",
    "print(\"Training data shape: {}\".format(X_train.shape))\n",
    "print(\"Training label shape: {}\".format(y_train.shape))\n",
    "print(\"Validation data shape: {}\".format(X_valid.shape))\n",
    "print(\"Validation label shape: {}\".format(y_valid.shape))\n",
    "print(\"Test data shape: {}\".format(X_test.shape))\n",
    "print(\"Test label shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(X_arr, y_arr, time_window=100, time_step=1, time_stride=1):\n",
    "    temp_x = np.moveaxis(X_arr, 2, 0)\n",
    "    temp_x = temp_x.astype(np.float32)\n",
    "    buff = []\n",
    "    \n",
    "    num_slices = (len(temp_x)-time_window*time_step) // time_stride + 1\n",
    "    \n",
    "    # get time slices for data\n",
    "    for i in range(num_slices):\n",
    "        buff.append(temp_x[i*time_stride:i*time_stride + time_window*time_step:time_step])\n",
    "        buff[i] = np.moveaxis(buff[i], 0, 2)\n",
    "        # uncomment this if additional dimension is needed\n",
    "        # buff[i] = buff[i].reshape(1, buff[i].shape[0], buff[i].shape[1], buff[i].shape[2])\n",
    "        \n",
    "    temp_x = np.concatenate(buff)\n",
    "        \n",
    "    # get time slice for labels\n",
    "    temp_y = np.ones((X_arr.shape[0],num_slices))\n",
    "    \n",
    "    for i in range(len(y_arr)):\n",
    "        temp_y[i] = temp_y[i] * y_arr[i]\n",
    "        \n",
    "    temp_y = temp_y.reshape((-1))\n",
    "    \n",
    "    return temp_x, temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: shallow model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we show that:\n",
    "1. shallow model can achieve up to 61.5% of validation accuracy given samples with 1000 timestamps;\n",
    "2. shallow model achieves lowest validation loss after being trained for 9 epochs, after which it starts to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ksquare(x):\n",
    "    return K.pow(x, 2)\n",
    "\n",
    "def Klog(x):\n",
    "    return K.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_shallow_model(TIME_WINDOW):\n",
    "    # input\n",
    "    shallow_input = layers.Input(shape=(22, TIME_WINDOW))\n",
    "\n",
    "    # conv accross time domain\n",
    "    r1 = layers.Reshape((22, TIME_WINDOW, 1))(shallow_input)\n",
    "    c1 = layers.Conv2D(40, (1, 25), strides=(1, 1), activation=\"elu\")(r1)\n",
    "    new_size = TIME_WINDOW - 25 + 1\n",
    "    t1 = tf.keras.layers.Permute((2, 3, 1))(c1)\n",
    "    \n",
    "    \n",
    "    # conv accross time domain\n",
    "    r2 = layers.Reshape((new_size, 40*22, 1))(t1)\n",
    "    c2 = layers.Conv2D(40, (1, 40*22), strides=(1, 1), activation=\"elu\")(r2)\n",
    "\n",
    "    sq1 = layers.Activation(Ksquare)(c2)\n",
    "    r3 = layers.Reshape((new_size, 40, 1))(sq1)\n",
    "    apool1 = layers.AveragePooling2D(pool_size=(75, 1), strides=(15, 1))(r3)\n",
    "\n",
    "    log1 = layers.Activation(Klog)(apool1)\n",
    "    f1 = layers.Flatten()(log1)\n",
    "\n",
    "    # output\n",
    "    shallow_output = layers.Dense(4, activation=\"softmax\")(f1)\n",
    "    \n",
    "    return keras.Model(inputs = shallow_input, outputs = shallow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000 = construct_shallow_model(1000)\n",
    "shallow_model_1000.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 22, 1000)]        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 22, 1000, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 22, 976, 40)       1040      \n",
      "_________________________________________________________________\n",
      "permute (Permute)            (None, 976, 40, 22)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 976, 880, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 976, 1, 40)        35240     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 976, 1, 40)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 976, 40, 1)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 61, 40, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2440)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 9764      \n",
      "=================================================================\n",
      "Total params: 46,044\n",
      "Trainable params: 46,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "shallow_model_1000.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on single person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape for 1 person: (189, 22, 1000)\n",
      "Training label shape for 1 person: (189,)\n",
      "Validation data shape for 1 person: (48, 22, 1000)\n",
      "Validation label shape for 1 person: (48,)\n",
      "Test data shape for 1 person: (50, 22, 1000)\n",
      "Test label shape for 1 person: (50,)\n"
     ]
    }
   ],
   "source": [
    "person_num = 0\n",
    "indices_train_valid = np.where(person_train_valid == person_num)[0]\n",
    "indices_test = np.where(person_test == person_num)[0]\n",
    "\n",
    "single_person_X_train_valid = X_train_valid[indices_train_valid]\n",
    "single_person_y_train_valid = y_train_valid[indices_train_valid]\n",
    "\n",
    "perm = np.random.permutation(single_person_X_train_valid.shape[0])\n",
    "num_train = int(0.8 * single_person_X_train_valid.shape[0])\n",
    "num_valid = single_person_X_train_valid.shape[0] - num_train\n",
    "single_person_X_train =  single_person_X_train_valid[perm[0:num_train]]\n",
    "single_person_y_train =  single_person_y_train_valid[perm[0:num_train]]\n",
    "single_person_X_valid = single_person_X_train_valid[perm[num_train: ]]\n",
    "single_person_y_valid = single_person_y_train_valid[perm[num_train: ]]\n",
    "\n",
    "single_person_X_test = X_test[indices_test]\n",
    "single_person_y_test = y_test[indices_test]\n",
    "\n",
    "\n",
    "print(\"Training data shape for 1 person: {}\".format(single_person_X_train.shape))\n",
    "print(\"Training label shape for 1 person: {}\".format(single_person_y_train.shape))\n",
    "print(\"Validation data shape for 1 person: {}\".format(single_person_X_valid.shape))\n",
    "print(\"Validation label shape for 1 person: {}\".format(single_person_y_valid.shape))\n",
    "print(\"Test data shape for 1 person: {}\".format(single_person_X_test.shape))\n",
    "print(\"Test label shape for 1 person: {}\".format(single_person_y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189 samples, validate on 48 samples\n",
      "Epoch 1/30\n",
      "189/189 [==============================] - 15s 78ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 2/30\n",
      "189/189 [==============================] - 19s 99ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 3/30\n",
      "189/189 [==============================] - 17s 90ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 4/30\n",
      "189/189 [==============================] - 15s 79ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 5/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 6/30\n",
      "189/189 [==============================] - 13s 71ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 7/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 8/30\n",
      "189/189 [==============================] - 19s 98ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 9/30\n",
      "189/189 [==============================] - 13s 67ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 10/30\n",
      "189/189 [==============================] - 13s 66ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 11/30\n",
      "189/189 [==============================] - 15s 80ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 12/30\n",
      "189/189 [==============================] - 14s 75ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 13/30\n",
      "189/189 [==============================] - 13s 70ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 14/30\n",
      "189/189 [==============================] - 17s 91ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 15/30\n",
      "189/189 [==============================] - 17s 92ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 16/30\n",
      "189/189 [==============================] - 14s 74ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 17/30\n",
      "189/189 [==============================] - 14s 74ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 18/30\n",
      "189/189 [==============================] - 16s 83ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 19/30\n",
      "189/189 [==============================] - 14s 75ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 20/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 21/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 22/30\n",
      "189/189 [==============================] - 14s 74ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 23/30\n",
      "189/189 [==============================] - 13s 70ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 24/30\n",
      "189/189 [==============================] - 19s 100ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 25/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 26/30\n",
      "189/189 [==============================] - 14s 73ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 27/30\n",
      "189/189 [==============================] - 14s 74ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 28/30\n",
      "189/189 [==============================] - 15s 77ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 29/30\n",
      "189/189 [==============================] - 14s 74ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n",
      "Epoch 30/30\n",
      "189/189 [==============================] - 14s 72ms/sample - loss: nan - acc: 0.2646 - val_loss: nan - val_acc: 0.2083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6d03c2bd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_model_1000_single = construct_shallow_model(1000)\n",
    "shallow_model_1000_single.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "shallow_model_1000_single.fit(single_person_X_train, single_person_y_train,\n",
    "                                            validation_data = (single_person_X_valid, single_person_y_valid),\n",
    "                                            epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "50/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 8ms/sample - loss: nan - acc: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.24]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_model_1000_single.evaluate(single_person_X_test, single_person_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "443/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 3s 8ms/sample - loss: nan - acc: 0.2506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.25056434]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shallow_model_1000_single.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1692 samples, validate on 423 samples\n",
      "Epoch 1/30\n",
      "1664/1692 [============================>.] - ETA: 1s - loss: nan - acc: 0.2542\n",
      "Epoch 00001: val_loss did not improve from inf\n",
      "1692/1692 [==============================] - 116s 68ms/sample - loss: nan - acc: 0.2565 - val_loss: nan - val_acc: 0.2246\n",
      "Epoch 2/30\n",
      "1664/1692 [============================>.] - ETA: 1s - loss: nan - acc: 0.2560\n",
      "Epoch 00002: val_loss did not improve from inf\n",
      "1692/1692 [==============================] - 122s 72ms/sample - loss: nan - acc: 0.2565 - val_loss: nan - val_acc: 0.2246\n",
      "Epoch 3/30\n",
      " 544/1692 [========>.....................] - ETA: 1:18 - loss: nan - acc: 0.2637WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4dd5d3677b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                                  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                  \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                  callbacks=checkpoint_callback)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shallow_model_loss_hist = shallow_model_1000.fit(X_train, y_train,\n",
    "                                                 validation_data = (X_valid, y_valid),\n",
    "                                                 epochs = 30,\n",
    "                                                 callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = shallow_model_loss_hist.history\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist['acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: shallow model with normilized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we shaow that data normalization does not help to improve validation accuracy. For the following experiment with shallow model, we do not try to normilize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normilize the data USING ONLY TRAIN DATA MEAN AND STANDARD DEVIATION\n",
    "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_valid_norm = (X_valid - np.mean(X_train))/np.std(X_train)\n",
    "X_test_norm = (X_test - np.mean(X_train))/np.std(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_model_1000_norm = construct_shallow_model(1000)\n",
    "shallow_model_1000_norm.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_1000_norm',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shallow_model_1000_norm.fit(X_train_norm, y_train,\n",
    "                            validation_data = (X_valid_norm, y_valid),\n",
    "                            epochs = 30,\n",
    "                            callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: shallow model - accuracy vs number of timestamps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we show that accuracy peaks at 700 timestamps per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 300\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_300 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_300.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_300.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 500\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_500 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_500.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_500.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 600\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_600 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_600.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_600.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 700\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_700 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_700.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_700.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 800\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_800 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_800.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_800.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TIME_WINDOW = 900\n",
    "TIME_STRIDE = 1000\n",
    "\n",
    "# cut the slices\n",
    "X_train_slices, y_train_slices = sliding_window(X_train, \n",
    "                                                y_train, \n",
    "                                                time_window=TIME_WINDOW,  \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=TIME_WINDOW, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "\n",
    "print(\"Training data shape with slices: {}\".format(X_train_slices.shape))\n",
    "print(\"Training label shape with slice: {}\".format(y_train_slices.shape))\n",
    "print(\"Validation data shape with slices: {}\".format(X_valid_slices.shape))\n",
    "print(\"Validation label shape with slice: {}\".format(y_valid_slices.shape))\n",
    "\n",
    "\n",
    "# save model with the best accuracy \n",
    "checkpoint_callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./model_checkpoints/shallow_model_' + str(TIME_WINDOW),\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "shallow_model_900 = construct_shallow_model(TIME_WINDOW)\n",
    "shallow_model_900.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "shallow_model_900.fit(X_train_slices, y_train_slices,\n",
    "                      validation_data = (X_valid_slices, y_valid_slices),\n",
    "                      epochs = 30,\n",
    "                      callbacks=checkpoint_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_shallow_model_300 = keras.models.load_model('./model_checkpoints/shallow_model_300')\n",
    "best_shallow_model_500 = keras.models.load_model('./model_checkpoints/shallow_model_500')\n",
    "best_shallow_model_600 = keras.models.load_model('./model_checkpoints/shallow_model_600')\n",
    "best_shallow_model_700 = keras.models.load_model('./model_checkpoints/shallow_model_700')\n",
    "best_shallow_model_800 = keras.models.load_model('./model_checkpoints/shallow_model_800')\n",
    "best_shallow_model_900 = keras.models.load_model('./model_checkpoints/shallow_model_900')\n",
    "best_shallow_model_1000 = keras.models.load_model('./model_checkpoints/shallow_model_1000')\n",
    "\n",
    "number_of_samples = [300, 500, 600, 700, 800, 900, 1000]\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "# ==================================== 300 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=300, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_300.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 500 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=500, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_500.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 600 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=600, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_600.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "\n",
    "# ==================================== 700 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=700, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_700.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 800 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=800, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_800.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 900 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=900, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_900.evaluate(X_valid_slices, y_valid_slices)[1])\n",
    "\n",
    "\n",
    "# ==================================== 1000 ==================================== #\n",
    "\n",
    "X_valid_slices, y_valid_slices = sliding_window(X_valid, \n",
    "                                                y_valid, \n",
    "                                                time_window=1000, \n",
    "                                                time_stride=TIME_STRIDE)\n",
    "\n",
    "accuracies.append(best_shallow_model_1000.evaluate(X_valid_slices, y_valid_slices)[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "plt.xlabel('number of samples')\n",
    "plt.ylabel('accuracy')\n",
    "ax.plot(number_of_samples, accuracies);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_slices, y_test_slices = sliding_window(X_test, \n",
    "                                              y_test, \n",
    "                                              time_window=700, \n",
    "                                              time_stride=TIME_STRIDE)\n",
    "\n",
    "shallow_model_results = best_shallow_model_700.evaluate(X_test_slices, y_test_slices)\n",
    "\n",
    "\n",
    "print('\\n# Evaluate on test data')\n",
    "print('Optimal shallow model test loss:', shallow_model_results[0])\n",
    "print('Optimal shallow model test acc:', shallow_model_results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 654.545454,
   "position": {
    "height": "40px",
    "left": "266.375px",
    "right": "20px",
    "top": "2px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
